---
draft: true
# readingtime: 15
slug: state-of-ai-2024
title: State of AI (2024)

authors:
  - emmanuel
#   - florian
#   - oceanne

categories:
  - Algorithms

date:
  created: 2024-10-12
  updated: 2024-10-12

description: This is the post description

# --- Sponsors only
# link:
#   - tests/pdf_hook.md
#   - tests/youtube_hook.md
#   - Widget: tests/widgets.md
# pin: false
# tags:
#   - FooTag
#   - BarTag
---

# State of AI (2024)

<!-- end-of-excerpt -->

# Links

 * State of AI - [https://www.stateof.ai/](https://www.stateof.ai/)
 * Embed Google slides in Jekyll - [https://dev-notes.eu/2016/09/embed-google-slides-in-jekyll/](https://dev-notes.eu/2016/09/embed-google-slides-in-jekyll/)

# Overview

 The State of AI Report analyses the most interesting developments in AI. We aim to trigger an informed conversation about the state of AI and its implication for the future. The Report is produced by AI investors Nathan Benaich and the Air Street Capital team.

 Now in its sixth year, the State of AI Report 2023 is reviewed by leading AI practioners in industry and research. It considers the following key dimensions, including a new Safety section:
  * Research: Technology breakthroughs and their capabilities.
  * Industry: Areas of commercial application for AI and its business impact.
  * Politics: Regulation of AI, its economic implications and the evolving geopolitics of AI.
  * Safety: Identifying and mitigating catastrophic risks that highly-capable future AI systems could pose to us.
  * Predictions: What we believe will happen and a performance review to keep us honest.

# 2024

 Link - [https://press.airstreet.com/p/state-of-ai-report-2024](https://press.airstreet.com/p/state-of-ai-report-2024)
  * Ai isn't the dotcom bubble - [https://press.airstreet.com/p/ai-isnt-the-dotcom-bubble](https://press.airstreet.com/p/ai-isnt-the-dotcom-bubble)

 {% pdfff "/+/s/state_of_ai_report_20241012.pdf" %}

# 2023

 {% youtube "https://www.youtube.com/watch?v=Ge99fqjD8HY" %}

 <div class="responsive-wrap">
 <!-- this is the embed code provided by Google -->
 <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSy85xPoG5nbPFuJv49z_4gYJW8FIIHoX_QYpKXX2cr2Z0nT-VvHQiemOSpzjTs5Awgf1KTlCNf8OZe/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
 <!-- Google embed ends -->
 </div>

 {% pdffff "/+/s/state_of_ai_report_20231012.pdf" %}

 For much of the last year, it’s felt like Large Language Models (LLMs) have been the only game in town. While the State of AI Report predicted that [transformers] were emerging as a general purpose system back in 2021, significant advances in capabilities caught both the AI community and wider world by surprise, with implications for research, industry dynamics, and geopolitics.

 Last year’s State of AI report outlined the rise of decentralization in AI research, but OpenAI’s [GPT-4] stunned observers as big tech returned with a vengeance. Amid the scrabble for ever more compute power, challengers have found themselves increasingly reliant on its war chest. At the same time, the open source community continues to thrive, as the number of releases continues to rocket.

 It has also led the drawing of new fault lines, with traditional community norms around openness under pressure from both commercial imperatives and safety fears.

 We’ve seen technical reports on state-of-the-art [LLMs] published that contain no useful information for AI researchers, while some labs have simply stopped producing them at all. One of the co-founders of [OpenAI] went as far as describing their original open source philosophy as “flat out … wrong”. In contrast, [Meta] AI has emerged as the champion of open(ish) AI, with their [LLaMa model family] acting as the most powerful publicly accessible alternative…for now.

 The discussion around openness is taking place against the backdrop of an impassioned debate about how we navigate governance and (existential) risk. As we forecast in last year’s report, safety has shed its status as the unloved cousin of the AI research world and took center-stage for the first time. As a result, governments and regulators around the world are beginning to sit up and take notice. This has been all the more challenging as the many of the mooted models of global governance require long-standing geopolitical rivals, currently locked in the chip wars, to cooperate. Indeed, State of AI Report co-author Ian Hogarth has been seconded to chair the UK Government’s Frontier AI Taskforce, so has therefore stepped back from writing this year.

 However, this is the State of AI, not the state of [LLMs], and the report dives into progress in other areas of the field - from breakthroughs in navigation and weather predictions through to [self-driving cars] and music generation. This has been one of the most exciting years to produce this report and we believe that it will have something for everyone - from AI research through to politics.

 Key takeaways:
  * GPT-4 is the master of all it surveys (for now), beating every other LLM on both classic benchmarks and exams designed to evaluate humans, validating the power of proprietary architectures and reinforcement learning from human feedback.
  * Efforts are growing to try to clone or surpass proprietary performance, through smaller models, better datasets, and longer context. These could gain new urgency, amid concerns that human-generated data may only be able to sustain AI scaling trends for a few more years.
  * LLMs and diffusion models continue to drive real-world breakthroughs, especially in the life sciences, with meaningful steps forward in both molecular biology and drug discovery.
  * Compute is the new oil, with NVIDIA printing record earnings and startups wielding their GPUs as a competitive edge. As the US tightens its restrictions on trade restrictions on China and mobilizes its allies in the chip wars, NVIDIA, Intel, and AMD have started to sell export-control proof chips at scale.
  * GenAI saves the VC world, as amid a slump in tech valuations, AI startups focused on generative AI applications (including video, text, and coding), raised over $18 billion from VC and corporate investors.
  * The safety debate has exploded into the mainstream, prompting action from governments and regulators around the world. However, this flurry of activity conceals profound divisions within the AI community and a lack of concrete progress towards global governance, as governments around the world pursue conflicting approaches.
  * Challenges mount in evaluating state of the art models, as standard LLMs often struggle with robustness. Considering the stakes, as “vibes-based” approach isn’t good enough.

 Source - [https://www.stateof.ai/](https://www.stateof.ai/)


# 2022

 {% youtube "https://www.youtube.com/watch?v=6aUkacsugwE" %}

 <div class="responsive-wrap">
 <!-- this is the embed code provided by Google -->
 <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSWZoyHka0OzgnZ5_DoHOLCDV6zMGXQWAINY-8mgLnStZmuQfhVpr2B3wibrDAoxCUYvHMtYYG7dkAg/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
 <!-- Google embed ends -->
 </div>

 {% pdfff "/+/s/state_of_ai_report_20221011.pdf" %}

 This year, new research collectives have open sourced breakthrough AI models developed by large centralized labs at a never before seen pace. By contrast, the large-scale AI compute infrastructure that has enabled this acceleration, however, remains firmly concentrated in the hands of [NVIDIA] despite investments by [Google], [Amazon], [Microsoft] and a range of startups.

 Produced in collaboration with my friend Ian Hogarth, this year’s State of AI Report also points to an increase in awareness among the AI community of the importance of AI safety research, with an estimated 300 safety researchers now working at large AI labs, compared to under 100 identified in last year's report.

 Small, previously unknown labs like [Stability.ai] and [Midjourney] have developed text-to-image models of similar capability to those released by [OpenAI] and [Google] earlier in the year, and made them available to the public via API access and open sourcing. Stability.AI’s model cost less than $600,000 to train, while Midjourney’s is already proving profitable and has become one of the leaders in the text-to-image market alongside OpenAI’s [Dall-E 2]. This demonstrates a fundamental shift in the previously accepted AI research dynamic that larger labs with the most resources, data, and talent would continually produce breakthrough research.

 Meanwhile, AI continues to advance scientific research. This year saw the release of 200M protein structure predictions using [AlphaFold], [DeepMind]’s advancement in nuclear fusion by training a [reinforcement learning] system to adjust the magnetic coils of a tokamak, and the development of a [machine learning] algorithm to engineer an enzyme capable of degrading PET plastics. However, as more AI-enabled science companies appear in the landscape, we also explore how methodological failures like data leakage and the ongoing tension between the speed of AI/ML development and the slower pace of scientific discovery might affect the landscape.

 Key takeaways. We hope the report has something for everyone, from AI research to politics:
  * New independent research labs are rapidly open sourcing the closed source output of major labs. Despite the dogma that AI research would be increasingly centralised among a few large players, the lowered cost of and access to compute has led to [state-of-the-art] research coming out of much smaller, previously unknown labs. Meanwhile, AI hardware remains strongly consolidated to [NVIDIA].
  * Safety is gaining awareness among major AI research entities, with an estimated 300 safety researchers working at large AI labs, compared to under 100 in last year's report, and the increased recognition of major AI safety academics is a promising sign when it comes to AI safety becoming a mainstream discipline.
  * The China-US AI research gap has continued to widen, with Chinese institutions producing 4.5 times as many papers than American institutions since 2010, and significantly more than the US, India, UK, and Germany combined. Moreover, China is significantly leading in areas with implications for security and geopolitics, such as surveillance, autonomy, scene understanding, and object detection.
  * AI-driven scientific research continues to lead to breakthroughs, but major methodological errors like data leakage need to be interrogated further. Even though AI breakthroughs in science continue, researchers warn that methodological errors in AI can leak to these disciplines, leading to a growing reproducibility crisis in AI-based science driven in part by data leakage.

 Source - [https://www.stateof.ai/2022-report-launch](https://www.stateof.ai/2022-report-launch)

# 2021

 {% comment %}
 <div class="responsive-wrap">
 <!-- this is the embed code provided by Google -->
 <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTHUWZ5w1TgCvUYIrawQbFNnEnEi0Cz9alxmW_0czhppDg-ewkPmpOySmxFPkuTuF2vVxLV6eA3TEne/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
 <!-- Google embed ends -->
 </div>
 {% endcomment %}


 {% pdffff "/+/s/state_of_ai_report_20211012.pdf" %}

 This year, we have seen AI become increasingly pivotal to breakthroughs in everything from drug discovery to mission critical infrastructure like electricity grids.

 While AI’s growing impact on society and the economy is now evident, our report highlights that research into AI safety and the impact of AI still lags behind its rapid commercial, civil, and military deployment. This, along with other prominent concerns of bias, gives us food for thought about how best to chart the progress of AI systems with rapidly advancing capabilities.

 This year’s report looks particularly at the emergence of transformer technology, a technique to focus machine learning algorithms on important relationships between data points to extract meaning more comprehensively for better predictions, which ultimately helped unlock many of the critical breakthroughs we highlight throughout.

 The report also sheds light on a watershed moment in the field of biology, where AI-first approaches continue to show their potential to entirely transform drug discovery and healthcare. I’m personally excited to see what’s next after the major breakthroughs with protein folding and the structure of RNA molecules.

 Key takeaways. We hope the report has something for everyone, from AI research to politics:
  * AI is stepping up in more concrete ways: AI is increasingly being applied to mission critical infrastructure like national electric grids and automated supermarket warehousing calculations during pandemics. However, there are questions about whether the maturity of the industry has caught up with the enormity of its growing deployment. An increasingly data-centric, rather than model-centric, view of AI is emerging.
  * AI-first approaches have taken biology by storm: AI has enabled faster simulations of humans’ cellular machinery (proteins and RNA) which has the potential to transform drug discovery and healthcare.
  * Transformers have emerged as a general purpose architecture for machine learning: beating the state of the art in many domains including NLP, computer vision, and even protein structure prediction.
  * Investors have taken notice: We have seen record funding this year into AI startups, and two first ever IPOs for AI-first drug discovery companies, as well as blockbuster IPOs for data infrastructure and cybersecurity companies that help enterprises retool for the AI-first era.
  * China's ascension in research quality is notable: China’s universities have rocketed from publishing no AI research in 1980 to the largest volume of quality AI research today.

 Source - [https://www.stateof.ai/2021-report-launch](https://www.stateof.ai/2021-report-launch)

# 2020

 {% youtube "https://www.youtube.com/watch?v=o2fYsrV-YlQ" %}

 {% comment %}
 <div class="responsive-wrap">
 <!-- this is the embed code provided by Google -->
 <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQbqF3dtROMsK2ayRV4VFas3F2F0SDJ-gTQxqE0luNpIDx-XI3Ee6CLaF7m76LXcgTKp52oh-w0RUbv/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
 <!-- Google embed ends -->
 </div>
 {% endcomment %}

 {% pdffff "/+/s/state_of_ai_report_20201001.pdf" %}

 Source - [https://www.stateof.ai/2020](https://www.stateof.ai/2020)

# 2019

 {% pdffff "/+/s/state_of_ai_report_20190628.pdf" %}

 Source - [https://www.stateof.ai/2019](https://www.stateof.ai/2019)

# 2018

 {% pdffff "/+/s/state_of_ai_report_20180629.pdf" %}

 Source - [https://www.stateof.ai/2018](https://www.stateof.ai/2018)
