
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/v/">
      
      
        <link rel="prev" href="../u/">
      
      
        <link rel="next" href="../w/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>V - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="V - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/v.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/v/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="V - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/v.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#v" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              V
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../g/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../l/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    V
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#valence-aware-dictionary-and-sentiment-reasoner-vader-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Valence Aware Dictionary and sEntiment Reasoner (VADER) Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#validation-set" class="md-nav__link">
    <span class="md-ellipsis">
      Validation Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#value" class="md-nav__link">
    <span class="md-ellipsis">
      Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#value-based-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Value-Based Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanilla" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanilla-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla GAN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanishing-gradient-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Vanishing Gradient Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable" class="md-nav__link">
    <span class="md-ellipsis">
      Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable-model" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable-type" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Type
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variance" class="md-nav__link">
    <span class="md-ellipsis">
      Variance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variational-autoencoder-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder (VAE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variational-autoencoder-reparameterization-trick" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder Reparameterization Trick
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vasa-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      VASA Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector" class="md-nav__link">
    <span class="md-ellipsis">
      Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-database" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Indexing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-quantized-generative-adversarial-network-vq-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Quantized Generative Adversarial Network (VQ-GAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-quantized-variational-autoencoder-vq-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Quantized Variational Autoencoder (VQ-VAE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Retrieval
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-search-library" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-search-plugin" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Plugin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-space" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-space-collision" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Space Collision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#veo-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Veo Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#viam-model" class="md-nav__link">
    <span class="md-ellipsis">
      Viam Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vicuna-model" class="md-nav__link">
    <span class="md-ellipsis">
      Vicuna Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-generator" class="md-nav__link">
    <span class="md-ellipsis">
      Video Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-joint-embedding-predictive-architecture-v-jepa" class="md-nav__link">
    <span class="md-ellipsis">
      Video Joint-Embedding Predictive Architecture (V-JEPA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-pre-training-vpt-model" class="md-nav__link">
    <span class="md-ellipsis">
      Video Pre-Training (VPT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-restoration" class="md-nav__link">
    <span class="md-ellipsis">
      Video Restoration
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Video Summarization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-to-video-vtv-model" class="md-nav__link">
    <span class="md-ellipsis">
      Video-To-Video (VTV) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vima-model" class="md-nav__link">
    <span class="md-ellipsis">
      VIMA Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-assistant" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Assistant
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-continuum" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Continuum
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-reality-vr" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Reality (VR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-geometry-group-vgg-model" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Geometry Group (VGG) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-arena" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Arena
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-model-vlm" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Model (VLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-pre-training-vlp" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Pre-Training (VLP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-transformer-vit-model" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformer (ViT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-grounding" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Grounding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-language-model-vlm" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Language Model (VLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-simultaneous-localization-and-mapping-vslam-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Simultaneous Localization And Mapping (VSLAM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voice-cloning" class="md-nav__link">
    <span class="md-ellipsis">
      Voice Cloning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voice-encoder-vocoder" class="md-nav__link">
    <span class="md-ellipsis">
      Voice Encoder (Vocoder)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voicebox-model" class="md-nav__link">
    <span class="md-ellipsis">
      Voicebox Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voiceflow-company" class="md-nav__link">
    <span class="md-ellipsis">
      VoiceFlow Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voxel" class="md-nav__link">
    <span class="md-ellipsis">
      Voxel
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#valence-aware-dictionary-and-sentiment-reasoner-vader-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Valence Aware Dictionary and sEntiment Reasoner (VADER) Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#validation-set" class="md-nav__link">
    <span class="md-ellipsis">
      Validation Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#value" class="md-nav__link">
    <span class="md-ellipsis">
      Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#value-based-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Value-Based Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanilla" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanilla-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Vanilla GAN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vanishing-gradient-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Vanishing Gradient Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable" class="md-nav__link">
    <span class="md-ellipsis">
      Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable-model" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variable-type" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Type
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variance" class="md-nav__link">
    <span class="md-ellipsis">
      Variance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variational-autoencoder-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder (VAE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variational-autoencoder-reparameterization-trick" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoder Reparameterization Trick
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vasa-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      VASA Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector" class="md-nav__link">
    <span class="md-ellipsis">
      Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-database" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Indexing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-quantized-generative-adversarial-network-vq-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Quantized Generative Adversarial Network (VQ-GAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-quantized-variational-autoencoder-vq-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Quantized Variational Autoencoder (VQ-VAE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Retrieval
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-search-library" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-search-plugin" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Search Plugin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-space" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-space-collision" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Space Collision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#veo-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Veo Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#viam-model" class="md-nav__link">
    <span class="md-ellipsis">
      Viam Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vicuna-model" class="md-nav__link">
    <span class="md-ellipsis">
      Vicuna Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-generator" class="md-nav__link">
    <span class="md-ellipsis">
      Video Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-joint-embedding-predictive-architecture-v-jepa" class="md-nav__link">
    <span class="md-ellipsis">
      Video Joint-Embedding Predictive Architecture (V-JEPA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-pre-training-vpt-model" class="md-nav__link">
    <span class="md-ellipsis">
      Video Pre-Training (VPT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-restoration" class="md-nav__link">
    <span class="md-ellipsis">
      Video Restoration
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Video Summarization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-to-video-vtv-model" class="md-nav__link">
    <span class="md-ellipsis">
      Video-To-Video (VTV) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vima-model" class="md-nav__link">
    <span class="md-ellipsis">
      VIMA Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-assistant" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Assistant
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-continuum" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Continuum
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-reality-vr" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Reality (VR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-geometry-group-vgg-model" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Geometry Group (VGG) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-arena" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Arena
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-model-vlm" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Model (VLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-language-pre-training-vlp" class="md-nav__link">
    <span class="md-ellipsis">
      Vision-Language Pre-Training (VLP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vision-transformer-vit-model" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformer (ViT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-grounding" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Grounding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-language-model-vlm" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Language Model (VLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visual-simultaneous-localization-and-mapping-vslam-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Simultaneous Localization And Mapping (VSLAM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voice-cloning" class="md-nav__link">
    <span class="md-ellipsis">
      Voice Cloning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voice-encoder-vocoder" class="md-nav__link">
    <span class="md-ellipsis">
      Voice Encoder (Vocoder)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voicebox-model" class="md-nav__link">
    <span class="md-ellipsis">
      Voicebox Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voiceflow-company" class="md-nav__link">
    <span class="md-ellipsis">
      VoiceFlow Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voxel" class="md-nav__link">
    <span class="md-ellipsis">
      Voxel
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="v">V<a class="headerlink" href="#v" title="Permanent link">#</a></h1>
<h2 id="valence-aware-dictionary-and-sentiment-reasoner-vader-python-module">Valence Aware Dictionary and sEntiment Reasoner (VADER) Python Module<a class="headerlink" href="#valence-aware-dictionary-and-sentiment-reasoner-vader-python-module" title="Permanent link">#</a></h2>
<p>VADER is a lexicon and rule-based feeling analysis instrument that is explicitly sensitive to suppositions communicated in web-based media. VADER utilizes a mix of lexical highlights (e.g., words) that are, for the most part, marked by their semantic direction as one or the other positive or negative. Thus, VADER not only tells about the Polarity score yet, in addition, it tells us concerning how positive or negative a conclusion is.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2021/06/vader-for-sentiment-analysis/">https://www.analyticsvidhya.com/blog/2021/06/vader-for-sentiment-analysis/</a></li>
<li><a href="https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/">https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../s/#sentiment-analysis">Sentiment Analysis</a></p>
<h2 id="validation-set">Validation Set<a class="headerlink" href="#validation-set" title="Permanent link">#</a></h2>
<p>~ Used to find the proper complexity of the model that is the balance between the bias and variance a.k.a. [bias-variance tradeoff]</p>
<p>Double training data split!</p>
<ul>
<li>In python you train_test_plit twice !</li>
<li>At the end you have a <a href="../t/#training-set">Training Set</a>, <a href="./#validation-set">Validation Set</a>, and a <a href="../t/#test-set">Test Set</a></li>
</ul>
<p>Why a validation set?</p>
<ul>
<li>Used for validation during training</li>
<li>Help avoid <a href="../o/#overfitting">overfitting</a> (and <a href="../u/#underfitting">underfitting</a> ?)</li>
<li>... </li>
<li>Used to find the proper balance for the [bias-variance tradeoff]</li>
</ul>
<p>Ratios ?</p>
<ul>
<li>80 - 10 - 10</li>
<li>70 - 15 - 15</li>
</ul>
<p>The validation set is used to fine-tune the hyperparameters of the model, a.k.a. <a href="../h/#hyperparameter-optimization-hpo">Hyperparameter Optimization (HPO)</a>, and is considered a part of the training of the model. The model only sees this data for evaluation but does not learn from this data, providing an objective unbiased evaluation of the model. Validation dataset can be utilized for <a href="../r/#regression-task">regression</a> as well by interrupting training of model when loss of validation dataset becomes greater than loss of training dataset .i.e. reducing <a href="../b/#bias">bias</a> and <a href="./#variance">variance</a>. This data is approximately 10-15% of the total data available for the project but this can change depending upon the number of <a href="../h/#hyperparameter">hyperparameters</a> .i.e. if model has quite many hyperparameters then using large validation set will give better results. Now, whenever the <a href="../a/#accuracy">accuracy</a> of model on validation data is greater than that on training data then the model is said to have generalized well. </p>
<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/training-vs-testing-vs-validation-sets/">https://www.geeksforgeeks.org/training-vs-testing-vs-validation-sets/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#Validation_data_set">https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#Validation_data_set</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="value">Value<a class="headerlink" href="#value" title="Permanent link">#</a></h2>
<p>In <a href="../r/#reinforcement-learning-rl">Reinforcement Learning</a>, ...</p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="value-based-algorithm">Value-Based Algorithm<a class="headerlink" href="#value-based-algorithm" title="Permanent link">#</a></h2>
<p>~ a class of [Reinforcement Learning Algorithms]</p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vanilla">Vanilla<a class="headerlink" href="#vanilla" title="Permanent link">#</a></h2>
<p>The most basic version of a model</p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vanilla-gan">Vanilla GAN<a class="headerlink" href="#vanilla-gan" title="Permanent link">#</a></h2>
<p>The Vanilla GAN is the simplest type of <a href="../g/#generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a> made up of the generator and discriminator , where the classification and generation of images is done by the generator and discriminator internally which both use the <a href="../m/#multilayer-perceptron-mlp-architecture">Multilayer Perceptron (MLP) Architecture</a>. The generator captures the data distribution meanwhile , the discriminator tries to find the probability of the input belonging to a certain class, finally the feedback is sent to both the generator and discriminator after calculating the loss function , and hence the effort to minimize the loss comes into picture.</p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vanishing-gradient-problem">Vanishing Gradient Problem<a class="headerlink" href="#vanishing-gradient-problem" title="Permanent link">#</a></h2>
<p>= a problem that arises because of the loss of information in backpropagation with forward activation function (sigmoid, etc). Vanishing Gradient Problem is a difficulty found in training certain Artificial Neural Networks with gradient based methods (e.g Back Propagation). In particular, this problem makes it really hard to learn and tune the parameters of the earlier layers in the network. This problem becomes worse as the number of layers in the architecture increases. <img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> This is not a fundamental problem with neural networks - it's a problem with gradient based learning methods caused by certain activation functions. Let's try to intuitively understand the problem and the cause behind it. </p>
<ul>
<li>Problem ==&gt; Gradient based methods learn a parameter's value by understanding how a small change in the parameter's value will affect the network's output. If a change in the parameter's value causes very small change in the network's output - the network just can't learn the parameter effectively, which is a problem. This is exactly what's happening in the vanishing gradient problem -- the gradients of the network's output with respect to the parameters in the early layers become extremely small. That's a fancy way of saying that even a large change in the value of parameters for the early layers doesn't have a big effect on the output. Let's try to understand when and why does this problem happen. </li>
<li>Cause ==&gt; Vanishing gradient problem depends on the choice of the activation function. Many common activation functions (e.g sigmoid or tanh) 'squash' their input into a very small output range in a very non-linear fashion. For example, sigmoid maps the real number line onto a "small" range of [0, 1], especially with the function being very flat on most of the number-line. As a result, there are large regions of the input space which are mapped to an extremely small range. In these regions of the input space, even a large change in the input will produce a small change in the output - hence the gradient is small. <img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> This becomes much worse when we stack multiple layers of such non-linearities on top of each other. For instance, first layer will map a large input region to a smaller output region, which will be mapped to an even smaller region by the second layer, which will be mapped to an even smaller region by the third layer and so on. As a result, even a large change in the parameters of the first layer doesn't change the output much.</li>
</ul>
<p>To minimize this problem, you can try to</p>
<ul>
<li>use the ReLU activation function over the sigmoid ones. ReLU which NOT cause a small derivative if &gt;= 0.</li>
<li>reduce the number of layers in the network (minimize total loss by reducing the number of times the signal goes through an activation function), </li>
<li>use batch normalization (don't reach the outer edges of the sigmoid function) = work in a regime (input value range) where the derivative is not zero </li>
<li>change model architecture</li>
<li>and/or use residual networks as they provide residual connections straight to earlier layers. The residual connection directly adds the value at the beginning of the block, x, to the end of the block (F(x)+x). This residual connection doesnt go through activation functions that squashes the derivatives, resulting in a higher overall derivative of the block.</li>
</ul>
<p>More at </p>
<ul>
<li><a href="https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484">https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484</a></li>
<li><a href="https://www.quora.com/What-is-the-vanishing-gradient-problem">https://www.quora.com/What-is-the-vanishing-gradient-problem</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">https://en.wikipedia.org/wiki/Vanishing_gradient_problem</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../b/#batch-normalization">Batch Normalization</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, [Rectified Linear Unit], [Residual Network Model]</p>
<h2 id="variable">Variable<a class="headerlink" href="#variable" title="Permanent link">#</a></h2>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="variable-model">Variable Model<a class="headerlink" href="#variable-model" title="Permanent link">#</a></h2>
<p>See also <a href="./">V</a>, <a href="../b/#bayesian-network">Bayesian Network</a>, <a href="../c/#constraint-satisfaction-problem">Constraint Satisfaction Problem</a>, <a href="../m/#model-type">Model Type</a></p>
<h2 id="variable-type">Variable Type<a class="headerlink" href="#variable-type" title="Permanent link">#</a></h2>
<ul>
<li>Continuous variable</li>
<li>Discrete variable</li>
</ul>
<p>See also <a href="./">V</a>, <a href="../c/#continuous-variable">Continuous Variable</a>, <a href="../d/#discrete-variable">Discrete Variable</a></p>
<h2 id="variance">Variance<a class="headerlink" href="#variance" title="Permanent link">#</a></h2>
<p>~ the amount that the <a href="../p/#prediction">prediction</a> will change if you change the training data</p>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> a lot of flexibility in the model causes high variance.</p>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> models such as <a href="../r/#random-forest">random Forests</a> and <a href="../n/#neural-network">Neural Networks</a> tend to have high variance</p>
<p>How dispersed your predicted values are. Low variance high bias = underfitting. High variance + low bias = overfitting.</p>
<p>See also <a href="./">V</a>, <a href="../b/#bias">Bias</a>, <a href="../o/#overfitting">Overfitting</a>, <a href="../u/#underfitting">Underfitting</a>, </p>
<h2 id="variational-autoencoder-vae">Variational Autoencoder (VAE)<a class="headerlink" href="#variational-autoencoder-vae" title="Permanent link">#</a></h2>
<p>VAEs are autoencoders (encoder + latent space + decoder) that encode inputs as distributions instead of points and whose latent space organisation is regularised by constraining distributions returned by the encoder to be close to a standard Gaussian. <img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> In the Autoencoder bottleneck, you have 2 vectors: (1) the mean vector, (2) the variance vector of the distributions. The input of the decoder is a sample of the distributions.</p>
<p><img alt="" src="../img/v/variational_autoencoder.png" width="100%" /></p>
<ul>
<li>first, the input is encoded as distribution over the latent space</li>
<li>second, a point from the latent space is sampled from that distribution</li>
<li>third, the sampled point is decoded and the reconstruction error can be computed</li>
<li>finally, the reconstruction error is backpropagated through the network </li>
</ul>
<iframe src="https://www.youtube.com/embed/9zKuYvjFFS8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>Why are VAE better than simple autoencoder? ==&gt; making the generative process possible </p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>## VAE LOSS FUNCTION = RECONSTRUCTION LOSS - KL DIVERGENCE
</span></code></pre></div>
<p><img alt="" src="../img/v/variational_autoencoder_loss_function_formula.png" width="100%" /></p>
<div class="admonition warning">
<p class="admonition-title">Backpropagation cannot be done with VAE!</p>
<p>, because of the sampling between the encoder and decoder. The solution is to use the "reparameterization trick</p>
</div>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73 </a></li>
<li><a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">https://jaan.io/what-is-variational-autoencoder-vae-tutorial/</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../a/#autoencoder">Autoencoder</a>, <a href="../a/#autoencoder-type">Autoencoder Type</a>, <a href="../d/#disentangled-variational-autoencoder">Disentangled Variational Autoencoder</a>, <a href="../g/#generative-model">Generative Model</a>, [Kullback-Leibler Divergence], <a href="../l/#latent-space">Latent Space</a>, <a href="./#variational-autoencoder-reparameterization-trick">Variational Autoencoder Reparameterization Trick</a>, [Vector Quantized Variational Autoencoder]</p>
<h2 id="variational-autoencoder-reparameterization-trick">Variational Autoencoder Reparameterization Trick<a class="headerlink" href="#variational-autoencoder-reparameterization-trick" title="Permanent link">#</a></h2>
<p>Because in a variational autoencoder, you sample the output of the encoder to feed the decoder, you cannot use backpropagation. The solution to this is to use this reparametrization trick.</p>
<p><img alt="" src="../img/v/variational_autoencoder_reparametrization_trick.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://youtu.be/rZufA635dq4?t=1401">https://youtu.be/rZufA635dq4?t=1401</a></li>
<li><a href="https://towardsdatascience.com/reparameterization-trick-126062cfd3c3">https://towardsdatascience.com/reparameterization-trick-126062cfd3c3</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../b/#backpropagation">Backpropagation</a>, <a href="../d/#deterministic-node">Deterministic Node</a>, <a href="../s/#stochastic-node">Stochastic Node</a>, <a href="./#variational-autoencoder-vae">Variational Autoencoder</a></p>
<h2 id="vasa-model-family">VASA Model Family<a class="headerlink" href="#vasa-model-family" title="Permanent link">#</a></h2>
<p>Lifelike Audio-Driven Talking Faces Generated in Real Time developed by <a href="../m/#microsoft-company">Microsoft</a></p>
<iframe src="https://www.youtube.com/embed/nQ1EuRF5x30" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2404.10667" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2404.10667">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>VASA-1 <ul>
<li>site - <a href="https://www.microsoft.com/en-us/research/project/vasa-1/">https://www.microsoft.com/en-us/research/project/vasa-1/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2404.10667">https://arxiv.org/abs/2404.10667</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vector">Vector<a class="headerlink" href="#vector" title="Permanent link">#</a></h2>
<p>~ a great way to represent unstructured data!</p>
<p>A 1 column matrix (akak a list!) that represent all the inputs to a neural network or a summary of all the values of the features. Not a <a href="../t/#tensor">tensor</a> (matrix).</p>
<p>See also <a href="./">V</a>, <a href="../d/#dot-product">Dot Product</a>, <a href="../f/#feature">Feature</a>, <a href="../s/#sparse-vector">Sparse Vector</a>, <a href="./#vector-database">Vector Database</a></p>
<h2 id="vector-database">Vector Database<a class="headerlink" href="#vector-database" title="Permanent link">#</a></h2>
<p>~ a great way to store unstructured data</p>
<p>A vector database indexes and stores vector embeddings for fast retrieval and similarity search.</p>
<p>2 types:</p>
<ul>
<li>bolt-on means you have a traditional DB (eg postgresql) and then the company added on a vector index (eg pgvector)</li>
<li>purpose-built = a vector DB that is built oly for vectors</li>
</ul>
<p>Being able to search across images, video, text, audio, and other forms of unstructured data via their content rather than human-generated labels or tags is exactly what vector databases were meant to solve. When combined with powerful machine learning models, vector databases such as Milvus have the ability to revolutionize e-commerce solutions, recommendation systems, computer security, pharmaceuticals, and many other industries. A vector database is a fully managed, no-frills solution for storing, indexing, and searching across a massive dataset of unstructured data that leverages the power of embeddings from machine learning models. A vector database should have the following features:</p>
<ul>
<li>scalability and tunability,</li>
<li>multi-tenancy and data isolation,</li>
<li>a complete suite of APIs, and</li>
<li>an intuitive user interface/administrative console.</li>
</ul>
<p>Databases</p>
<ul>
<li>Vector Databases<ul>
<li>[Chroma] - in-memory ? can also use sqlite backend!</li>
<li><a href="../m/#milvus-vector-database">Milvus</a></li>
<li><a href="../p/#pinecone-company">Pinecone</a></li>
</ul>
</li>
<li>KV store<ul>
<li>[Redis]</li>
</ul>
</li>
<li>Others<ul>
<li>[Qdrant]</li>
<li>[Vespa]</li>
<li>[Weaviate]</li>
</ul>
</li>
</ul>
<p>Alternatives</p>
<ul>
<li>np.array</li>
<li>traditional databases</li>
</ul>
<p>Use cases</p>
<ul>
<li>Long-term memory for LLMs</li>
<li>Semantic search: search based on the meaning or context</li>
<li>Similarity search for text, images, audio, or video data</li>
<li>Recommendation engine (recommend items similar to past purchases)</li>
</ul>
<iframe src="https://www.youtube.com/embed/yM9aKQiJVo0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/klTvEwg3oJ4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/dN0lsF2cvm4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>vector retrieval paper - <a href="https://arxiv.org/abs/2401.09350">https://arxiv.org/abs/2401.09350</a></li>
<li><a href="https://www.pinecone.io/learn/vector-database/">https://www.pinecone.io/learn/vector-database/</a></li>
<li>article(s)A<ul>
<li><a href="https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases">https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases</a></li>
<li>part 1 - <a href="https://arupnanda.medium.com/lowdown-on-vector-databases-a4c8ddcf5d1d">https://arupnanda.medium.com/lowdown-on-vector-databases-a4c8ddcf5d1d</a></li>
<li>part 2 - <a href="https://arupnanda.medium.com/lowdown-on-vector-databases-ec39fe70a17">https://arupnanda.medium.com/lowdown-on-vector-databases-ec39fe70a17</a></li>
<li>part 3 - <a href="https://arupnanda.medium.com/lowdown-on-vector-databases-be93a8dd82d8">https://arupnanda.medium.com/lowdown-on-vector-databases-be93a8dd82d8</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">V</a>, <a href="../r/#representation-space">Representation Space</a>, <a href="./#vector">Vector</a>, <a href="./#vector-search-library">Vector Search Library</a></p>
<h2 id="vector-embedding">Vector Embedding<a class="headerlink" href="#vector-embedding" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li><a href="https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases">https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="./#vector-database">Vector Database</a></p>
<h2 id="vector-indexing">Vector Indexing<a class="headerlink" href="#vector-indexing" title="Permanent link">#</a></h2>
<p>See also <a href="./">V</a>, <a href="./#vector-database">Vector Database</a></p>
<h2 id="vector-quantized-generative-adversarial-network-vq-gan">Vector Quantized Generative Adversarial Network (VQ-GAN)<a class="headerlink" href="#vector-quantized-generative-adversarial-network-vq-gan" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/2hgfbf5OOoI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>colab - <a href="https://colab.research.google.com/drive/1lx9AGsrh7MlyJhK9UrNTK8pYpARnx457?usp=sharing">https://colab.research.google.com/drive/1lx9AGsrh7MlyJhK9UrNTK8pYpARnx457?usp=sharing</a></li>
<li><a href="https://medium.com/nightcafe-creator/vqgan-clip-tutorial-a411402cf3ad">https://medium.com/nightcafe-creator/vqgan-clip-tutorial-a411402cf3ad</a></li>
</ul>
<p>See also <a href="./">V</a>, [Generative Adversarial Network]</p>
<h2 id="vector-quantized-variational-autoencoder-vq-vae">Vector Quantized Variational Autoencoder (VQ-VAE)<a class="headerlink" href="#vector-quantized-variational-autoencoder-vq-vae" title="Permanent link">#</a></h2>
<p>Vector Quantized Variational Autoencoder (VQVAE) extends the standard autoencoder by adding a discrete codebook component to the network. The codebook is basically a list of vectors associated with a corresponding index.</p>
<p><img alt="" src="../img/v/vector_quantized_variational_autoencoder.png" width="100%" /></p>
<p>It is used to quantize the bottleneck of the autoencoder; the output of the encoder network is compared to all the vectors in the codebook, and the codebook vector closest in euclidean distance is fed to the decoder. Mathematically this is written as </p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>z_q(x)=\text{argmin}_i ||z_e(x)-e_i||_2 
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a># where z_e(x) is the encoder vector for some raw input x
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a># e_i is the ith codebook vector
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a># and z_q(x) is the resulting quantized vector that is passed as input to the decoder.
</span></code></pre></div>
<p>This argmin operation is a bit concerning, since it is non-differentiable with respect to the encoder. But in practice everything seems to work fine if you just pass the decoder gradient directly through this operation to the encoder (i.e. set its gradient to 1 wrt the encoder and the quantized codebook vector; and to 0 wrt all other codebook vectors). The decoder is then tasked with reconstructing the input from this quantized vector as in the standard autoencoder formulation.</p>
<p>More at :</p>
<ul>
<li>home - <a href="https://paperswithcode.com/method/vq-vae">https://paperswithcode.com/method/vq-vae</a></li>
<li>paper -  </li>
<li>code - <a href="https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py">https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py</a></li>
<li>sample - <a href="https://sites.google.com/view/videogen">https://sites.google.com/view/videogen</a></li>
<li><a href="https://ml.berkeley.edu/blog/posts/vq-vae/">https://ml.berkeley.edu/blog/posts/vq-vae/</a></li>
</ul>
<p>See also <a href="./">V</a>, [Codebook], <a href="./#variational-autoencoder-vae">Variational Autoencoder</a></p>
<h2 id="vector-retrieval">Vector Retrieval<a class="headerlink" href="#vector-retrieval" title="Permanent link">#</a></h2>
<ul>
<li><a href="../m/#multi-vector-retrieval">Multi-Vector Retrieval</a></li>
<li><a href="../p/#parent-document-retrieval">Parent Document Retrieval</a></li>
</ul>
<object data="https://arxiv.org/pdf/2401.09350" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2401.09350">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2401.09350">https://arxiv.org/abs/2401.09350</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vector-search-library">Vector Search Library<a class="headerlink" href="#vector-search-library" title="Permanent link">#</a></h2>
<p>projects such as FAISS, ScaNN, and HNSW are lightweight ANN libraries rather than managed solutions. The intention of these libraries is to aid in the construction of vector indices  data structures designed to significantly speed up nearest neighbor search for multi-dimensional vectors. If your dataset is small and limited, these libraries can prove to be sufficient for unstructured data processing, even for systems running in production. However, as dataset sizes increase and more users are onboarded, the problem of scale becomes increasingly difficult to solve. Vector databases also operate in a totally different layer of abstraction from vector search libraries - vector databases are full-fledged services, while ANN libraries are meant to be integrated into the application that youre developing. In this sense, ANN libraries are one of the many components that vector databases are built on top of, similar to how Elasticsearch is built on top of Apache Lucene.</p>
<p>See also <a href="./">V</a>, <a href="./#vector">Vector</a>, <a href="./#vector-database">Vector Database</a></p>
<h2 id="vector-search-plugin">Vector Search Plugin<a class="headerlink" href="#vector-search-plugin" title="Permanent link">#</a></h2>
<p>An increasing number of traditional databases and search systems, such as Clickhouse and Elasticsearch, include built-in vector search plugins. Elasticsearch 8.0, for example, includes vector insertion and ANN search functionality that can be called via restful API endpoints. The problem with vector search plugins should be clear as night and day - these solutions do not take a full-stack approach to embedding management and vector search. Instead, these plugins are meant to be enhancements on top of existing architectures, thereby making them limited and unoptimized. Developing an unstructured data application atop a traditional database would be like trying to fit lithium batteries and electric motors inside a frame of a gas-powered car - not a great idea! To illustrate why this is, lets go back to the list of features that a vector database should implement (from the first section). Vector search plugins are missing two of these features - tunability and user-friendly APIs/SDKs.</p>
<p>See also <a href="./">V</a>, <a href="./#vector">Vector</a>, <a href="./#vector-database">Vector Database</a></p>
<h2 id="vector-space">Vector Space<a class="headerlink" href="#vector-space" title="Permanent link">#</a></h2>
<p>In AI and machine learning, a vector space is a mathematical space where vectorsordered sets of numbersrepresent various forms of data. Each <a href="./#vector">vector</a> in this space can represent things like words, images, data points, or even features of a <a href="../d/#dataset">dataset</a>. These spaces are important because they enable algorithms to operate on data in a structured way, making it easier to measure similarity, apply transformations, and find patterns. Here's a deeper look at how theyre used:</p>
<ol>
<li><strong>Representation of Data</strong>: Data in machine learning is often represented in numerical form as vectors. For instance, each point in a dataset can be thought of as a vector where each element represents a feature. In natural language processing (NLP), words are often represented as vectors (like in Word2Vec or GloVe embeddings) that capture semantic meaning based on their relationships to other words.</li>
<li><strong>Operations in Vector Spaces</strong>: In AI, vector spaces allow for mathematical operations like addition, scaling, and finding angles (cosine similarity), which can indicate how similar two vectors are. For example, in NLP, the vectors for "king" and "queen" are often close in the vector space, reflecting their semantic similarity.</li>
<li><strong>Training and Transformations</strong>: Machine learning models operate on data in vector spaces by learning patterns and transformations in this space. For example, in neural networks, layers apply transformations to move data through different vector spaces to identify features and relationships in the data.</li>
<li><strong>Dimensionality Reduction</strong>: Techniques like <a href="../p/#principal-component-analysis-pca">Principal Component Analysis (PCA)</a> and <a href="../t/#t-distributed-stochastic-neighbor-embedding-t-sne-algorithm">t-Distributed Stochastic Neighbor Embedding (t-SNE)</a> reduce high-dimensional vector spaces into lower dimensions, helping visualize data and speed up computations while retaining meaningful structure.</li>
</ol>
<p>So, vector spaces form the foundation of data representation in AI/ML, enabling models to learn, compare, and make decisions based on the relationships between data points within these spaces.</p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vector-space-collision">Vector Space Collision<a class="headerlink" href="#vector-space-collision" title="Permanent link">#</a></h2>
<p>Here is a brief overview of vector space collisions in machine learning:</p>
<ul>
<li>In machine learning models like <a href="../w/#word-embedding">word embeddings</a> or <a href="../r/#recommendation-engine">recommendation engines</a>, items are often represented as vectors in a high-dimensional vector space.</li>
<li>The vectors are positioned in the space such that similar items are close together based on certain metrics like <a href="../c/#cosine-similarity-function">cosine similarity</a>. This allows detecting similarities between items by looking at the distance between their vector representations.</li>
<li>A vector space collision happens when two very different items end up having very similar vector representations. Their embeddings collide and become indistinguishable in the vector space.</li>
<li>This can happen when the vector space is too low-dimensional to capture all the nuanced differences between items. It can also happen when the training data is insufficient or biased.</li>
<li>Collisions are problematic because they cause the model to think very different items are highly similar based on their vector locations. This leads to poor performance on similarity tasks.</li>
<li>Techniques to mitigate collisions include using higher dimensionality, regularization, better sampling strategies, and contrastive training methods that explicitly optimize vectors to be distinct. Overall, collisions indicate limitations in the representational capacity of the vector space.</li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="veo-model-family">Veo Model Family<a class="headerlink" href="#veo-model-family" title="Permanent link">#</a></h2>
<p>~ Sora but built by <a href="../g/#google-company">Google</a></p>
<p>Veo creates videos with realistic motion and high quality output, up to 4K.</p>
<iframe src="https://www.youtube.com/embed/J5VtYdakanM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/-XFTnQBNz50" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>veo 2 - <a href="https://deepmind.google/technologies/veo/veo-2/">https://deepmind.google/technologies/veo/veo-2/</a></li>
<li>co-lead - <a href="https://x.com/shlomifruchter">https://x.com/shlomifruchter</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="viam-model">Viam Model<a class="headerlink" href="#viam-model" title="Permanent link">#</a></h2>
<p>Developed by <a href="../n/#nvidia-company">Nvidia</a>, ...</p>
<p>More at:</p>
<ul>
<li><a href="https://www.viam.com/">https://www.viam.com/</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vicuna-model">Vicuna Model<a class="headerlink" href="#vicuna-model" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li><a href="https://lmsys.org/blog/2023-03-30-vicuna/">https://lmsys.org/blog/2023-03-30-vicuna/</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="video-generator">Video Generator<a class="headerlink" href="#video-generator" title="Permanent link">#</a></h2>
<p>Generate a video from</p>
<ul>
<li>a text prompt</li>
<li>a website</li>
<li>....</li>
</ul>
<p>More at:</p>
<ul>
<li>videogen.app - <a href="https://app.videogen.io/">https://app.videogen.io/</a></li>
<li>runway Gen 2 - <a href="https://research.runwayml.com/gen2">https://research.runwayml.com/gen2</a></li>
<li>SORA - </li>
<li>[Veo] by <a href="../g/#google-company">Google</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="video-joint-embedding-predictive-architecture-v-jepa">Video Joint-Embedding Predictive Architecture (V-JEPA)<a class="headerlink" href="#video-joint-embedding-predictive-architecture-v-jepa" title="Permanent link">#</a></h2>
<p>A method for [Join-Embedding Predictive Architecture (JEPA)] in 02/2024</p>
<p>More at:</p>
<ul>
<li><a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a></li>
<li>code - <a href="https://github.com/facebookresearch/jepa">https://github.com/facebookresearch/jepa</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="video-pre-training-vpt-model">Video Pre-Training (VPT) Model<a class="headerlink" href="#video-pre-training-vpt-model" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/oz5yZc9ULAc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/ODat7kfZ-5k" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2206.11795">https://arxiv.org/abs/2206.11795</a></li>
<li>code - <a href="https://github.com/openai/Video-Pre-Training">https://github.com/openai/Video-Pre-Training</a></li>
<li>blog post - <a href="https://openai.com/blog/vpt/">https://openai.com/blog/vpt/</a></li>
</ul>
<p>See also <a href="./">V</a>, [Inverse Dynamics Model], <a href="../r/#reinforcement-learning-rl">Reinforcement Learning</a></p>
<h2 id="video-restoration">Video Restoration<a class="headerlink" href="#video-restoration" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/sHkc83XA2dY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.youtube.com/@NASS_0/videos">https://www.youtube.com/@NASS_0/videos</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="video-summarization">Video Summarization<a class="headerlink" href="#video-summarization" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li>with claude 3 - <a href="https://github.com/hundredblocks/transcription_demo">https://github.com/hundredblocks/transcription_demo</a><ul>
<li>twitter challenge - <a href="https://twitter.com/karpathy/status/1760740503614836917">https://twitter.com/karpathy/status/1760740503614836917</a></li>
<li>input - <a href="https://www.youtube.com/watch?v=zduSFxRajkE">https://www.youtube.com/watch?v=zduSFxRajkE</a></li>
<li>output - <a href="https://hundredblocks.github.io/transcription_demo/">https://hundredblocks.github.io/transcription_demo/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="video-to-video-vtv-model">Video-To-Video (VTV) Model<a class="headerlink" href="#video-to-video-vtv-model" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/a2yGs8bEeQg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">V</a>, ...</p>
<h2 id="vima-model">VIMA Model<a class="headerlink" href="#vima-model" title="Permanent link">#</a></h2>
<p>A model built by <a href="../n/#nvidia-company">Nvidia</a></p>
<iframe src="https://www.youtube.com/embed/oLBg8aLoQ00" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">V</a>, ...</p>
<h2 id="virtual-assistant">Virtual Assistant<a class="headerlink" href="#virtual-assistant" title="Permanent link">#</a></h2>
<p>All the Alexas, Siris, Google Assistants, and customer support chatbots of the world fall into this category. They use NLP to understand, analyze, and prioritize user questions and requests, and respond to them quickly and correctly.</p>
<p>See also <a href="./">V</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a></p>
<h2 id="virtual-continuum">Virtual Continuum<a class="headerlink" href="#virtual-continuum" title="Permanent link">#</a></h2>
<p>Mixed reality blends both physical and digital worlds. These two realities mark the polar ends of a spectrum known as the virtuality continuum. We refer to this spectrum of realities as the mixed reality spectrum. On one end of the spectrum, we have the physical reality that we as humans exist. On the other end of the spectrum, we have the corresponding digital reality.</p>
<p><img alt="" src="../img/v/virtual_continuum.png" width="&quot;100%" /></p>
<p>See also <a href="./">V</a>, <a href="../a/#augmented-reality-ar">Augmented Reality</a>, <a href="../m/#mixed-reality-mr">Mixed Reality</a>, <a href="./#virtual-reality-vr">Virtual Reality</a></p>
<h2 id="virtual-reality-vr">Virtual Reality (VR)<a class="headerlink" href="#virtual-reality-vr" title="Permanent link">#</a></h2>
<p>VR is a simulated experience that employs pose tracking and 3D near-eye displays to give the user an immersive feel of a virtual world. Applications of virtual reality include entertainment (particularly video games), education (such as medical or military training) and business (such as virtual meetings). Other distinct types of VR-style technology include augmented reality and mixed reality, sometimes referred to as extended reality or XR, although definitions are currently changing due to the nascence of the industry.</p>
<p>Currently, standard virtual reality systems use either virtual reality headsets or multi-projected environments to generate some realistic images, sounds and other sensations that simulate a user's physical presence in a virtual environment. A person using virtual reality equipment is able to look around the artificial world, move around in it, and interact with virtual features or items. The effect is commonly created by VR headsets consisting of a head-mounted display with a small screen in front of the eyes, but can also be created through specially designed rooms with multiple large screens. Virtual reality typically incorporates auditory and video feedback, but may also allow other types of sensory and force feedback through haptic technology.</p>
<p><img alt="" src="../img/v/virtual_reality.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Virtual_reality">https://en.wikipedia.org/wiki/Virtual_reality</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../m/#metaverse">Metaverse</a>, <a href="./#virtual-continuum">Virtual Continuum</a></p>
<h2 id="visual-geometry-group-vgg-model">Visual Geometry Group (VGG) Model<a class="headerlink" href="#visual-geometry-group-vgg-model" title="Permanent link">#</a></h2>
<p>A model developed by VGG in the Department of Engineering Science, University of Oxford. </p>
<ul>
<li>VGG-19 = The number 19 stands for the number of layers with trainable weights. 16 <a href="../c/#convolutional-layer">Convolutional layers</a> with <a href="../m/#max-pooling-layer">Max Pooling</a> and 3 Fully Connected layers. The VGG-19 was trained on the ImageNet challenge (ILSVRC) 1000-class classification task. The network takes a (224, 224, 3) RBG image as the input.</li>
</ul>
<p><img alt="" src="../img/v/visual_geometry_group_19_model.webp" width="100%" /></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">keras.applications.vgg16</span><span class="w"> </span><span class="kn">import</span> <span class="n">VGG16</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="c1"># load the model</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">()</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># summarize the model</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># summarize filter shapes</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>   <span class="c1"># check for convolutional layer</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>   <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>   <span class="k">continue</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>   <span class="c1"># get filter weights</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>   <span class="n">filters</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>   <span class="nb">print</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">filters</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div>
<object data="https://arxiv.org/pdf/1409.1556" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1409.1556">Download PDF</a>.
    </p>
</object>

<p>More at</p>
<ul>
<li>vgg-16 (2015)<ul>
<li>paper - <a href="https://arxiv.org/abs/1409.1556">https://arxiv.org/abs/1409.1556</a></li>
<li>keras - <a href="https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/">https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/</a></li>
</ul>
</li>
<li>articles<ul>
<li><a href="https://medium.com/mlearning-ai/image-detection-using-convolutional-neural-networks-89c9e21fffa3">https://medium.com/mlearning-ai/image-detection-using-convolutional-neural-networks-89c9e21fffa3</a></li>
<li><a href="https://www.image-net.org/challenges/LSVRC/">https://www.image-net.org/challenges/LSVRC/</a></li>
<li><a href="https://becominghuman.ai/what-exactly-does-cnn-see-4d436d8e6e52">https://becominghuman.ai/what-exactly-does-cnn-see-4d436d8e6e52</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">V</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a></p>
<h2 id="vision-arena">Vision Arena<a class="headerlink" href="#vision-arena" title="Permanent link">#</a></h2>
<p>Used for benchmarking multimodal model LLMs in the wild!</p>
<p>More at: </p>
<ul>
<li>site - <a href="https://huggingface.co/spaces/WildVision/vision-arena">https://huggingface.co/spaces/WildVision/vision-arena</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vision-language-model-vlm">Vision-Language Model (VLM)<a class="headerlink" href="#vision-language-model-vlm" title="Permanent link">#</a></h2>
<p>~ Vision language models are models that can learn simultaneously from images and texts to tackle many tasks, from visual question answering to image captioning.</p>
<p>Vision language models are broadly defined as multimodal models that can learn from images and text. They are a type of generative models that take image and text inputs, and generate text outputs. Large vision language models have good zero-shot capabilities, generalize well, and can work with many types of images, including documents, web pages, and more. The use cases include chatting about images, image recognition via instructions, visual question answering, document understanding, image captioning, and others. Some vision language models can also capture spatial properties in an image. These models can output bounding boxes or segmentation masks when prompted to detect or segment a particular subject, or they can localize different entities or answer questions about their relative or absolute positions. Theres a lot of diversity within the existing set of large vision language models, the data they were trained on, how they encode images, and, thus, their capabilities.</p>
<p><img alt="" src="../img/v/vision_language_model.jpg" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://huggingface.co/blog/vlms">https://huggingface.co/blog/vlms</a></li>
<li><a href="https://huggingface.co/blog/vision_language_pretraining">https://huggingface.co/blog/vision_language_pretraining</a></li>
</ul>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="vision-language-pre-training-vlp">Vision-Language Pre-Training (VLP)<a class="headerlink" href="#vision-language-pre-training-vlp" title="Permanent link">#</a></h2>
<object data="https://arxiv.org/pdf/2202.09061" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2202.09061">Download PDF</a>.
    </p>
</object>

<p>More at:
  * paper - <a href="https://arxiv.org/abs/2202.09061">https://arxiv.org/abs/2202.09061</a></p>
<p>See also <a href="./">V</a>, <a href="../m/#masked-vision-modeling-mvm">Masked Vision Modeling</a></p>
<h2 id="vision-transformer-vit-model">Vision Transformer (ViT) Model<a class="headerlink" href="#vision-transformer-vit-model" title="Permanent link">#</a></h2>
<p>Used to caption images! Trained on imagNet. Instead of a tokenizer, uses a feature_extractor (image kernels? No, the whole image).</p>
<p>The Vision Transformer, or ViT, is a model for image classification that employs a Transformer-like architecture over patches of the image. An image is split into fixed-size patches, each of them are then linearly embedded, position embeddings are added, and the resulting sequence of vectors is fed to a standard Transformer encoder. In order to perform classification, the standard approach of adding an extra learnable classification token to the sequence is used.</p>
<p><img alt="" src="../img/v/vision_transformer_architecture.png" width="100%" /></p>
<object data="https://arxiv.org/pdf/2010.11929" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2010.11929">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>papers<ul>
<li>An image is worth 16x16 words - <a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a></li>
<li>Scaling Vision Transformers to 22 Billion Parameters - <a href="https://arxiv.org/abs/2302.05442">https://arxiv.org/abs/2302.05442</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">V</a>, <a href="../f/#feature-extractor">Feature Extractor</a>, <a href="../t/#tokenizer">Tokenizer</a></p>
<h2 id="visual-grounding">Visual Grounding<a class="headerlink" href="#visual-grounding" title="Permanent link">#</a></h2>
<p>Visual grounding is the task of localizing concepts referred to by the language onto an image. </p>
<p>See also <a href="./">V</a>, ...</p>
<h2 id="visual-language-model-vlm">Visual Language Model (VLM)<a class="headerlink" href="#visual-language-model-vlm" title="Permanent link">#</a></h2>
<p>See also <a href="./">V</a>, <a href="../f/#flamingo-model">Flamingo Model</a></p>
<h2 id="visual-simultaneous-localization-and-mapping-vslam-algorithm">Visual Simultaneous Localization And Mapping (VSLAM) Algorithm<a class="headerlink" href="#visual-simultaneous-localization-and-mapping-vslam-algorithm" title="Permanent link">#</a></h2>
<p>Doing <a href="../s/#simultaneous-localization-and-mapping-slam-algorithm">SLAM</a> but instead of using a <a href="../l/#lidar">LIDAR</a> only using video cameras?</p>
<iframe src="https://www.youtube.com/embed/5O8VmDiab3w" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">V</a>, ...</p>
<h2 id="voice-cloning">Voice Cloning<a class="headerlink" href="#voice-cloning" title="Permanent link">#</a></h2>
<p>Models</p>
<ul>
<li><a href="../o/#openvoice-model">OpenVoice</a></li>
<li><a href="../e/#elevenlabs-ai-company">ElevenLabs</a></li>
</ul>
<h2 id="voice-encoder-vocoder">Voice Encoder (Vocoder)<a class="headerlink" href="#voice-encoder-vocoder" title="Permanent link">#</a></h2>
<p>used to transform the generated mel-spectrogram into a waveform.</p>
<iframe src="https://www.youtube.com/embed/2Iq5658IlFc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53">https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../e/#encoder">Encoder</a></p>
<h2 id="voicebox-model">Voicebox Model<a class="headerlink" href="#voicebox-model" title="Permanent link">#</a></h2>
<p>A speech infilling model, where audio style is inferred from audio context, and textual content is specified through transcript</p>
<p>Applications:</p>
<ul>
<li>Denoising - edit audio track, remove non-white noise</li>
<li>Text-only sampling - read from text</li>
<li>Zero-shot TTS - style transfer from existing recording to text</li>
<li>Cross-lingual style transfer - style transfer from existing voice recording with text extracted from another audio recording to a final audio with changed voice</li>
</ul>
<object data="https://arxiv.org/pdf/2306.15687" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2306.15687">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>blog posts<ul>
<li><a href="https://about.fb.com/news/2023/06/introducing-voicebox-ai-for-speech-generation/">https://about.fb.com/news/2023/06/introducing-voicebox-ai-for-speech-generation/</a></li>
<li><a href="https://ai.meta.com/blog/voicebox-generative-ai-model-speech/">https://ai.meta.com/blog/voicebox-generative-ai-model-speech/</a></li>
</ul>
</li>
<li>site - <a href="https://voicebox.metademolab.com/">https://voicebox.metademolab.com/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2306.15687">https://arxiv.org/abs/2306.15687</a> </li>
</ul>
<h2 id="voiceflow-company">VoiceFlow Company<a class="headerlink" href="#voiceflow-company" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/2ZrQfZrpZQw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://www.voiceflow.com/">https://www.voiceflow.com/</a></li>
</ul>
<p>See also <a href="./">V</a>, <a href="../c/#custom-gpt">Custom GPT</a></p>
<h2 id="voxel">Voxel<a class="headerlink" href="#voxel" title="Permanent link">#</a></h2>
<p>A pixel in 3-D</p>
<p>See also <a href="./">V</a>, <a href="../n/#neural-radiance-field-nerf">Neural Radiance Field</a></p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../u/" class="md-footer__link md-footer__link--prev" aria-label="Previous: U">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                U
              </div>
            </div>
          </a>
        
        
          
          <a href="../w/" class="md-footer__link md-footer__link--next" aria-label="Next: W">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                W
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>