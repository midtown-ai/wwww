
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/s/">
      
      
        <link rel="prev" href="../r/">
      
      
        <link rel="next" href="../t/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>S - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="S - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/s.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/s/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="S - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/s.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#s" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              S
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../g/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../l/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    S
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sagemaker" class="md-nav__link">
    <span class="md-ellipsis">
      Sagemaker
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sagemaker-ground-truth" class="md-nav__link">
    <span class="md-ellipsis">
      SageMaker Ground Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sagemaker-neo" class="md-nav__link">
    <span class="md-ellipsis">
      SageMaker Neo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sam-altman-person" class="md-nav__link">
    <span class="md-ellipsis">
      Sam Altman Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample" class="md-nav__link">
    <span class="md-ellipsis">
      Sample
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficiency
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficient-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficient Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficient-rl-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficient RL Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-error" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling Error
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-inefficient-rl-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Inefficient RL Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#satya-nadella-person" class="md-nav__link">
    <span class="md-ellipsis">
      Satya Nadella Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scale-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Scale AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scale-invariant-feature-transform-sift" class="md-nav__link">
    <span class="md-ellipsis">
      Scale-Invariant Feature Transform (SIFT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaled-dot-product-sdp" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled Dot-Product (SDP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaled-dot-product-sdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled Dot-Product (SDP) Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaler" class="md-nav__link">
    <span class="md-ellipsis">
      Scaler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaling-law" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling Law
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seaborn-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Seaborn Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#search-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Search Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#search-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Search Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scene-graph" class="md-nav__link">
    <span class="md-ellipsis">
      Scene Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scienceqa-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      ScienceQA Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scikit-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Scikit Learn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#secure-ai-framework-saif" class="md-nav__link">
    <span class="md-ellipsis">
      Secure AI Framework (SAIF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#segformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Segformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#segment-anything-model-sam" class="md-nav__link">
    <span class="md-ellipsis">
      Segment Anything Model (SAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-consistency-sc-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Consistency (SC) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-destructive-model" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Destructive Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-driving-car" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Driving Car
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-improvement" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Improvement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-instruct-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Instruct Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-organizing-map-som-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Organizing Map (SOM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-play" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Play
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-reflection-sr-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Reflection (SR) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-reflective-retrieval-augmented-generation-sr-rag-system" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Reflective Retrieval Augmented Generation (SR-RAG) System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-supervised-learning-ssl" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning (SSL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-router" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Router
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-search" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-space" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Understanding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Semi-Supervised Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sensitivity-specificity-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity-Specificity Trade-Off
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-bert-sbert-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sentence-BERT (SBERT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Sentence Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentencepiece-tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      SentencePiece Tokenizer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentient-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Sentient AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-seq2seq-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence To Sequence (Seq2Seq) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-seq2seq-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence To Sequence (Seq2Seq) Transformer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequential-data" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serialized-flat-file" class="md-nav__link">
    <span class="md-ellipsis">
      Serialized Flat File
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#service-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Service Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shallow-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Shallow Neural Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shane-legg-person" class="md-nav__link">
    <span class="md-ellipsis">
      Shane Legg Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shannon-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Shannon Entropy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shapley-additive-explanations-shap-value" class="md-nav__link">
    <span class="md-ellipsis">
      Shapley Additive Explanations (SHAP) Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shapley-value" class="md-nav__link">
    <span class="md-ellipsis">
      Shapley Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shifted-window-attention-swa" class="md-nav__link">
    <span class="md-ellipsis">
      Shifted Window Attention (SWA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siamese-network" class="md-nav__link">
    <span class="md-ellipsis">
      Siamese Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siggraph-conference" class="md-nav__link">
    <span class="md-ellipsis">
      SIGGRAPH Conference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-function" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#similarity-metric" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Metric
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simulated-policy-learning-simple-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Simulated Policy Learning (SimPLe) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simulated-to-real-sim2real-performance-gap" class="md-nav__link">
    <span class="md-ellipsis">
      Simulated-To-Real (Sim2Real) Performance Gap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simultaneous-localization-and-mapping-slam-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Simultaneous Localization And Mapping (SLAM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#single-life-reinforcement-learning-slrl" class="md-nav__link">
    <span class="md-ellipsis">
      Single Life Reinforcement Learning (SLRL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siri-virtual-assistant" class="md-nav__link">
    <span class="md-ellipsis">
      Siri Virtual Assistant
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      Skip Connection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skip-gram-model" class="md-nav__link">
    <span class="md-ellipsis">
      Skip-Gram Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skorch-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Skorch Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slicing-function" class="md-nav__link">
    <span class="md-ellipsis">
      Slicing Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slide-deck-generator" class="md-nav__link">
    <span class="md-ellipsis">
      Slide Deck Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slidego" class="md-nav__link">
    <span class="md-ellipsis">
      Slidego
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#small-language-model-slm" class="md-nav__link">
    <span class="md-ellipsis">
      Small Language Model (SLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#snorkel-program" class="md-nav__link">
    <span class="md-ellipsis">
      Snorkel Program
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sobol-search" class="md-nav__link">
    <span class="md-ellipsis">
      Sobol Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#social-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Social Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#social-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Social Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#society-of-mind" class="md-nav__link">
    <span class="md-ellipsis">
      Society Of Mind
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#socratic-method" class="md-nav__link">
    <span class="md-ellipsis">
      Socratic Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#socratic-method-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Socratic Method Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soft-actor-critic-sac-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Soft Actor-Critic (SAC) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softbank-robotics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Softbank Robotics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softmax-function" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softplus-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Softplus Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-10" class="md-nav__link">
    <span class="md-ellipsis">
      Software 1.0
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-20" class="md-nav__link">
    <span class="md-ellipsis">
      Software 2.0
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-development-life-cycle-sdlc" class="md-nav__link">
    <span class="md-ellipsis">
      Software Development Life Cycle (SDLC)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-development-life-cycle-sdlc-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Software Development Life Cycle (SDLC) Agent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sophia-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Sophia Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sora-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sora Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soul-machine-company" class="md-nav__link">
    <span class="md-ellipsis">
      Soul Machine Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sound-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sound Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#source-knowledge" class="md-nav__link">
    <span class="md-ellipsis">
      Source Knowledge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spam-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Spam Detection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#space" class="md-nav__link">
    <span class="md-ellipsis">
      Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-mixture-of-experts-smoe-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Mixture-Of-Experts (SMoE) Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparsity" class="md-nav__link">
    <span class="md-ellipsis">
      Sparsity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparrow-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sparrow Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-activation" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Activation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Matrix
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specificity" class="md-nav__link">
    <span class="md-ellipsis">
      Specificity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spectrogram" class="md-nav__link">
    <span class="md-ellipsis">
      Spectrogram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speech-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Speech Recognition
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speech-to-text-stt-model" class="md-nav__link">
    <span class="md-ellipsis">
      Speech-To-Text (STT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speechx-model" class="md-nav__link">
    <span class="md-ellipsis">
      SpeechX Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spot-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Spot Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#squad-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      SQuAD Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stability-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Stability AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-code-model" class="md-nav__link">
    <span class="md-ellipsis">
      Stable Code Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-diffusion-model" class="md-nav__link">
    <span class="md-ellipsis">
      Stable Diffusion Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#standard-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      Standard Knowledge Distillation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#standardization" class="md-nav__link">
    <span class="md-ellipsis">
      Standardization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-autonomous-helicopter" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford Autonomous Helicopter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-natural-language-inference-snli" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford Natural Language Inference (SNLI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-university" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford University
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state" class="md-nav__link">
    <span class="md-ellipsis">
      State
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-model" class="md-nav__link">
    <span class="md-ellipsis">
      State Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-space" class="md-nav__link">
    <span class="md-ellipsis">
      State Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-space-model-ssm" class="md-nav__link">
    <span class="md-ellipsis">
      State Space Model (SSM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-transition" class="md-nav__link">
    <span class="md-ellipsis">
      State Transition
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-action-pair" class="md-nav__link">
    <span class="md-ellipsis">
      State-Action Pair
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-action-reward-state-action-sarsa-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      State-Action-Reward-State-Action (SARSA) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-of-the-art-sota" class="md-nav__link">
    <span class="md-ellipsis">
      State-Of-The-Art (SOTA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-value-function" class="md-nav__link">
    <span class="md-ellipsis">
      State-Value Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-machine-translation-smt" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Machine Translation (SMT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-model" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Statistics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#steerability" class="md-nav__link">
    <span class="md-ellipsis">
      Steerability
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Step Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-back-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Step-Back Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stereo-vision" class="md-nav__link">
    <span class="md-ellipsis">
      Stereo Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stochastic-gradient-descent-sgd-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Gradient Descent (SGD) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stochastic-node" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Node
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#streamlit" class="md-nav__link">
    <span class="md-ellipsis">
      Streamlit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stretch-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Stretch Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#strong-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Strong AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#strong-learner" class="md-nav__link">
    <span class="md-ellipsis">
      Strong Learner
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-data" class="md-nav__link">
    <span class="md-ellipsis">
      Structured Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      Structured Pruning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-state-space-sequence-s4-model" class="md-nav__link">
    <span class="md-ellipsis">
      Structured State Space Sequence (S4) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#style-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Style GAN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sub-symbolic-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Sub-Symbolic AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#subsampling" class="md-nav__link">
    <span class="md-ellipsis">
      Subsampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sundar-pichai-person" class="md-nav__link">
    <span class="md-ellipsis">
      Sundar Pichai Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#suno-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Suno AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#suno-ai-model" class="md-nav__link">
    <span class="md-ellipsis">
      Suno AI Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#super-resolution-gan-srgan" class="md-nav__link">
    <span class="md-ellipsis">
      Super Resolution GAN (SRGAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#superalignment" class="md-nav__link">
    <span class="md-ellipsis">
      Superalignment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#superglue-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      SuperGLUE Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supertranslate-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Supertranslate AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-feedback" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Feedback
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-fine-tuning-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Fine-Tuning (SFT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervisor" class="md-nav__link">
    <span class="md-ellipsis">
      Supervisor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supply-chain-vulnerability" class="md-nav__link">
    <span class="md-ellipsis">
      Supply Chain Vulnerability
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machine-svm" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector Machine (SVM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#surrogate-model" class="md-nav__link">
    <span class="md-ellipsis">
      Surrogate Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#swarm-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Swarm AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#switch-transformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Switch Transformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#symbolic-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Symbolic AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synapse" class="md-nav__link">
    <span class="md-ellipsis">
      Synapse
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synaptic-strength" class="md-nav__link">
    <span class="md-ellipsis">
      Synaptic Strength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synchronous-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Synchronous Neural Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthesia-company" class="md-nav__link">
    <span class="md-ellipsis">
      Synthesia Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthesized-variable" class="md-nav__link">
    <span class="md-ellipsis">
      Synthesized Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-data" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-data-privacy" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Data Privacy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-feature" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Feature
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-users-company" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Users Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthid" class="md-nav__link">
    <span class="md-ellipsis">
      SynthID
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#system-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      System Prompt
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../v/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#sagemaker" class="md-nav__link">
    <span class="md-ellipsis">
      Sagemaker
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sagemaker-ground-truth" class="md-nav__link">
    <span class="md-ellipsis">
      SageMaker Ground Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sagemaker-neo" class="md-nav__link">
    <span class="md-ellipsis">
      SageMaker Neo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sam-altman-person" class="md-nav__link">
    <span class="md-ellipsis">
      Sam Altman Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample" class="md-nav__link">
    <span class="md-ellipsis">
      Sample
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficiency
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficient-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficient Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-efficient-rl-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Efficient RL Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-error" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling Error
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-inefficient-rl-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Inefficient RL Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#satya-nadella-person" class="md-nav__link">
    <span class="md-ellipsis">
      Satya Nadella Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scale-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Scale AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scale-invariant-feature-transform-sift" class="md-nav__link">
    <span class="md-ellipsis">
      Scale-Invariant Feature Transform (SIFT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaled-dot-product-sdp" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled Dot-Product (SDP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaled-dot-product-sdp-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled Dot-Product (SDP) Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaler" class="md-nav__link">
    <span class="md-ellipsis">
      Scaler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scaling-law" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling Law
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seaborn-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Seaborn Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#search-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Search Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#search-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Search Problem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scene-graph" class="md-nav__link">
    <span class="md-ellipsis">
      Scene Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scienceqa-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      ScienceQA Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scikit-learn" class="md-nav__link">
    <span class="md-ellipsis">
      Scikit Learn
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#secure-ai-framework-saif" class="md-nav__link">
    <span class="md-ellipsis">
      Secure AI Framework (SAIF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#segformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Segformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#segment-anything-model-sam" class="md-nav__link">
    <span class="md-ellipsis">
      Segment Anything Model (SAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-consistency-sc-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Consistency (SC) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-destructive-model" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Destructive Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-driving-car" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Driving Car
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-improvement" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Improvement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-instruct-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Instruct Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-organizing-map-som-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Organizing Map (SOM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-play" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Play
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-reflection-sr-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Reflection (SR) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-reflective-retrieval-augmented-generation-sr-rag-system" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Reflective Retrieval Augmented Generation (SR-RAG) System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-supervised-learning-ssl" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning (SSL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-router" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Router
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-search" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Segmentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-space" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semantic-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Understanding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Semi-Supervised Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sensitivity-specificity-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity-Specificity Trade-Off
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-bert-sbert-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sentence-BERT (SBERT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Sentence Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentencepiece-tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      SentencePiece Tokenizer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentient-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Sentient AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-seq2seq-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence To Sequence (Seq2Seq) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-seq2seq-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence To Sequence (Seq2Seq) Transformer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequential-data" class="md-nav__link">
    <span class="md-ellipsis">
      Sequential Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serialized-flat-file" class="md-nav__link">
    <span class="md-ellipsis">
      Serialized Flat File
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#service-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Service Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shallow-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Shallow Neural Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shane-legg-person" class="md-nav__link">
    <span class="md-ellipsis">
      Shane Legg Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shannon-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Shannon Entropy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shapley-additive-explanations-shap-value" class="md-nav__link">
    <span class="md-ellipsis">
      Shapley Additive Explanations (SHAP) Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shapley-value" class="md-nav__link">
    <span class="md-ellipsis">
      Shapley Value
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shifted-window-attention-swa" class="md-nav__link">
    <span class="md-ellipsis">
      Shifted Window Attention (SWA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siamese-network" class="md-nav__link">
    <span class="md-ellipsis">
      Siamese Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siggraph-conference" class="md-nav__link">
    <span class="md-ellipsis">
      SIGGRAPH Conference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sigmoid-function" class="md-nav__link">
    <span class="md-ellipsis">
      Sigmoid Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#similarity-metric" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Metric
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      Similarity Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simulated-policy-learning-simple-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Simulated Policy Learning (SimPLe) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simulated-to-real-sim2real-performance-gap" class="md-nav__link">
    <span class="md-ellipsis">
      Simulated-To-Real (Sim2Real) Performance Gap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simultaneous-localization-and-mapping-slam-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Simultaneous Localization And Mapping (SLAM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#single-life-reinforcement-learning-slrl" class="md-nav__link">
    <span class="md-ellipsis">
      Single Life Reinforcement Learning (SLRL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#singular-value-decomposition-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Singular Value Decomposition (SVD)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#siri-virtual-assistant" class="md-nav__link">
    <span class="md-ellipsis">
      Siri Virtual Assistant
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      Skip Connection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skip-gram-model" class="md-nav__link">
    <span class="md-ellipsis">
      Skip-Gram Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skorch-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Skorch Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slicing-function" class="md-nav__link">
    <span class="md-ellipsis">
      Slicing Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slide-deck-generator" class="md-nav__link">
    <span class="md-ellipsis">
      Slide Deck Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slidego" class="md-nav__link">
    <span class="md-ellipsis">
      Slidego
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#small-language-model-slm" class="md-nav__link">
    <span class="md-ellipsis">
      Small Language Model (SLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#snorkel-program" class="md-nav__link">
    <span class="md-ellipsis">
      Snorkel Program
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sobol-search" class="md-nav__link">
    <span class="md-ellipsis">
      Sobol Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#social-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Social Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#social-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Social Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#society-of-mind" class="md-nav__link">
    <span class="md-ellipsis">
      Society Of Mind
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#socratic-method" class="md-nav__link">
    <span class="md-ellipsis">
      Socratic Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#socratic-method-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Socratic Method Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soft-actor-critic-sac-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Soft Actor-Critic (SAC) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softbank-robotics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Softbank Robotics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softmax-function" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softplus-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Softplus Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-10" class="md-nav__link">
    <span class="md-ellipsis">
      Software 1.0
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-20" class="md-nav__link">
    <span class="md-ellipsis">
      Software 2.0
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-development-life-cycle-sdlc" class="md-nav__link">
    <span class="md-ellipsis">
      Software Development Life Cycle (SDLC)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software-development-life-cycle-sdlc-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Software Development Life Cycle (SDLC) Agent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sophia-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Sophia Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sora-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sora Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soul-machine-company" class="md-nav__link">
    <span class="md-ellipsis">
      Soul Machine Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sound-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sound Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#source-knowledge" class="md-nav__link">
    <span class="md-ellipsis">
      Source Knowledge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spam-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Spam Detection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#space" class="md-nav__link">
    <span class="md-ellipsis">
      Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-mixture-of-experts-smoe-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Mixture-Of-Experts (SMoE) Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparsity" class="md-nav__link">
    <span class="md-ellipsis">
      Sparsity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparrow-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sparrow Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-activation" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Activation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Matrix
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-model" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparse-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specificity" class="md-nav__link">
    <span class="md-ellipsis">
      Specificity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spectrogram" class="md-nav__link">
    <span class="md-ellipsis">
      Spectrogram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speech-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Speech Recognition
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speech-to-text-stt-model" class="md-nav__link">
    <span class="md-ellipsis">
      Speech-To-Text (STT) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speechx-model" class="md-nav__link">
    <span class="md-ellipsis">
      SpeechX Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spot-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Spot Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#squad-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      SQuAD Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stability-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Stability AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-code-model" class="md-nav__link">
    <span class="md-ellipsis">
      Stable Code Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-diffusion-model" class="md-nav__link">
    <span class="md-ellipsis">
      Stable Diffusion Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#standard-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      Standard Knowledge Distillation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#standardization" class="md-nav__link">
    <span class="md-ellipsis">
      Standardization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-autonomous-helicopter" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford Autonomous Helicopter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-natural-language-inference-snli" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford Natural Language Inference (SNLI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanford-university" class="md-nav__link">
    <span class="md-ellipsis">
      Stanford University
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state" class="md-nav__link">
    <span class="md-ellipsis">
      State
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-model" class="md-nav__link">
    <span class="md-ellipsis">
      State Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-space" class="md-nav__link">
    <span class="md-ellipsis">
      State Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-space-model-ssm" class="md-nav__link">
    <span class="md-ellipsis">
      State Space Model (SSM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-transition" class="md-nav__link">
    <span class="md-ellipsis">
      State Transition
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-action-pair" class="md-nav__link">
    <span class="md-ellipsis">
      State-Action Pair
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-action-reward-state-action-sarsa-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      State-Action-Reward-State-Action (SARSA) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-of-the-art-sota" class="md-nav__link">
    <span class="md-ellipsis">
      State-Of-The-Art (SOTA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#state-value-function" class="md-nav__link">
    <span class="md-ellipsis">
      State-Value Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-machine-translation-smt" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Machine Translation (SMT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-model" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Statistics
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#steerability" class="md-nav__link">
    <span class="md-ellipsis">
      Steerability
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Step Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-back-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Step-Back Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stereo-vision" class="md-nav__link">
    <span class="md-ellipsis">
      Stereo Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stochastic-gradient-descent-sgd-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Gradient Descent (SGD) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stochastic-node" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Node
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#streamlit" class="md-nav__link">
    <span class="md-ellipsis">
      Streamlit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stretch-robot" class="md-nav__link">
    <span class="md-ellipsis">
      Stretch Robot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#strong-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Strong AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#strong-learner" class="md-nav__link">
    <span class="md-ellipsis">
      Strong Learner
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-data" class="md-nav__link">
    <span class="md-ellipsis">
      Structured Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      Structured Pruning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#structured-state-space-sequence-s4-model" class="md-nav__link">
    <span class="md-ellipsis">
      Structured State Space Sequence (S4) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#style-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Style GAN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sub-symbolic-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Sub-Symbolic AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#subsampling" class="md-nav__link">
    <span class="md-ellipsis">
      Subsampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sundar-pichai-person" class="md-nav__link">
    <span class="md-ellipsis">
      Sundar Pichai Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#suno-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Suno AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#suno-ai-model" class="md-nav__link">
    <span class="md-ellipsis">
      Suno AI Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#super-resolution-gan-srgan" class="md-nav__link">
    <span class="md-ellipsis">
      Super Resolution GAN (SRGAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#superalignment" class="md-nav__link">
    <span class="md-ellipsis">
      Superalignment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#superglue-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      SuperGLUE Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supertranslate-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Supertranslate AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-feedback" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Feedback
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-fine-tuning-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Fine-Tuning (SFT)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supervisor" class="md-nav__link">
    <span class="md-ellipsis">
      Supervisor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supply-chain-vulnerability" class="md-nav__link">
    <span class="md-ellipsis">
      Supply Chain Vulnerability
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machine-svm" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector Machine (SVM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#surrogate-model" class="md-nav__link">
    <span class="md-ellipsis">
      Surrogate Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#swarm-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Swarm AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#switch-transformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      Switch Transformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#symbolic-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Symbolic AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synapse" class="md-nav__link">
    <span class="md-ellipsis">
      Synapse
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synaptic-strength" class="md-nav__link">
    <span class="md-ellipsis">
      Synaptic Strength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synchronous-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Synchronous Neural Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthesia-company" class="md-nav__link">
    <span class="md-ellipsis">
      Synthesia Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthesized-variable" class="md-nav__link">
    <span class="md-ellipsis">
      Synthesized Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-data" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-data-privacy" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Data Privacy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-feature" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Feature
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthetic-users-company" class="md-nav__link">
    <span class="md-ellipsis">
      Synthetic Users Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#synthid" class="md-nav__link">
    <span class="md-ellipsis">
      SynthID
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#system-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      System Prompt
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="s">S<a class="headerlink" href="#s" title="Permanent link">#</a></h1>
<h2 id="sagemaker">Sagemaker<a class="headerlink" href="#sagemaker" title="Permanent link">#</a></h2>
<p>See <a href="../a/#aws-sagemaker-service">AWS Sagemaker</a></p>
<h2 id="sagemaker-ground-truth">SageMaker Ground Truth<a class="headerlink" href="#sagemaker-ground-truth" title="Permanent link">#</a></h2>
<p>Used for labelling the data by machines, internal employees, mechanical turk, or 3rd party partner.</p>
<h2 id="sagemaker-neo">SageMaker Neo<a class="headerlink" href="#sagemaker-neo" title="Permanent link">#</a></h2>
<p>~ compiler of ML models before they are distributed to the endpoint. Compatible with TensorFlow, XGBoost, MxNET, PyTorch, ... Allow the model to run without any framework, this reduce the memory footprint on the device (at the edge) by 100x, while improving the performance by x2.</p>
<h2 id="sam-altman-person">Sam Altman Person<a class="headerlink" href="#sam-altman-person" title="Permanent link">#</a></h2>
<p>Sam Altman is the CEO of OpenAI, the buzzy AI firm he cofounded with Elon Musk.
 Before that, he was well known in Silicon Valley as president of startup accelerator Y-Combinator.
 Here's how the serial entrepreneur got his start  and ended up helming one of today's most-watched companies.</p>
<iframe src="https://www.youtube.com/embed/L_Guz73e6fw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1">https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1</a></li>
<li><a href="http://startupclass.samaltman.com/">http://startupclass.samaltman.com/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sample">Sample<a class="headerlink" href="#sample" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../d/#distribution">Distribution</a></p>
<h2 id="sample-efficiency">Sample Efficiency<a class="headerlink" href="#sample-efficiency" title="Permanent link">#</a></h2>
<p>How much is learned from each sample.</p>
<p>Relate to the impact of training the model with more data. Should you get more data, more compute, or more weights/parameters?</p>
<p>Sample Efficiency is a measure of how much experience an <a href="../a/#agent">agent</a> or an [algorithm] needs to generate in an environment during training in order to reach a certain level of performance. It is related to how well the agent or the algorithm can learn from the data it collects. A more sample efficient method needs fewer data or observations than a less sample efficient one to achieve the same or better results. Sample efficiency is important for <a href="../r/#reinforcement-learning-rl">reinforcement learning</a>, where data collection can be costly, time-consuming, or limited. Importance sampling is a technique that can be used to improve sample efficiency by reweighting the data according to their relevance or importance for the [learning objective]. For example, in <a href="../o/#off-policy-learning">off-policy learning</a>, where the agent learns from data generated by a different policy than the one it follows, importance sampling can be used to adjust the estimates of the value function or the policy gradient based on the ratio of the target policy and the behavior policy probabilities.</p>
<p>See also <a href="./">S</a>, <a href="../l/#learning-velocity">Learning Velocity</a>, <a href="../n/#neural-scaling-law">Neural Scaling Law</a></p>
<h2 id="sample-efficient-algorithm">Sample Efficient Algorithm<a class="headerlink" href="#sample-efficient-algorithm" title="Permanent link">#</a></h2>
<ul>
<li>[Sample Efficient RL Algorithms]</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sample-efficient-rl-algorithm">Sample Efficient RL Algorithm<a class="headerlink" href="#sample-efficient-rl-algorithm" title="Permanent link">#</a></h2>
<p>Here are some sample efficient reinforcement learning algorithms:</p>
<ul>
<li><a href="../m/#model-based-reinforcement-learning">Model-based RL</a> - Learn model of environment to simulate experiences. Examples: <a href="../d/#dyna-model">Dyna</a>, <a href="../p/#probabilistic-inference-for-learning-control-pilco-model">PILCO</a>.</li>
<li><a href="../h/#hierarchical-rl">Hierarchical RL</a> - Learn policies at different levels of temporal abstraction over options. Accelerates learning.</li>
<li><a href="../t/#transfer-learning">Transfer Learning</a> - Leverage knowledge from source tasks when learning target tasks. Jumpstarts learning.</li>
<li><a href="../f/#few-shot-rl">Few-shot RL</a> - Learn new tasks from only a few examples. Leverages prior knowledge.</li>
<li><a href="../c/#curiosity-driven-rl">Curiosity-Driven RL</a> - Exploration bonuses for novel or uncertain states to guide experience collection.</li>
<li><a href="../p/#prioritized-experience-replay">Prioritized Experience Replay</a> - Replay important transitions more frequently for efficient learning.</li>
<li><a href="../d/#distributional-reinforcement-learning">Distributional RL</a> - Learn value distribution rather than just mean. Improves extrapolation.</li>
<li><a href="../u/#unsupervised-pre-training">Unsupervised pre-training</a> - Pretrain representation using unsupervised learning before RL fine-tuning.</li>
<li><a href="../r/#reward-shaping">Reward shaping</a> - Carefully shape reward function to accelerate learning the desired behavior.</li>
<li><a href="../g/#goal-conditioned-rl">Goal-conditioned RL</a> - Train universal policies conditioned on goals. Generalizes to new goals.</li>
<li><a href="../h/#hindsight-experience-replay">Hindsight experience replay</a> - Learn from failed episodes by pretending any state reached was the goal.</li>
<li><a href="../m/#meta-learning">Meta-learning</a> - Learn how to quickly adapt to new tasks within similar domains.</li>
</ul>
<p>In general, any method that enables effective generalization, transfers knowledge across tasks, or reduces the samples needed through simulation, pre-training, or guided exploration will improve sample efficiency.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sampling-error">Sampling Error<a class="headerlink" href="#sampling-error" title="Permanent link">#</a></h2>
<p>Sampling errors occur when a sample of data is used to estimate a population parameter, such as the mean or proportion. These errors occur because the sample may not be a perfect representation of the population, and there will be some degree of difference between the sample statistic and the true population parameter. There are two types of sampling errors:
  * Random sampling error: Random sampling error occurs due to chance. It occurs because each sample of data will have some degree of variation from the population. The larger the sample, the smaller the random sampling error is likely to be.
  * Systematic sampling error: Systematic sampling error occurs due to bias in the sampling process. Bias can be introduced if the sample is not selected at random, or if the sample is not representative of the population.
 Both of these types of sampling errors can be reduced by using a larger sample size or by using a more representative sample. However, it is important to note that it is never possible to completely eliminate sampling error.</p>
<p>See also <a href="./">S</a>, <a href="../r/#resampling-method">Resampling Method</a>, [Sampling]</p>
<h2 id="sample-inefficient-rl-algorithm">Sample Inefficient RL Algorithm<a class="headerlink" href="#sample-inefficient-rl-algorithm" title="Permanent link">#</a></h2>
<p>Sample inefficiency refers to reinforcement learning algorithms that require a large number of interactions with the environment to learn an effective policy. Some key characteristics:</p>
<ul>
<li>Sample inefficient algorithms need more samples (steps through the environment) to reach a good policy.</li>
<li>This is problematic for real-world environments where samples are expensive or limited.</li>
<li>Common causes are lack of generalization, not reusing past experience, or inability to plan ahead.</li>
<li>Random exploration without exploiting past knowledge wastes samples.</li>
<li>[Deep reinforcement learning] methods like <a href="../d/#deep-q-network-dqn">DQN</a> can be sample inefficient due to dependency on massive experience replays.</li>
<li>[Evolution strategies] are considered sample inefficient as random mutations ignore past fitness.</li>
<li><a href="../m/#model-based-reinforcement-learning">Model-based RL</a> can improve sample efficiency by learning environment models for planning.</li>
<li>Hierarchy, abstraction, <a href="../t/#transfer-learning">transfer learning</a>, and curiosity can improve sample efficiency.</li>
<li>Key metrics are total samples to threshold performance, samples per <a href="../e/#epoch">epoch</a>, and computational cost per sample.</li>
<li><a href="./#sample-efficiency">Sample efficiency</a> is crucial for real-world complex tasks like robotics where environment samples are slow and expensive.</li>
</ul>
<p>In summary, sample inefficient RL algorithms require large amounts of environment interaction to find performant policies. Improving sample efficiency remains an active research area in RL.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sampling-method">Sampling Method<a class="headerlink" href="#sampling-method" title="Permanent link">#</a></h2>
<ul>
<li>Bayesian Optimizatin Sampling Method</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../b/#bayesian-optimization-sampling-method">Bayesian Optimization Sampling Method</a></p>
<h2 id="satya-nadella-person">Satya Nadella Person<a class="headerlink" href="#satya-nadella-person" title="Permanent link">#</a></h2>
<p>CEO of <a href="../m/#microsoft-company">Microsoft</a></p>
<iframe src="https://www.youtube.com/embed/9NtsnzRFJ_o" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, ...</p>
<h2 id="scale-ai-company">Scale AI Company<a class="headerlink" href="#scale-ai-company" title="Permanent link">#</a></h2>
<p>Focus on augmenting the data with metadata/labels</p>
<p>More at:</p>
<ul>
<li><a href="https://scale.com/">https://scale.com/</a></li>
<li><a href="https://pitchbook.com/profiles/company/163154-17">https://pitchbook.com/profiles/company/163154-17</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="scale-invariant-feature-transform-sift">Scale-Invariant Feature Transform (SIFT)<a class="headerlink" href="#scale-invariant-feature-transform-sift" title="Permanent link">#</a></h2>
<p>Inspired by the <a href="../n/#neocognitron">neocognitron</a></p>
<p>For any object in an image, interesting points on the object can be extracted to provide a "feature description" of the object. This description, extracted from a training image, can then be used to identify the object when attempting to locate the object in a test image containing many other objects. To perform reliable recognition, it is important that the features extracted from the training image be detectable even under changes in image scale, noise and illumination. Such points usually lie on high-contrast regions of the image, such as object edges.</p>
<p>Another important characteristic of these features is that the relative positions between them in the original scene shouldn't change from one image to another. For example, if only the four corners of a door were used as features, they would work regardless of the door's position; but if points in the frame were also used, the recognition would fail if the door is opened or closed. Similarly, features located in articulated or flexible objects would typically not work if any change in their internal geometry happens between two images in the set being processed. However, in practice SIFT detects and uses a much larger number of features from the images, which reduces the contribution of the errors caused by these local variations in the average error of all feature matching errors.</p>
<iframe src="https://www.youtube.com/embed/6oLRdnQI_2w" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">https://en.wikipedia.org/wiki/Scale-invariant_feature_transform</a></li>
<li>&lt;!&gt; not this SIFT method! - <a href="https://oer.pressbooks.pub/collegeresearch/chapter/the-sift-method/">https://oer.pressbooks.pub/collegeresearch/chapter/the-sift-method/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="scaled-dot-product-sdp">Scaled Dot-Product (SDP)<a class="headerlink" href="#scaled-dot-product-sdp" title="Permanent link">#</a></h2>
<ul>
<li>Scaled =&gt; kind of a normalization</li>
<li>Dot-product = kind of similarity measure (cosine similarity)</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="scaled-dot-product-sdp-attention">Scaled Dot-Product (SDP) Attention<a class="headerlink" href="#scaled-dot-product-sdp-attention" title="Permanent link">#</a></h2>
<ul>
<li>attention = kind of a weighted sum, with attention weights (tensor)</li>
</ul>
<iframe src="https://www.youtube.com/embed/PFczJ6NR5rY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, <a href="./#self-attention">Self-Attention</a></p>
<h2 id="scaler">Scaler<a class="headerlink" href="#scaler" title="Permanent link">#</a></h2>
<p>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected. THe standard scaler does the following:
  * Standardize features by removing the mean and scaling to unit variance.
  * The standard score of a sample x is calculated as:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>z = (x - u) / s
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>u == mean of discrete random variable
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>u = sum(x) / number_of_samples
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>v == variance of discrete random variable in training sample
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>v = 1 / number_of_sample * ( sum_of_each_sample ( sample_value - mean) ^ 2) )
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>s == standard deviation of discrete random variable in random sample
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>s = sqrt(v)
</span></code></pre></div>
<p>Example in code</p>
<div class="language-pycon highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="go">StandardScaler()</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">mean_</span><span class="p">)</span>                       <span class="c1"># (0 + 0 + 1 + 1 ) / 4 = 0.5</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="go">[0.5 0.5]</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="go">                                              # the variance is the average of each point from the mean.</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">var_</span><span class="p">)</span>                        <span class="c1"># [ (0-0.5)^2 + (0-0.5)^2 + (1-0.5)^2 + (1-0.5)^2 ] / 4 =  (0.5)^2 = 0.25</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="go">[0.25, 0.25]</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="go">[[-1. -1.]                                    # 0 --&gt; (0 - 0.5) / sqrt(0.25) = -1</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="go"> [-1. -1.]</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="go"> [ 1.  1.]                                    # 1 --&gt; (1 - 0.5) / sqrt(0.25) = 1</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="go"> [ 1.  1.]</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="go">[[3. 3.]]                                     # 2 --&gt; (2 - 0.5) / sqrt(0.25) = 3</span>
</span></code></pre></div>
<p>See also <a href="./">S</a>, <a href="../e/#estimator">Estimator</a></p>
<h2 id="scaling-law">Scaling Law<a class="headerlink" href="#scaling-law" title="Permanent link">#</a></h2>
<p>See <a href="../n/#neural-scaling-law">Neural Scaling Law</a></p>
<h2 id="seaborn-python-module">Seaborn Python Module<a class="headerlink" href="#seaborn-python-module" title="Permanent link">#</a></h2>
<p>A <a href="../p/#python-module">python module</a> for Statistical Data Visualization</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="search-algorithm">Search Algorithm<a class="headerlink" href="#search-algorithm" title="Permanent link">#</a></h2>
<p>Problems</p>
<ul>
<li>[Traveling Salesman]</li>
</ul>
<p>Algorithm</p>
<ul>
<li>A*</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../o/#objective-function">Objective Function</a></p>
<h2 id="search-problem">Search Problem<a class="headerlink" href="#search-problem" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="./#state-model">State Model</a></p>
<h2 id="scene-graph">Scene Graph<a class="headerlink" href="#scene-graph" title="Permanent link">#</a></h2>
<p>Do entity extract + add relationship. Can be built based from text or images.</p>
<p>See also <a href="./">S</a>, <a href="../e/#entity-extraction">Entity Extraction</a>, [Graph Neural Network], [Knowledge Graph], <a href="../r/#relation-extraction">Relation Extraction</a></p>
<h2 id="scienceqa-dataset">ScienceQA Dataset<a class="headerlink" href="#scienceqa-dataset" title="Permanent link">#</a></h2>
<p>ScienceQA, in contrast to previous datasets, has richer domain diversity from three subjects: natural science, language science, and social science. ScienceQA features 26 topics, 127 categories, and 379 skills that cover a wide range of domains.</p>
<object data="https://lupantech.github.io/papers/neurips22_scienceqa.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://lupantech.github.io/papers/neurips22_scienceqa.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://github.com/lupantech/ScienceQA">https://github.com/lupantech/ScienceQA</a></li>
<li>explore - <a href="https://scienceqa.github.io/explore.html">https://scienceqa.github.io/explore.html</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="scikit-learn">Scikit Learn<a class="headerlink" href="#scikit-learn" title="Permanent link">#</a></h2>
<p>Since its release in 2007, scikit-learn has become one of the most popular machine learning libraries. scikit-learn provides algorithms for machine learning tasks including classification, regression, dimensionality reduction, and clustering. It also provides modules for pre-processing data, extracting features, optimizing hyperparameters, and evaluating models. scikit-learn is built on the popular Python libraries NumPy and SciPy. NumPy extends Python to support efficient operations on large arrays and multi-dimensional matrices. SciPy provides modules for scientific computing. The visualization library matplotlib is often used in conjunction with scikit-learn.</p>
<p>See also <a href="./">S</a>, <a href="../d/#dataset">Dataset</a></p>
<h2 id="secure-ai-framework-saif">Secure AI Framework (SAIF)<a class="headerlink" href="#secure-ai-framework-saif" title="Permanent link">#</a></h2>
<p>~ a security framework for AI models developed by <a href="../g/#google-company">Google</a> </p>
<p>The potential of AI, especially generative AI, is immense. As innovation moves forward, the industry needs security standards for building and deploying AI responsibly. Thats why we introduced the Secure AI Framework (SAIF), a conceptual framework to secure AI systems.</p>
<p>SAIF is designed to address top-of-mind concerns for security professionals, such as AI/ML model risk management, security, and privacy  helping to ensure that when AI models are implemented, they are secure-by-default.</p>
<ul>
<li>Expand strong security foundations to the AI ecosystem</li>
<li>Extend detection and response to bring AI into an organizations threat universe</li>
<li>Automate defenses to keep pace with existing and new threats</li>
<li>Harmonize platform level controls to ensure consistent security across the organization</li>
<li>Adapt controls to adjust mitigations and create faster feedback loops for AI deployment</li>
<li>Contextualize AI system risks in surrounding business processes</li>
</ul>
<object data="https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://services.google.com/fh/files/blogs/google_secure_ai_framework_summary.pdf">Download PDF</a>.
    </p>
</object>

<object data="https://services.google.com/fh/files/blogs/google_secure_ai_framework_approach.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://services.google.com/fh/files/blogs/google_secure_ai_framework_approach.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://safety.google/cybersecurity-advancements/saif/">https://safety.google/cybersecurity-advancements/saif/</a></li>
<li>announcement - <a href="https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/">https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="segformer-model">Segformer Model<a class="headerlink" href="#segformer-model" title="Permanent link">#</a></h2>
<p>Semantic image segmentation with transformers. Developed by <a href="../n/#nvidia-company">Nvidia</a></p>
<iframe src="https://www.youtube.com/embed/J0MoRQzZe8U" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/cgq2d_HkfnM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2105.15203" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2105.15203">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://github.com/NVlabs/SegFormer">https://github.com/NVlabs/SegFormer</a></li>
<li>paper - <a href="https://arxiv.org/abs/2105.15203">https://arxiv.org/abs/2105.15203</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../o/#openmmlab">OpenMMLab</a></p>
<h2 id="segment-anything-model-sam">Segment Anything Model (SAM)<a class="headerlink" href="#segment-anything-model-sam" title="Permanent link">#</a></h2>
<p><a href="../m/#meta-company">Meta</a> has launched Segment Anything, a project that introduces the Segment Anything Model (SAM), a promptable model for <a href="../i/#instance-segmentation">image segmentation</a> in <a href="../c/#computer-vision-cv">computer vision</a>. SAM can generate masks for any object in any image or video and learn a generalized notion of objects, making it a powerful tool for various applications, such as AR/VR, content creation, and scientific domains. SAM's promptable design allows for flexible integration with other systems, eliminating the need for task-specific modeling expertise, training compute, and custom data annotation. SAM is a single model that can perform both interactive and automatic segmentation, making it a unique and innovative tool in the field of computer vision.</p>
<p>META AI has also released the Segment Anything 1-Billion mask dataset (SA-1B), containing more than 1.1 billion segmentation masks collected from about 11 million licensed and privacy-preserving images. The <a href="../d/#dataset">dataset</a> is the largest segmentation dataset to date and has been verified through human evaluation studies. By sharing their research and dataset, META AI hopes to accelerate research in segmentation and contribute to more general image and video understanding, unlocking even more powerful AI systems in the future.</p>
<p>More at:</p>
<ul>
<li><a href="https://segment-anything.com/">https://segment-anything.com/</a></li>
<li>demo - <a href="https://segment-anything.com/demo">https://segment-anything.com/demo</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-attention">Self-Attention<a class="headerlink" href="#self-attention" title="Permanent link">#</a></h2>
<p>Use itself as input to</p>
<ul>
<li>find to what pronouns are referring to, what noun is being modified by adjective, subject of verbs, etc</li>
<li>(implicit) grammar rules  --- when you learn to speak, you do not have to learn grammar rules first to speak!</li>
</ul>
<iframe src="https://www.youtube.com/embed/g2BRIuln4uc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/PFczJ6NR5rY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>code explanation - <a href="https://nlp.seas.harvard.edu/annotated-transformer/">https://nlp.seas.harvard.edu/annotated-transformer/</a></li>
<li><a href="https://towardsdatascience.com/self-attention-5b95ea164f61">https://towardsdatascience.com/self-attention-5b95ea164f61</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../a/#attention-mechanism">Attention</a>, <a href="../a/#attention-based-model">Attention-Based Model</a>, <a href="../m/#masked-self-attention">Masked Self-Attention</a>, <a href="../m/#multi-head-attention">Multi-Head Attention</a>, <a href="./#scaled-dot-product-sdp-attention">Scaled Dot-Product Attention</a></p>
<h2 id="self-consistency-sc-prompting">Self-Consistency (SC) Prompting<a class="headerlink" href="#self-consistency-sc-prompting" title="Permanent link">#</a></h2>
<p>~ a [prompt engineering technique] that improves over <a href="../c/#chain-of-thought-cot-prompting">Chain-Of-Thought (COT)</a> prompting.</p>
<p>Self-consistency aims "to replace the naive greedy decoding used in chain-of-thought prompting". The idea is to sample multiple, diverse reasoning paths through few-shot <a href="../c/#chain-of-thought-cot-prompting">CoT</a>, and use the generations to select the most consistent answer. This helps to boost the performance of <a href="../c/#chain-of-thought-cot-prompting">CoT prompting</a> on tasks involving arithmetic and commonsense reasoning.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>there will be 21 trees. How many trees did the grove workers plant today?
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>So, they must have planted 21 - 15 = 6 trees. The answer is 6.
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>A: Leah had 32 chocolates and Leahs sister had 42. That means there were originally 32 + 42 = 74
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>did Jason give to Denny?
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>he have now?
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>in total he has 7 + 2 = 9 toys. The answer is 9.
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>Q: There were nine computers in the server room. Five more computers were installed each day, from
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>monday to thursday. How many computers are now in the server room?
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>The answer is 29.
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>golf balls did he have at the end of wednesday?
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>A: She bought 5 bagels for $3 each. This means she spent 5
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>Q: When I was 6 my sister was half my age. Now Im 70 how old is my sister?
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>A:
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a># output 1
</span><span id="__span-2-33"><a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>When I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70 - 3 = 67. The answer is 67.
</span><span id="__span-2-34"><a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>
</span><span id="__span-2-35"><a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a># output 2
</span><span id="__span-2-36"><a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>When the narrator was 6, his sister was half his age, which is 3. Now that the narrator is 70, his sister would be 70 - 3 = 67 years old. The answer is 67.
</span><span id="__span-2-37"><a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>
</span><span id="__span-2-38"><a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a># output 3
</span><span id="__span-2-39"><a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>When I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70/2 = 35. The answer is 35.
</span></code></pre></div>
<p>Computing for the final answer involves a few steps (check out the paper for the details) but for the sake of simplicity, we can see that there is already a majority answer emerging so that would essentially become the final answer.</p>
<object data="https://arxiv.org/pdf/2203.11171" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2203.11171">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2203.11171">https://arxiv.org/abs/2203.11171</a></li>
<li><a href="https://www.promptingguide.ai/techniques/consistency">https://www.promptingguide.ai/techniques/consistency</a> </li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-destructive-model">Self-Destructive Model<a class="headerlink" href="#self-destructive-model" title="Permanent link">#</a></h2>
<p>A way to make sure that a model cannot be retrained or fine-tuned for negative intent.
 So the end user does not have to be trusted to have good intentions to use a model.
 This is being researched now.</p>
<p>For what I understand, the model is using "instabilities" ... whatever that means!</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-driving-car">Self-Driving Car<a class="headerlink" href="#self-driving-car" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-improvement">Self-Improvement<a class="headerlink" href="#self-improvement" title="Permanent link">#</a></h2>
<p>AlphaGo approach consists in 2 steps:
 1. Learn by imitation , but cannot surpass human
 1. to surpass human, you need another method ==&gt; self-improvement</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-instruct-dataset">Self-Instruct Dataset<a class="headerlink" href="#self-instruct-dataset" title="Permanent link">#</a></h2>
<p>The Self-Instruct process is an iterative bootstrapping algorithm that starts with a seed set of manually-written instructions and uses them to prompt the language model to generate new instructions and corresponding input-output instances. These generations are then filtered to remove low-quality or similar ones, and the resulting data is added back to the task pool. This process can be repeated multiple times, resulting in a large collection of instructional data that can be used to fine-tune the language model to follow instructions more effectively.</p>
<p><img alt="" src="../img/s/self_instruct_dataset.jpeg" width="100%" /></p>
<p>We plot the below figure to demonstrate the diversity of our data. The inner circle of the plot represents the root verb of the instructions, and the outer circle represents the direct objects.</p>
<p><img alt="" src="../img/s/self_instruct_dataset_wheel.png" width="100%" /></p>
<p>This dataset was created to be used to train the <a href="../a/#alpaca-model">Alpaca model</a></p>
<object data="https://arxiv.org/pdf/2212.10560" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2212.10560">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://github.com/clcarwin/self-instruct-for-alpaca-dataset">https://github.com/clcarwin/self-instruct-for-alpaca-dataset</a></li>
<li>paper - <a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-organizing-map-som-algorithm">Self-Organizing Map (SOM) Algorithm<a class="headerlink" href="#self-organizing-map-som-algorithm" title="Permanent link">#</a></h2>
<p>SOM (Self-Organizing Map), also known as Kohonen map, is an <a href="../u/#unsupervised-learning">unsupervised learning</a> algorithm used for clustering, visualization, and dimensionality reduction tasks. It was developed by Finnish professor Teuvo Kohonen in the 1980s.</p>
<p>SOM is a type of artificial neural network that learns to represent the input data in a lower-dimensional grid or map while preserving the topological relationships between the data points. The algorithm organizes the input data based on their similarity, grouping similar instances together in the map.</p>
<p>Here's a general overview of how SOM works:
  1. Initialization: SOM starts by initializing a grid of neurons, each representing a specific location in the map. Each neuron is associated with a weight vector of the same dimensionality as the input data.
  1. Training: The algorithm iteratively presents input data samples to the SOM. For each input sample, the algorithm finds the best matching unit (BMU), which is the neuron with weight vector closest to the input sample in terms of similarity (e.g., using Euclidean distance).
  1. Neighborhood Update: After finding the BMU, the algorithm updates the weights of the BMU and its neighboring neurons in the map. The update is performed to move the weights closer to the input sample, encouraging nearby neurons to become more similar to the BMU.
  1. Iteration: The training process repeats for a specified number of iterations or until convergence. As the training progresses, the map self-organizes, and similar input samples tend to be grouped together.
  1. Visualization and Clustering: Once trained, the SOM can be used for various purposes. It can be used to visualize the high-dimensional input data in a lower-dimensional map, providing insights into the underlying structure of the data. Additionally, the SOM can be used for clustering by assigning new instances to the cluster associated with the BMU or by grouping instances that are close to each other in the map.</p>
<p>SOM is particularly useful for visualizing and exploring high-dimensional data, discovering clusters or patterns, and reducing the dimensionality of data for subsequent analysis. It has applications in various fields, including data mining, image processing, feature extraction, and anomaly detection.</p>
<p><img alt="" src="../img/s/self_organizing_map_algorithm.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/5CvJWtxytIk" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/K4WuE7zlOZo" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://www.superdatascience.com/blogs/the-ultimate-guide-to-self-organizing-maps-soms">https://www.superdatascience.com/blogs/the-ultimate-guide-to-self-organizing-maps-soms</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../u/#unsupervised-deep-learning-model">Unsupervised Deep Learning Model</a>, <a href="../u/#unsupervised-learning">Unsupervised Learning</a></p>
<h2 id="self-play">Self-Play<a class="headerlink" href="#self-play" title="Permanent link">#</a></h2>
<p>The idea that an agent can improve its gameplay by playing against slightly different versions of itself because it'll progressively encounter more challenging situation s.</p>
<p>Approach used by <a href="../a/#alphago-model">AlphaGo</a></p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-reflection-sr-prompting">Self-Reflection (SR) Prompting<a class="headerlink" href="#self-reflection-sr-prompting" title="Permanent link">#</a></h2>
<p>Self-reflection prompting is a technique used to improve the performance and reasoning capabilities of Large Language Models (LLMs) by encouraging the model to explicitly review, critique, and refine its own outputs.</p>
<p>This approach is inspired by human metacognition - our ability to think about our own thinking processes, which helps us learn and improve problem-solving skills.</p>
<p>Metacognitive Process</p>
<ul>
<li>The LLM is asked to evaluate its initial response</li>
<li>It critically examines its own reasoning, potential errors, or limitations</li>
<li>Encourages a more thoughtful and nuanced approach to problem-solving</li>
</ul>
<p>Typical Implementation</p>
<ul>
<li>After generating an initial response, the model is prompted to:<ul>
<li>Check the logic of its reasoning</li>
<li>Identify potential weaknesses or biases</li>
<li>Suggest improvements or alternative approaches</li>
<li>Verify the accuracy of key claims</li>
</ul>
</li>
</ul>
<p>Benefits</p>
<ul>
<li>Reduces hallucinations</li>
<li>Improves answer accuracy</li>
<li>Enhances reasoning capabilities</li>
<li>Promotes more comprehensive problem-solving</li>
<li>Helps identify potential blind spots in the model's initial response</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>// Initial Task Prompt
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>Solve the following word problem: A bakery sells cookies at $3 each. They want to raise $450 for a charity event. How many cookies do they need to sell to reach their fundraising goal?
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>Please show your calculation step by step.
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>// Potential Self-Reflection Prompt
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>You just solved the previous math problem. Now, I want you to review your solution carefully:
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>1. Verify your calculation method
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>2. Check if your computational steps are mathematically correct
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>3. Confirm that your final answer directly addresses the original question
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>4. Identify any potential assumptions or simplifications you made
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>5. Suggest if there are alternative ways to solve this problem
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>If you find any errors in your previous solution, provide the corrected calculation and explain why your initial approach might have been incorrect.
</span></code></pre></div>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-reflective-retrieval-augmented-generation-sr-rag-system">Self-Reflective Retrieval Augmented Generation (SR-RAG) System<a class="headerlink" href="#self-reflective-retrieval-augmented-generation-sr-rag-system" title="Permanent link">#</a></h2>
<p>~ a more advanced version of a traditional <a href="../r/#retrieval-augmented-generation-rag-system">RAG system</a></p>
<p>Self-Reflective RAG, closely related to <a href="../c/#corrective-retrieval-augmented-generation-crag-system">CRAG</a>, incorporates feedback loops such as re-generating questions or re-retrieving documents based on the relevance and accuracy of the initially retrieved information. This approach necessitates the use of state machines, where a series of steps and transitions are defined to enhance the relevance and quality of the generated content.</p>
<p><img alt="" src="../img/s/self_reflective_retrieval_augmented_generation_workflow.png" width="&quot;100%" /></p>
<p>More at:</p>
<ul>
<li>articles<ul>
<li><a href="https://blog.langchain.dev/agentic-rag-with-langgraph/">https://blog.langchain.dev/agentic-rag-with-langgraph/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="self-supervised-learning-ssl">Self-Supervised Learning (SSL)<a class="headerlink" href="#self-supervised-learning-ssl" title="Permanent link">#</a></h2>
<p>~ a form of unsupervised learning, where manually labeled data is not needed. Raw data is instead modified in an automated way to create artificial labels to learn from. An example of SSL is learning to complete text by masking random words in a sentence and trying to predict the missing ones.</p>
<p>~ automatic generation of labels from the unlabeled input data.` A type of learning that does not need labels to be applied by humans. The training dataset is generated from the data. Examples:</p>
<ul>
<li><a href="../n/#next-word-prediction">Next word prediction</a> - "she planned to visit the"</li>
<li><a href="../m/#masked-language-modeling-mlm">Masked Language Modeling</a> - "Alice chased the <strong><em>_ rabbit and fell down the </em></strong>_ into a new world."</li>
<li>Replaced word detection : "The cat pounced on the carrot"</li>
<li>Paraphrased sentences : "He needs to throw a lot of things -- he has a lot of stuff to get rid off."</li>
</ul>
<p><img alt="" src="../img/s/self_supervised_learning.png" width="&quot;100%" /></p>
<p>Self-supervised learning in humans refers to the process by which individuals acquire knowledge and skills through their own experiences and interactions with their environment, without the need for explicit external feedback or instruction.  This type of learning can occur in a variety of contexts, including during childhood development, where children learn to walk, talk, and interact with their surroundings through self-directed exploration and experimentation.  Self-supervised learning can also occur in more advanced stages of learning, such as when individuals acquire new skills or knowledge in their field of expertise through self-directed practice and experimentation. Overall, self-supervised learning for humans is a natural and essential process that enables individuals to acquire new knowledge and skills in a self-directed and autonomous manner.</p>
<p>See also <a href="./">S</a>, [Data2Vec Model], [Replaced Word Detection], <a href="./#semi-supervised-learning">Semi-Supervised Learning</a>, <a href="./#supervised-learning">Supervised Learning</a>, <a href="../u/#unsupervised-learning">Unsupervised Learning</a>, <a href="../u/#upstream-task">Upstream Task</a></p>
<h2 id="semantic-embedding">Semantic Embedding<a class="headerlink" href="#semantic-embedding" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/s/semantic_embedding.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, <a href="./#semantic-space">Semantic Space</a>, <a href="../z/#zero-shot-learning">Zero-Shot Learning</a></p>
<h2 id="semantic-router">Semantic Router<a class="headerlink" href="#semantic-router" title="Permanent link">#</a></h2>
<p>An alternative to <a href="../r/#reason-act-react-prompting">React Prompting</a> iwhen working with <a href="../a/#ai-agent">AI Agents</a>, where a query is semantically mapped to an embedded space where tool queries are mapped.</p>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> can also be used for safeguards !</p>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Can be used for RAG !</p>
<p>/// details | That probably works well for 1 tools, but what about several tools?
    type:question</p>
<p>///</p>
<iframe src="https://www.youtube.com/embed/ro312jDqAh0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>notebooks <ul>
<li>get started - <a href="https://github.com/aurelio-labs/semantic-router/blob/main/docs/00-introduction.ipynb">https://github.com/aurelio-labs/semantic-router/blob/main/docs/00-introduction.ipynb</a></li>
<li>langchain - <a href="https://github.com/aurelio-labs/semantic-router/blob/main/docs/03-basic-langchain-agent.ipynb">https://github.com/aurelio-labs/semantic-router/blob/main/docs/03-basic-langchain-agent.ipynb</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="semantic-search">Semantic Search<a class="headerlink" href="#semantic-search" title="Permanent link">#</a></h2>
<p>= embedding + similarity + reranking</p>
<p>Semantic search leverages deep neural networks to intelligently search through data. You interact with it every time you search on Google. Semantic search is helpful when you want to search for something based on the context rather than specific keywords.</p>
<p>Semantic search is often used in <a href="../r/#retriever">retriever</a> in <a href="../r/#retrieval-augmented-generation-rag-system">RAG</a></p>
<div class="admonition warning">
<p class="admonition-title">Beware:</p>
<ul>
<li>If you only use embeddings and similarity, you may not be finding the answer to the question as the closest point may be out of date or false. To solve this, you need to use <a href="../r/#reranking">reranking</a> --&gt; give a score to all the nearest embeddings and pick the one with the highest score!</li>
</ul>
</div>
<iframe src="https://www.youtube.com/embed/fFt4kR4ntAA" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://txt.cohere.com/what-is-semantic-search/">https://txt.cohere.com/what-is-semantic-search/</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../l/#lexical-search">Lexical Search</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a>, <a href="./#similarity-metric">Similarity Metric</a></p>
<h2 id="semantic-segmentation">Semantic Segmentation<a class="headerlink" href="#semantic-segmentation" title="Permanent link">#</a></h2>
<p>semantic segmentation algorithm provides a fine-grained, pixel-level approach to developing computer vision applications. It tags every pixel in an image with a class label from a predefined set of classes (ex: a person). Tagging is fundamental for understanding scenes, which is critical to an increasing number of computer vision applications, such as self-driving vehicles, medical imaging diagnostics, and robot sensing.</p>
<p>For comparison, the Amazon SageMaker Image Classification Algorithm is a supervised learning algorithm that analyzes only whole images, classifying them into one of multiple output categories. The Object Detection Algorithm is a supervised learning algorithm that detects and classifies all instances of an object in an image. It indicates the location and scale of each object in the image with a rectangular bounding box.</p>
<p>Because the semantic segmentation algorithm classifies every pixel in an image, it also provides information about the shapes of the objects contained in the image. The segmentation output is represented as an RGB or grayscale image, called a segmentation mask. A segmentation mask is an RGB (or grayscale) image with the same shape as the input image.</p>
<p><img alt="" src="../img/s/semantic_and_instance_segmentation.png" width="&quot;100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b">https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a>, <a href="../i/#instance-segmentation">Instance Segmentation</a>, <a href="../u/#u-net-architecture">U-Net Architecture</a></p>
<h2 id="semantic-space">Semantic Space<a class="headerlink" href="#semantic-space" title="Permanent link">#</a></h2>
<p>semantic space, where the knowledge from seen classes can be transferred to unseen classes.</p>
<p>See also <a href="./">S</a>, <a href="../e/#embedding-space">Embedding Space</a>, <a href="../l/#latent-space">Latent Space</a>, <a href="./#semantic-embedding">Semantic Embedding</a>, <a href="../z/#zero-shot-learning">Zero-Shot Learning</a></p>
<h2 id="semantic-understanding">Semantic Understanding<a class="headerlink" href="#semantic-understanding" title="Permanent link">#</a></h2>
<p>machine translation, information extraction, text summarization, question answering.</p>
<p>See also <a href="./">S</a>, <a href="../b/#benchmark">Benchmark</a></p>
<h2 id="semi-supervised-learning">Semi-Supervised Learning<a class="headerlink" href="#semi-supervised-learning" title="Permanent link">#</a></h2>
<p>~ <code>dataset not fully labeled --&gt; use similarity to label other data</code> Supervised learning and unsupervised learning can be thought of as occupying opposite ends of a spectrum. Some types of problem, called semi-supervised learning problems, make use of both supervised and unsupervised data; these problems are located on the spectrum between supervised and unsupervised learning.  Several algorithm can be used like neighbor infection or nearest labeled neighbor. Example A: In a series of picture, you recognize people, let's say 4 of them. If you tag one image, then the tags can be pushed to all the other images. Example B: Classification problem but only on a small subset you have is CORRECTLY labeled. Can you train your model with the rest of the unlabeled data? </p>
<p>See also <a href="./">S</a>, [K-Nearest Neighbors Algorithm], <a href="./#self-supervised-learning-ssl">Self-Supervised Learning</a>, <a href="./#supervised-learning">Supervised Learning</a>, [Unlabelled Data Algorithm], <a href="../u/#unsupervised-learning">Unsupervised Learning</a>, <a href="../w/#weak-supervised-learning">Weak-Supervised Learning</a></p>
<h2 id="sensitivity">Sensitivity<a class="headerlink" href="#sensitivity" title="Permanent link">#</a></h2>
<p>~ capacity at detecting a rare disease based on a threshold (?)</p>
<p>~ a term more commonly used in fields like medicine or epidemiology. It describes a test's ability to correctly identify patients with a disease (true positives).</p>
<p>~ High sensitivity = test is effective at detecting positive cases without missing many </p>
<p>~ aka <a href="../r/#recall">recall</a> in the field of <a href="../m/#machine-learning-ml">ML</a> and information retrieval. It describes the ability of a model to find all the relevant cases within a dataset.</p>
<p>~ aka <a href="../t/#true-positive-rate-tpr">True Positive Rate (TPR)</a> in the context of a classifier. = probability of a positive test given the patient has the disease.  Sensitivity refers to the probability of a positive test, conditioned on truly being positive. Examples:</p>
<ul>
<li>how many sick people were CORRECTLY identified as having the condition.</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a># P(Pos) = Probability of getting a positive test result
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a># P(D) = The probability of a person having diabetes
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a># P(~D) = The probabilitiy of a person NOT having diabetes
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>## Sensitivity = 
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>## Specificity =
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>P(Pos) = [P(D) * Sensitivity] + [P(~D) * (1-Specificity))]
</span></code></pre></div>
<p>More at:</p>
<ul>
<li>articles<ul>
<li><a href="https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5">https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5</a></li>
<li><a href="https://medium.com/becoming-human/naive-bayes-theorem-d8854a41ea08">https://medium.com/becoming-human/naive-bayes-theorem-d8854a41ea08</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a>, <a href="./#sensitivity-specificity-trade-off">Sensitivity-Specificity Trade-Off</a>, <a href="./#specificity">Specificity</a></p>
<h2 id="sensitivity-specificity-trade-off">Sensitivity-Specificity Trade-Off<a class="headerlink" href="#sensitivity-specificity-trade-off" title="Permanent link">#</a></h2>
<p>The sensitivity-specificity trade-off in a classifier refers to the balance between two key metrics:</p>
<ul>
<li><a href="./#sensitivity">Sensitivity</a> (or <a href="../r/#recall">Recall</a>): The ability of the classifier to correctly identify positive instances. It is calculated as the proportion of true positives out of the total actual positives.</li>
<li><a href="./#specificity">Specificity</a>: The ability of the classifier to correctly identify negative instances. It is calculated as the proportion of true negatives out of the total actual negatives.</li>
</ul>
<p>The trade-off between sensitivity and specificity arises because improving one of these metrics often comes at the expense of the other. This is particularly evident in classifiers that output a probability or score, where a threshold is set to determine the class labels (positive or negative). Adjusting this threshold will typically increase one metric but decrease the other.</p>
<p>Here's how:</p>
<ul>
<li>Lowering the Threshold: If you lower the threshold for classifying an instance as positive, you will likely identify more true positives (increasing sensitivity), but you will also likely misclassify more negatives as positives (decreasing specificity).</li>
<li>Raising the Threshold: Conversely, if you raise the threshold, you'll classify fewer instances as positive. This can lead to fewer false positives (increasing specificity), but also more false negatives (decreasing sensitivity).</li>
</ul>
<p>This trade-off is crucial in many real-world applications. For example, in medical diagnostics, a high sensitivity is often desired for initial screenings to ensure that as many cases of a disease as possible are identified. However, this might come at the cost of higher false positives, leading to more follow-up tests. On the other hand, in a different context, one might prefer high specificity to ensure that only the most likely cases are pursued further.</p>
<p>The <a href="../r/#receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) curve</a> is a common tool used to visualize this trade-off. It plots the [True Positive Rate] ( or <a href="./#sensitivity">Sensitivity</a>) against the [False Positive Rate] or  (1 - <a href="./#specificity">Specificity</a>) at various threshold settings. The <a href="../a/#area-under-the-receiver-operating-characteristic-auroc-curve">Area Under the Receiver Operating Characteristic (AUROC) curve</a> can give a sense of the overall ability of the <a href="../b/#binary-classification">binary classifier</a> to discriminate between the two classes, independent of any particular threshold.</p>
<p>In summary, the sensitivity-specificity trade-off highlights the balancing act in setting the threshold for <a href="../c/#classification-task">classification</a>, where the goal is to achieve an optimal balance that suits the specific needs and consequences of the classification task at hand.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sentence-bert-sbert-model">Sentence-BERT (SBERT) Model<a class="headerlink" href="#sentence-bert-sbert-model" title="Permanent link">#</a></h2>
<p>A derivative model of <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT</a> that ...</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sentence-embedding">Sentence Embedding<a class="headerlink" href="#sentence-embedding" title="Permanent link">#</a></h2>
<p>A type of <a href="../e/#embedding">embeddings</a></p>
<ul>
<li><a href="../u/#universal-sentence-encoder-use">Universal Sentence Encoder (USE)</a>  Encodes sentences into high-dimensional vectors using a transformer or deep averaging network. For example, the sentences The quick brown fox jumps over the lazy dog and A swift auburn fox leaps over a sleepy canine would have similar embeddings because they convey the same meaning.</li>
<li>Sentence-BERT (SBERT)  Fine-tunes BERT on sentence-pair regression tasks to produce meaningful sentence embeddings. For instance, determining that How do I reset my password? is similar in meaning to What is the process to change my password?. This capability is excellent for applications like <abbr title="Frequent Asked Questions">FAQ</abbr> matching and paraphrase detection</li>
</ul>
<p>More at:</p>
<ul>
<li>tutorial - <a href="https://txt.cohere.com/sentence-word-embeddings/">https://txt.cohere.com/sentence-word-embeddings/</a></li>
<li>articles<ul>
<li>LLM embeddings - <a href="https://www.iguazio.com/glossary/llm-embeddings/">https://www.iguazio.com/glossary/llm-embeddings/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sentencepiece-tokenizer">SentencePiece Tokenizer<a class="headerlink" href="#sentencepiece-tokenizer" title="Permanent link">#</a></h2>
<p>~ a type of [tokenizers]</p>
<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1808.06226">https://arxiv.org/abs/1808.06226</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../d/#detokenizer">Detokenizer</a></p>
<h2 id="sentient-ai">Sentient AI<a class="headerlink" href="#sentient-ai" title="Permanent link">#</a></h2>
<p>Is Google's [Lambda Model] sentient?</p>
<iframe src="https://www.youtube.com/embed/kgCUn4fQTsc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/2856XOaUPpg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/NAihcvDGaP8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>{% pdf "img/s/sentient_ai_post.pdf" %}</p>
<p>More at:</p>
<ul>
<li><a href="https://bdtechtalks.com/2023/02/20/llm-dissociating-language-and-thought/">https://bdtechtalks.com/2023/02/20/llm-dissociating-language-and-thought/</a></li>
<li><a href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917">https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917</a></li>
<li><a href="https://medium.com/movement-dao/fired-google-engineer-blake-lemoine-on-his-future-lamda-and-ai-advocacy-98c816dde89e">https://medium.com/movement-dao/fired-google-engineer-blake-lemoine-on-his-future-lamda-and-ai-advocacy-98c816dde89e</a></li>
<li><a href="https://www.theatlantic.com/ideas/archive/2022/06/google-lamda-chatbot-sentient-ai/661322/">https://www.theatlantic.com/ideas/archive/2022/06/google-lamda-chatbot-sentient-ai/661322/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sentiment-analysis">Sentiment Analysis<a class="headerlink" href="#sentiment-analysis" title="Permanent link">#</a></h2>
<p>Marketers collect social media posts about specific brands, conversation subjects, and keywords, then use NLP to analyze how users feel about each topic, individually and collectively. This helps the brands with customer research, image evaluation, and social dynamics detection.</p>
<p>Architectures:</p>
<ul>
<li><a href="../n/#natural-language-toolkit-nltk">Natural Language ToolKit (NLTK)</a></li>
<li><a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT Model</a></li>
<li><a href="../v/#valence-aware-dictionary-and-sentiment-reasoner-vader-python-module">VADER</a></li>
<li><a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT Model</a> - requires API call</li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/">https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/</a></li>
<li>word sentiment weight - <a href="https://observablehq.com/d/caaff7524e19d7ba">https://observablehq.com/d/caaff7524e19d7ba</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../b/#benchmark">Benchmark</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a></p>
<h2 id="sequence-model">Sequence Model<a class="headerlink" href="#sequence-model" title="Permanent link">#</a></h2>
<p>Map one sequence to a similar sequence</p>
<p><img alt="" src="../img/s/sequence_model.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</a>, <a href="../n/#neural-ordinary-differential-equation-ode">Neural ODE</a>, <a href="../r/#recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</a>, <a href="../t/#transformer-architecture">Transformer Architecture</a></p>
<h2 id="sequence-to-sequence-seq2seq-model">Sequence To Sequence (Seq2Seq) Model<a class="headerlink" href="#sequence-to-sequence-seq2seq-model" title="Permanent link">#</a></h2>
<p>= A <a href="./#supervised-learning">supervised learning</a> algorithm where the input is a sequence of tokens (for example, text, audio) and the output generated is another sequence of tokens. </p>
<p>Example applications include:</p>
<ul>
<li><a href="../m/#machine-translation">machine translation</a> - input a sentence from one language and predict what that sentence would be in another language</li>
<li><a href="../t/#text-summarization">text summarization</a> - input a longer string of words and predict a shorter string of words that is a summary</li>
<li><a href="./#speech-to-text-stt-model">speech-to-text</a> - audio clips converted into output sentences in tokens.</li>
</ul>
<p>Recently, problems in this domain have been successfully modeled with deep neural networks that show a significant performance boost over previous methodologies. Amazon SageMaker seq2seq uses <a href="../r/#recurrent-neural-network-rnn">Recurrent Neural Networks (RNNs)</a> and <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</a> models with <a href="../a/#attention-mechanism">attention</a> as encoder-decoder architectures. Seq2Seq models are particularly good at translation, where a sequence of words from one language is transformed into a sequence of different words in another language.</p>
<p><mark>Google Translate started using a Seq2Seq-based model in production in late 2016</mark></p>
<p><img alt="" src="../img/s/sequence_to_sequence_model.png" width="&quot;100%" /></p>
<p>Seq2Seq models consist of two parts: an <a href="../e/#encoder">encoder</a> and a <a href="../d/#decoder">decoder</a>. Imagine the encoder and decoder as human translators who can each speak only two languages, with each having a different mother tongue. For our example, well say the encoder is a native French speaker and the decoder is a native English speaker. The two have a second language in common: lets say its Korean. To translate French into English, the encoder converts the French sentence into Korean (known as context) and passes on the context to the decoder. Since the decoder understands Korean, he or she can now translate from Korean into English. Working together, they can translate the French language to English.</p>
<iframe src="https://www.youtube.com/embed/L8HKweZIOmg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, <a href="./#sequence-to-sequence-seq2seq-transformer">Seq2Seq Transformer</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a>, <a href="../t/#text-to-speech-tts-model">Text-To-Speech Model</a></p>
<h2 id="sequence-to-sequence-seq2seq-transformer">Sequence To Sequence (Seq2Seq) Transformer<a class="headerlink" href="#sequence-to-sequence-seq2seq-transformer" title="Permanent link">#</a></h2>
<p>When you use the encoder and decoder of a transformer, you can do a sequence to sequence transformer!</p>
<p><img alt="" src="../img/s/sequence_to_sequence_transformer.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, <a href="../d/#decoder">Decoder</a>, <a href="../e/#encoder">Encoder</a>, <a href="../e/#encoder-decoder-model">Encoder-Decoder Model</a></p>
<h2 id="sequential-data">Sequential Data<a class="headerlink" href="#sequential-data" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/s/sequential_data.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="serialized-flat-file">Serialized Flat File<a class="headerlink" href="#serialized-flat-file" title="Permanent link">#</a></h2>
<p>The model in compact form, delivered to endpoint.</p>
<h2 id="service-robot">Service Robot<a class="headerlink" href="#service-robot" title="Permanent link">#</a></h2>
<p>A type of <a href="../r/#robot">robots</a> that ...</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="shallow-neural-network">Shallow Neural Network<a class="headerlink" href="#shallow-neural-network" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="shane-legg-person">Shane Legg Person<a class="headerlink" href="#shane-legg-person" title="Permanent link">#</a></h2>
<p>One of the 3 founders of <a href="../d/#deepmind-company">DeepMind</a></p>
<iframe src="https://www.youtube.com/embed/Kc1atfJkiJU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, ...</p>
<h2 id="shannon-entropy">Shannon Entropy<a class="headerlink" href="#shannon-entropy" title="Permanent link">#</a></h2>
<p>See <a href="../e/#entropy">Entropy</a></p>
<h2 id="shapley-additive-explanations-shap-value">Shapley Additive Explanations (SHAP) Value<a class="headerlink" href="#shapley-additive-explanations-shap-value" title="Permanent link">#</a></h2>
<p>The Shapley Additive Explanations (SHAP) is another novel approach to <a href="../e/#explainability">explainability</a> developed by Scott Lundberg at <a href="../m/#microsoft-company">Microsoft</a> and eventually opened sourced.</p>
<p>SHAP has a strong mathematical foundation based on Shapley values in game theory where each player in the cooperation is rewarded based on how important they are to cooperation.</p>
<object data="https://arxiv.org/pdf/1705.07874" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1705.07874">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1705.07874">https://arxiv.org/abs/1705.07874</a></li>
<li><a href="https://towardsdatascience.com/what-is-explainable-ai-xai-afc56938d513">https://towardsdatascience.com/what-is-explainable-ai-xai-afc56938d513</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="shapley-value">Shapley Value<a class="headerlink" href="#shapley-value" title="Permanent link">#</a></h2>
<p>In <a href="../g/#game-theory">Game Theory</a>, ...</p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Shapley_value">https://en.wikipedia.org/wiki/Shapley_value</a></li>
</ul>
<p>See also <a href="./">S</a>, [Shapley Additive Explanations]</p>
<h2 id="shifted-window-attention-swa">Shifted Window Attention (SWA)<a class="headerlink" href="#shifted-window-attention-swa" title="Permanent link">#</a></h2>
<p>~ allow LLM to handle long sequences with reduced inference cost</p>
<p>SWA is an attention mechanism designed to enable efficient processing of longer input sequences in transformers and related neural network models.</p>
<p>Used by [Longformer Models] such as:</p>
<ul>
<li><a href="../m/#mistral-model">Mistral Models</a></li>
</ul>
<p>Here are the key points about Shifted Window Attention (SWA):</p>
<ul>
<li>Like grouped query attention, SWA divides the input sequence into chunks or windows to focus the attention.</li>
<li>However, unlike grouped attention, the windows in SWA overlap with each other. For example, a sequence could be divided into windows 1-100, 51-150, 101-200 etc, with 50 tokens of overlap.</li>
<li>This overlapping window approach allows each token to attend within its window as well as to tokens from adjacent windows. This provides wider contextual attention than isolated groups.</li>
<li>Additionally, the windows are shifted systematically across the sequence. So window 1 covers tokens 1-100, window 2 then covers tokens 51-150, and so on. This shifting enables all tokens to be covered by overlapping windows.</li>
<li>Mathematically, this shifting of systematic, overlapping windows enables efficient attention computation in transformers. It limits the complexity that comes from full global attention across extremely long sequences.</li>
</ul>
<p>In summary, SWA reduces computational overhead while retaining modeling flexibility for longer sequences. The shifting windows provide efficiency while the overlap enables wider attention. This helps advanced transformers scale effectively to tasks with longer inputs while still utilizing the power and benefits of attention mechanisms.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="siamese-network">Siamese Network<a class="headerlink" href="#siamese-network" title="Permanent link">#</a></h2>
<p>A convolutional encoder that looks at similarities. Ex: Compare 2 images of a lion with nothing else.</p>
<p><img alt="" src="../img/s/siamese_network.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, [One Short Learning], <a href="./#similarity-metric">Similarity Metric</a></p>
<h2 id="siggraph-conference">SIGGRAPH Conference<a class="headerlink" href="#siggraph-conference" title="Permanent link">#</a></h2>
<p>An <a href="../a/#ai-conference">AI conference</a> reltated to graphics and interactive techniques</p>
<p>More at:</p>
<ul>
<li><a href="https://s2023.siggraph.org/">https://s2023.siggraph.org/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sigmoid-activation-function">Sigmoid Activation Function<a class="headerlink" href="#sigmoid-activation-function" title="Permanent link">#</a></h2>
<p>Pros:</p>
<ul>
<li>output is between 0 and 1</li>
<li>sigmoid can be used as a switch (in LSTM and GRU cells)</li>
<li>solves exploding gradient problem</li>
</ul>
<p>Cons:</p>
<ul>
<li>vanishing gradient problem</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="sigmoid-function">Sigmoid Function<a class="headerlink" href="#sigmoid-function" title="Permanent link">#</a></h2>
<p>Used as an activation function and in logistic regression.</p>
<p><img alt="" src="../img/s/sigmoid_function.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, [Logistic Regression], <a href="./#sigmoid-activation-function">Sigmoid Activation Function</a></p>
<h2 id="similarity-metric">Similarity Metric<a class="headerlink" href="#similarity-metric" title="Permanent link">#</a></h2>
<p>Similarity is almost like distance in the semantic embedding space, except that:</p>
<ul>
<li>When the distance is small, the similarity is big</li>
<li>When the distance is big, the similarity is small</li>
</ul>
<p>Functions:</p>
<ul>
<li><a href="../e/#euclidean-distance">Euclidean Distance</a></li>
<li><a href="../m/#manhattan-distance">Manhattan Distance</a></li>
<li><a href="../c/#cosine-similarity-function">Cosine Similarity</a></li>
<li><a href="../d/#dot-product-similarity">Dot Product Similarity</a></li>
<li>[Scaled Dot Product Similarity]</li>
<li>[Hadamard Product]</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../e/#encoder">Encoder</a>, <a href="../o/#one-shot-learning">One-Shot Learning</a>, <a href="./#siamese-network">Siamese Network</a></p>
<h2 id="similarity-search">Similarity Search<a class="headerlink" href="#similarity-search" title="Permanent link">#</a></h2>
<p>Algorithms:</p>
<ul>
<li>[K-Nearest Neighbors] - good, but slow as I have to calculate as many distances as we have points in the dataset! (Ex: 8 words --&gt; 8^2 distances)</li>
<li><a href="../i/#inverted-file-index-ivd">Inverted File Index (IVD)</a> - cluster, then search</li>
<li><a href="../h/#hierarchical-navigable-small-world-hnsw-function">Hierarchical Navigable Small World (HNSW)</a> - Start with fewer points, search there. Then add more and iterate</li>
<li><a href="../l/#local-sensitive-hashing-lsh">Local Sensitive Hashing (LSH)</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="simulated-policy-learning-simple-algorithm">Simulated Policy Learning (SimPLe) Algorithm<a class="headerlink" href="#simulated-policy-learning-simple-algorithm" title="Permanent link">#</a></h2>
<p>In <a href="../r/#reinforcement-learning-rl">Reinforcement Learning</a>, ... </p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="simulated-to-real-sim2real-performance-gap">Simulated-To-Real (Sim2Real) Performance Gap<a class="headerlink" href="#simulated-to-real-sim2real-performance-gap" title="Permanent link">#</a></h2>
<p>Because the simulation cannot capture all aspects of the real world accurately, the models trained in simulation may not work well in the real world. Such discrepancies are often referred to as simulated-to-real (sim2real) performance gaps.</p>
<p>Many factors affect the real-world performance of a trained model, including the choice of the action space, reward function, hyperparameters used in the training, and vehicle calibration as well as real-world track conditions. In addition, the simulation is only an (often crude) approximation of the real world. They make it a challenge to train a model in simulation, to apply it to the real world, and to achieve a satisfactory performance.</p>
<p>Training a model to give a solid real-world performance often requires numerous iterations of exploring the reward function, action spaces, hyperparameters, and evaluation in simulation and testing in a real environment. The last step involves the so-called simulation-to-real world (sim2real) transfer and can feel unwieldy.</p>
<p>More at:</p>
<ul>
<li><a href="https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-how-it-works-virtual-to-physical.html">https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-how-it-works-virtual-to-physical.html</a></li>
<li><a href="https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-console-train-evaluate-models.html#deepracer-evaluate-model-test-approaches">https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-console-train-evaluate-models.html#deepracer-evaluate-model-test-approaches</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="simultaneous-localization-and-mapping-slam-algorithm">Simultaneous Localization And Mapping (SLAM) Algorithm<a class="headerlink" href="#simultaneous-localization-and-mapping-slam-algorithm" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/-XU54IsG8Vo" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, [Inertial Measurement Unit], <a href="../l/#lidar">Lidar</a>, [Visual SLAM Algorithm]</p>
<h2 id="single-life-reinforcement-learning-slrl">Single Life Reinforcement Learning (SLRL)<a class="headerlink" href="#single-life-reinforcement-learning-slrl" title="Permanent link">#</a></h2>
<p>RL algorithms are designed to learn a performant policy that can repeatedly complete a task, but many real-world situations involve on-the-fly adaptation that requires solving a task successfully once without interventions. Example: A disaster relief robot tasked with retrieving an item has a single trial to complete its mission and may encounter novel obstacles in a previously-experienced building. We model these situations with the following problem setting: Utilizing some prior data, the agent is given a single life, i.e. trial, to autonomously adapt to a novel scenario to complete a task once. We call this problem setting single-life reinforcement learning (SLRL). SLRL provides a natural setting in which to study autonomous adaptation to novel situations in reinforcement learning.</p>
<p>More at:</p>
<ul>
<li><a href="https://sites.google.com/stanford.edu/single-life-rl">https://sites.google.com/stanford.edu/single-life-rl</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)<a class="headerlink" href="#singular-value-decomposition-svd" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/vSczTbgc8Rc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/DG7YTlGnCEo" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/singular-value-decomposition-svd/">https://www.geeksforgeeks.org/singular-value-decomposition-svd/</a></li>
<li><a href="https://www.geeksforgeeks.org/singular-value-decomposition">https://www.geeksforgeeks.org/singular-value-decomposition/?ref=lbp</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../n/#netflix-prize">Netflix Prize</a></p>
<h2 id="siri-virtual-assistant">Siri Virtual Assistant<a class="headerlink" href="#siri-virtual-assistant" title="Permanent link">#</a></h2>
<p>First conceptualized in a <a href="../c/#concept-video">Concept Video</a> and named the Knowledge Navigator.</p>
<p>Siri is a virtual assistant developed by <a href="../a/#apple-company">Apple</a> that is part of iOS, iPadOS, watchOS, macOS, tvOS, and audioOS operating systems. It uses voice queries, gesture based control, focus-tracking and a natural-language user interface to answer questions, make recommendations, and perform actions by delegating requests to a set of Internet services. With continued use, it adapts to users' individual language usages, searches and preferences, returning individualized results.</p>
<p><img alt="" src="../img/s/siri_logo.png" /></p>
<p>Siri is a spin-off from a project developed by the SRI International Artificial Intelligence Center. Its speech recognition engine was provided by Nuance Communications, and it uses advanced machine learning technologies to function. Its original American, British and Australian voice actors recorded their respective voices around 2005, unaware of the recordings' eventual usage. Siri was released as an app for iOS in February 2010. Two months later, Apple acquired it and integrated into iPhone 4S at its release on 4 October, 2011, removing the separate app from the iOS App Store. Siri has since been an integral part of Apple's products, having been adapted into other hardware devices including newer iPhone models, iPad, iPod Touch, Mac, AirPods, Apple TV, and HomePod.</p>
<p>More at: </p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Siri">https://en.wikipedia.org/wiki/Siri</a></li>
<li><a href="https://www.cultofmac.com/447783/today-in-apple-history-siri-makes-its-public-debut-on-iphone-4s/">https://www.cultofmac.com/447783/today-in-apple-history-siri-makes-its-public-debut-on-iphone-4s/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Knowledge_Navigator">https://en.wikipedia.org/wiki/Knowledge_Navigator</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="skip-connection">Skip Connection<a class="headerlink" href="#skip-connection" title="Permanent link">#</a></h2>
<p>A way to alleviate the vanishing gradient problem by having activation skip hidden layers?</p>
<p>See also <a href="./">S</a>, <a href="../r/#residual-block">Residual Block</a>, [Residual Network Model]</p>
<h2 id="skip-gram-model">Skip-Gram Model<a class="headerlink" href="#skip-gram-model" title="Permanent link">#</a></h2>
<p>= increases the context by using word in the middle to predict the surrounding words</p>
<p>The skip-gram model is a simple neural network with one hidden layer trained in order to predict the probability of a given word being present when an input word is present. The process can be described visually as seen below.</p>
<p><img alt="" src="../img/s/skip_gram_model_training_data.webp" /></p>
<p>As seen above, given some corpus of text, a target word is selected over some rolling window. The training data consists of pairwise combinations of that target word and all other words in the window. This is the resulting training data for the neural network. Once the model is trained, we can essentially yield a probability of a word being a context word for a given target. The following image below represents the architecture of the neural network for the skip-gram model.</p>
<p><img alt="" src="../img/s/skip_gram_model_architecture.webp" /></p>
<p>A corpus can be represented as a vector of size N, where each element in N corresponds to a word in the corpus. During the training process, we have a pair of target and context words, the input array will have 0 in all elements except for the target word. The target word will be equal to 1. The hidden layer will learn the embedding representation of each word, yielding a d-dimensional embedding space. The output layer is a dense layer with a softmax activation function. The output layer will essentially yield a vector of the same size as the input, each element in the vector will consist of a probability. This probability indicates the similarity between the target word and the associated word in the corpus.</p>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/node2vec-explained-db86a319e9ab">https://towardsdatascience.com/node2vec-explained-db86a319e9ab</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../n/#node2vec-model">Node2Vec Model</a>, <a href="../w/#word2vec-model">Word2Vec Model</a></p>
<h2 id="skorch-python-module">Skorch Python Module<a class="headerlink" href="#skorch-python-module" title="Permanent link">#</a></h2>
<p>~ scikit learn that wrap s pytorch.</p>
<p>Pytorch objects can be passed as parameters to scikit!</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">skorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">NeuralNetRegressor</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="o">...</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">net</span> <span class="o">=</span> <span class="n">NeuralNetRegressor</span><span class="p">(</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    <span class="n">LinearRegressionTorch</span><span class="p">,</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="c1"># Shuffle training data on each epoch</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span class="n">iterator_train__shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="p">)</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="n">net</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">train_split</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>    <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">],</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>    <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a><span class="p">}</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a><span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best score: </span><span class="si">{</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, best params: </span><span class="si">{</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>More at:</p>
<ul>
<li>docs - <a href="https://skorch.readthedocs.io/en/stable/">https://skorch.readthedocs.io/en/stable/</a></li>
<li>code - <a href="https://github.com/midtown-ai/PyTorch-Ultimate-2023---From-Basics-to-Cutting-Edge/blob/main/030_ModelingIntroduction/50_LinReg_HyperparameterTuning_end.py">https://github.com/midtown-ai/PyTorch-Ultimate-2023---From-Basics-to-Cutting-Edge/blob/main/030_ModelingIntroduction/50_LinReg_HyperparameterTuning_end.py</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="slicing-function">Slicing Function<a class="headerlink" href="#slicing-function" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="./#snorkel-program">Snorkel Program</a></p>
<h2 id="slide-deck-generator">Slide Deck Generator<a class="headerlink" href="#slide-deck-generator" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li>beautiful AI - <a href="https://www.beautiful.ai/">https://www.beautiful.ai/</a></li>
<li>gamma.app - <a href="https://gamma.app/">https://gamma.app/</a></li>
<li>tome.app - <a href="https://tome.app/">https://tome.app/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="slidego">Slidego<a class="headerlink" href="#slidego" title="Permanent link">#</a></h2>
<p>Free templates for Google Slides and PowerPoint</p>
<p>More at:</p>
<ul>
<li>site - <a href="https://slidesgo.com/">https://slidesgo.com/</a></li>
<li><a href="https://slidesgo.com/slidesgo-school/google-slides-tutorials/how-to-add-or-change-themes-in-google-slides">https://slidesgo.com/slidesgo-school/google-slides-tutorials/how-to-add-or-change-themes-in-google-slides</a></li>
</ul>
<p>See also [S}, ...</p>
<h2 id="small-language-model-slm">Small Language Model (SLM)<a class="headerlink" href="#small-language-model-slm" title="Permanent link">#</a></h2>
<p>A version of the language model that can be deployed on devices (such as cellphones or computer desktops).
 They often have less than a 10 billion parameters.</p>
<p>See also <a href="./">S</a>, <a href="../l/#large-language-model-llm">Large Language Model</a></p>
<h2 id="snorkel-program">Snorkel Program<a class="headerlink" href="#snorkel-program" title="Permanent link">#</a></h2>
<p>~ <mark>Unlabeled data --&gt; a weak supervision labeling function</mark></p>
<p>Snorkel is a system for programmatically building and managing training <a href="../d/#dataset">datasets</a> without manual labeling. In Snorkel, users can develop large training datasets in hours or days rather than hand-labeling them over weeks or months. Snorkel currently exposes three key programmatic operations: (1) Labeling data, e.g., using heuristic rules or distant supervision techniques (2) Transforming data, e.g., rotating or stretching images to perform data augmentation (3) Slicing data into different critical subsets for monitoring or targeted improvement.</p>
<p><img alt="" src="../img/s/snorkel_program.png" width="&quot;100%" /></p>
<p>More at:</p>
<ul>
<li>site - <a href="https://www.snorkel.org/">https://www.snorkel.org/</a></li>
<li>blog - <a href="https://www.snorkel.org/blog/">https://www.snorkel.org/blog/</a></li>
<li>articles:<ul>
<li>new snorkel - <a href="https://www.snorkel.org/blog/hello-world-v-0-9">https://www.snorkel.org/blog/hello-world-v-0-9</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../d/#data-augmentation">Data Augmentation</a>, <a href="../l/#labeling-function">Labeling Function</a>, <a href="./#slicing-function">Slicing Function</a>, [Transform Function], [Unlabelled Data Algorithm]</p>
<h2 id="sobol-search">Sobol Search<a class="headerlink" href="#sobol-search" title="Permanent link">#</a></h2>
<p>Sobol is a type of random sampling supported by sweep job types. You can use sobol to reproduce your results using seed and cover the search space distribution more evenly.</p>
<p>Sobol search is used for [hyperparameter optimization]</p>
<p>See also <a href="./">S</a>, <a href="../r/#random-search">Random Search</a></p>
<h2 id="social-bias">Social Bias<a class="headerlink" href="#social-bias" title="Permanent link">#</a></h2>
<p>Social biases are represented by language models, but it is not clear how systematically these biases manifest in applied tasks like QA</p>
<p>Examples of biases:</p>
<ul>
<li>girls are bad at math</li>
<li>older people are in cognitive decline</li>
<li>gay people are more likely to have HIV</li>
</ul>
<p>Risks:</p>
<ul>
<li>stereotype reinforcement</li>
<li>stereotype attribution</li>
</ul>
<iframe src="https://www.youtube.com/embed/JKPQ9cqBJWE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, [Bias Benchmark For Question Answering]</p>
<h2 id="social-robot">Social Robot<a class="headerlink" href="#social-robot" title="Permanent link">#</a></h2>
<p>Social <a href="../r/#robot">robots</a> are <a href="../a/#artificial-intelligence-ai">artificial intelligence</a> platforms, paired with sensors, cameras, microphones and other technology, like computer vision, so they can better interact and engage with humans or other robots.</p>
<p>Despite their lack of consciousness, social robots provide companionship and emotional and learning support to children and adults who play, talk and even snuggle with them like they would a pet. They also work together in warehouses and factories to transport goods, and are used as research and development platforms, allowing researchers to study how humans interact with robots and make even further advances in the field.</p>
<p>Today, social robots are most often found working as companions and support tools for childhood development, specifically autism therapy and social-emotional learning. Social robot pets can even be an effective form of therapy for people with dementia.</p>
<p>Social robots also work as concierges in hotels and other settings like malls, where they provide customer service.</p>
<iframe src="https://www.youtube.com/embed/3lEQDf9Cv4s" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://builtin.com/robotics/social-robot">https://builtin.com/robotics/social-robot</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="society-of-mind">Society Of Mind<a class="headerlink" href="#society-of-mind" title="Permanent link">#</a></h2>
<p>So, AGI might look like a video game, with multiple AI agents working together like a well-oiled machine, each having different roles and reaching consensus after a hearty discussion. Here, youve got an office vibe with AI-powered workers divided into departments. They are given tasks, they brainstorm, debate, plan, code, test, document the results, and finally deliver a working product, be it a game, an app, or whatever.</p>
<iframe src="https://www.youtube.com/embed/5Zj_zstLLP4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2307.07924" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2307.07924">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>MetaGPT<ul>
<li>code - <a href="https://github.com/geekan/MetaGPT">https://github.com/geekan/MetaGPT</a></li>
<li>paper - <a href="https://arxiv.org/abs/2308.00352">https://arxiv.org/abs/2308.00352</a></li>
<li>video - <a href="https://www.youtube.com/watch?v=uT75J_KG_aY">https://www.youtube.com/watch?v=uT75J_KG_aY</a></li>
<li>articles</li>
<li><a href="https://www.unite.ai/metagpt-complete-guide-to-the-best-ai-agent-available-right-now/">https://www.unite.ai/metagpt-complete-guide-to-the-best-ai-agent-available-right-now/</a></li>
</ul>
</li>
<li>ChatDev<ul>
<li>paper-with-code - <a href="https://paperswithcode.com/paper/communicative-agents-for-software-development">https://paperswithcode.com/paper/communicative-agents-for-software-development</a></li>
<li>paper - <a href="https://arxiv.org/abs/2307.07924">https://arxiv.org/abs/2307.07924</a></li>
<li>code - <a href="https://github.com/OpenBMB/ChatDev">https://github.com/OpenBMB/ChatDev</a></li>
<li>articles</li>
<li><a href="https://www.unite.ai/chatdev-communicative-agents-for-software-development/">https://www.unite.ai/chatdev-communicative-agents-for-software-development/</a></li>
</ul>
</li>
<li>AgentVerse<ul>
<li>paper-with-code - <a href="https://paperswithcode.com/paper/agentverse-facilitating-multi-agent">https://paperswithcode.com/paper/agentverse-facilitating-multi-agent</a></li>
<li>code - <a href="https://github.com/OpenBMB/AgentVerse">https://github.com/OpenBMB/AgentVerse</a></li>
<li>paper - <a href="https://arxiv.org/abs/2308.10848">https://arxiv.org/abs/2308.10848</a></li>
<li>huggingface - <a href="https://huggingface.co/spaces/AgentVerse/agentVerse">https://huggingface.co/spaces/AgentVerse/agentVerse</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="socratic-method">Socratic Method<a class="headerlink" href="#socratic-method" title="Permanent link">#</a></h2>
<p>The Socratic method is a teaching and dialogue technique rooted in the practices of the ancient Greek philosopher Socrates. It is based on asking and answering questions to stimulate critical thinking, uncover assumptions, and clarify ideas. Instead of simply presenting information or directly answering questions, the Socratic method encourages exploration through disciplined and thoughtful inquiry.</p>
<p>Questioning:</p>
<ul>
<li>The teacher or facilitator asks a series of open-ended questions.</li>
<li>These questions are designed to probe deeper into the topic, challenge assumptions, and explore underlying beliefs.</li>
</ul>
<p>Dialogue:</p>
<ul>
<li>It involves a cooperative discussion rather than a one-sided lecture.</li>
<li>Both participantsquestioner and responderactively engage in the exchange.</li>
</ul>
<p>Critical Thinking:</p>
<ul>
<li>Participants are encouraged to think logically, evaluate evidence, and refine their thoughts.</li>
<li>It helps to expose contradictions or gaps in reasoning.</li>
</ul>
<p>Learning Through Reflection:</p>
<ul>
<li>The process fosters self-discovery and learning as participants reflect on their own beliefs and knowledge.</li>
</ul>
<p>Iterative Process:</p>
<ul>
<li>The dialogue often circles back to earlier points, refining and building upon ideas as understanding deepens.</li>
</ul>
<p>/// example | Example: Imagine a conversation about justice. Instead of defining it outright, the facilitator might ask:
  * "What does it mean to be just?"
  * "Can you provide an example of a just action?"
  * "Is justice always fair? Why or why not?"
///</p>
<p>Through this dialogue, the participants would refine their understanding of justice, questioning initial assumptions and exploring the concept in depth.</p>
<p>See also <a href="./">S</a>, <a href="../r/#reasoning">Reasoning</a></p>
<h2 id="socratic-method-prompting">Socratic Method Prompting<a class="headerlink" href="#socratic-method-prompting" title="Permanent link">#</a></h2>
<p>~ prompting that requires a multi-agent environment (?) with several agents that play different roles</p>
<p><img alt="" src="../img/s/socratic_method_prompting.png" width="&quot;100%" /></p>
<object data="https://arxiv.org/pdf/2303.08769" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.08769">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2303.08769">https://arxiv.org/abs/2303.08769</a></li>
<li>code - <a href="https://github.com/RunzheYang/SocraticAI">https://github.com/RunzheYang/SocraticAI</a></li>
<li>articles<ul>
<li><a href="https://princeton-nlp.github.io/SocraticAI/">https://princeton-nlp.github.io/SocraticAI/</a></li>
<li><a href="https://giovannigatti.github.io/socratic-llm/">https://giovannigatti.github.io/socratic-llm/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="soft-actor-critic-sac-algorithm">Soft Actor-Critic (SAC) Algorithm<a class="headerlink" href="#soft-actor-critic-sac-algorithm" title="Permanent link">#</a></h2>
<p>Soft Actor Critic, or SAC, is an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the <a href="../a/#actor">actor</a> aims to maximize expected reward while also maximizing <a href="../e/#entropy">entropy</a>. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as <a href="../q/#q-learning-algorithm">Q-learning</a> methods. SAC combines off-policy updates with a stable stochastic actor-critic formulation.</p>
<p>The SAC objective has a number of advantages. First, the <a href="../p/#policy">policy</a> is incentivized to explore more widely, while giving up on clearly unpromising avenues. Second, the <a href="../p/#policy">policy</a> can capture multiple modes of near-optimal behavior. In problem settings where multiple <a href="../a/#action">actions</a> seem equally attractive, the <a href="../p/#policy">policy</a> will commit equal probability mass to those <a href="../a/#action">actions</a>. Lastly, the authors present evidence that it improves learning speed over [state-of-the-art] methods that optimize the conventional RL objective function.</p>
<iframe src="https://www.youtube.com/embed/pg-lKy7JIRk" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/1801.01290v2" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1801.01290v2">Download PDF</a>.
    </p>
</object>

<object data="https://arxiv.org/pdf/1812.05905" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1812.05905">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1812.05905">https://arxiv.org/abs/1812.05905</a><ul>
<li>SAC and applications - <a href="https://arxiv.org/abs/1812.05905">https://arxiv.org/abs/1812.05905</a></li>
</ul>
</li>
<li>code - <a href="https://paperswithcode.com/paper/soft-actor-critic-off-policy-maximum-entropy#code">https://paperswithcode.com/paper/soft-actor-critic-off-policy-maximum-entropy#code</a></li>
<li>ICML 2018 - <a href="https://icml.cc/Conferences/2018/Schedule?showEvent=1986">https://icml.cc/Conferences/2018/Schedule?showEvent=1986</a></li>
<li>Articles<ul>
<li><a href="https://bair.berkeley.edu/blog/2018/12/14/sac/">https://bair.berkeley.edu/blog/2018/12/14/sac/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, [Proximal Policy Optimization Algorithm]</p>
<h2 id="softbank-robotics-company">Softbank Robotics Company<a class="headerlink" href="#softbank-robotics-company" title="Permanent link">#</a></h2>
<p>The <a href="../c/#company">company</a> that built the <a href="../p/#pepper-robot">Pepper Robot</a></p>
<p>More at:
  * <a href="https://us.softbankrobotics.com/">https://us.softbankrobotics.com/</a></p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="softmax-function">Softmax Function<a class="headerlink" href="#softmax-function" title="Permanent link">#</a></h2>
<p>~ fit output values in [0, 1] range and sum = 1 --&gt; can be interpreted as probabilities, but not really accurate probabilities though!</p>
<p>The softmax function is a function that turns a vector of K real values into a vector of K real values that sum to 1. The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities. If one of the inputs is small or negative, the softmax turns it into a small probability, and if an input is large, then it turns it into a large probability, but it will always remain between 0 and 1.
  * Make the resulting probabilities between 0 and 1.
  * Make the sum of the resulting probabilities equal to 1.</p>
<p><img alt="" src="../img/s/softmax_function.png" width="&quot;100%" /></p>
<iframe src="https://www.youtube.com/embed/8ps_JEW42xs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/KpKog-L9veg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/M59JElEPgIg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, <a href="../a/#argmax-function">Argmax Function</a>, <a href="../f/#feedforward-neural-network">Feedforward Neural Network</a></p>
<h2 id="softplus-activation-function">Softplus Activation Function<a class="headerlink" href="#softplus-activation-function" title="Permanent link">#</a></h2>
<p>Pros:</p>
<ul>
<li>...</li>
</ul>
<p>Cons:</p>
<ul>
<li>...</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="software-10">Software 1.0<a class="headerlink" href="#software-10" title="Permanent link">#</a></h2>
<p>The classical stack of Software 1.0 is what were all familiar with  it is written in languages such as Python, C++, etc. It consists of explicit instructions to the computer written by a programmer. By writing each line of code, the programmer identifies a specific point in program space with some desirable behavior.</p>
<p>See also <a href="./">S</a>, <a href="./#software-20">Software 2.0</a></p>
<h2 id="software-20">Software 2.0<a class="headerlink" href="#software-20" title="Permanent link">#</a></h2>
<p>Software 2.0 is written in much more abstract, human unfriendly language, such as the weights of a neural network. No human is involved in writing this code because there are a lot of weights (typical networks might have millions), and coding directly in weights is kind of hard (I tried). Instead, our approach is to specify some goal on the behavior of a desirable program (e.g., satisfy a dataset of input output pairs of examples, or win a game of Go), write a rough skeleton of the code (i.e. a neural net architecture) that identifies a subset of program space to search, and use the computational resources at our disposal to search this space for a program that works. In the case of neural networks, we restrict the search to a continuous subset of the program space where the search process can be made (somewhat surprisingly) efficient with backpropagation and stochastic gradient descent.</p>
<p><img alt="" src="../img/s/software_2_0.png" width="&quot;100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="./#software-10">Software 1.0</a></p>
<h2 id="software-development-life-cycle-sdlc">Software Development Life Cycle (SDLC)<a class="headerlink" href="#software-development-life-cycle-sdlc" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../d/#development-life-cycle">Development Life Cycle</a></p>
<h2 id="software-development-life-cycle-sdlc-agent">Software Development Life Cycle (SDLC) Agent<a class="headerlink" href="#software-development-life-cycle-sdlc-agent" title="Permanent link">#</a></h2>
<p>An <a href="../a/#agent">Agent</a> that automated the development lifecycle:</p>
<ul>
<li>Sprint agent - Breaks down a request into subtasks, add description of tasks, adds acceptance criteria, estimate effort</li>
<li>Dev agent - transition JIRA to "in progress" and create feature branch, generates relevant code given sub-tasks from sprint agent</li>
<li>Test agent - Write unit tests and scenarios for code given acceptance criteria, commits and pushes code and unit tests to code repository</li>
<li>Peer Review agent - transitions tasks to "Peer Review" state in JIRA, provides thorough review of code as part of description of pull request, creates a pull request to merge branch into master</li>
</ul>
<p>The final output = application fully generated automatically using SDLC chain given the task</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>As a trader, I want to create an application that lets me customize and viualize charts for different stock options so that I can compare different stocks at different points in times
</span></code></pre></div>
<p><img alt="" src="../img/s/software_development_life_cycle_agent.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sophia-robot">Sophia Robot<a class="headerlink" href="#sophia-robot" title="Permanent link">#</a></h2>
<p>Sophia is a social humanoid robot developed by the Hong Kong-based company <a href="../h/#hanson-robotics-company">Hanson Robotics</a>. Sophia was activated on February 14, 2016, and made its first public appearance in mid-March 2016 at South by Southwest (SXSW) in Austin, Texas, United States. Sophia is marketed as a "social robot" that can mimic social behavior and induce feelings of love in humans.</p>
<iframe src="https://www.youtube.com/embed/BhU9hOo5Cuc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Sophia_(robot)">https://en.wikipedia.org/wiki/Sophia_(robot)</a> </li>
</ul>
<p>See also <a href="./">S</a>, <a href="../r/#robot">Robot</a></p>
<h2 id="sora-model">Sora Model<a class="headerlink" href="#sora-model" title="Permanent link">#</a></h2>
<p>Diffusion model built by <a href="../o/#openai-company">OpenAI</a> used to generate 60 sec videos</p>
<p>Release data: 02/2024</p>
<p>More at:</p>
<ul>
<li>site - <a href="https://openai.com/sora">https://openai.com/sora</a></li>
<li>annuncement - <a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a></li>
<li>articles<ul>
<li><a href="https://www.cnn.com/2024/02/15/tech/openai-text-to-video-sora/index.html">https://www.cnn.com/2024/02/15/tech/openai-text-to-video-sora/index.html</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="soul-machine-company">Soul Machine Company<a class="headerlink" href="#soul-machine-company" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sound-analysis">Sound Analysis<a class="headerlink" href="#sound-analysis" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="source-knowledge">Source Knowledge<a class="headerlink" href="#source-knowledge" title="Permanent link">#</a></h2>
<p><a href="../k/#knowledge">Knowledge</a> stored in the vector database</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="spam-detection">Spam Detection<a class="headerlink" href="#spam-detection" title="Permanent link">#</a></h2>
<p>The spam filtering in your email inbox assigns a percentage of the incoming emails to the spam folder, using NLP to evaluate which emails look suspicious.</p>
<p>See also <a href="./">S</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a></p>
<h2 id="space">Space<a class="headerlink" href="#space" title="Permanent link">#</a></h2>
<p>Relates to how an object is represented. In pixel space, an image consist of pixels or pixel parameters (e.g RGB + position). In a latent space, images are encoded and represented by a different tensor. Each time an object is represented differently, that transition make be lossy or lossless.</p>
<p>See also <a href="./">S</a>, <a href="../l/#latent-space">Latent Space</a>, <a href="../p/#pixel-space">Pixel Space</a></p>
<h2 id="sparse-mixture-of-experts-smoe-architecture">Sparse Mixture-Of-Experts (SMoE) Architecture<a class="headerlink" href="#sparse-mixture-of-experts-smoe-architecture" title="Permanent link">#</a></h2>
<p>~ like an <a href="../e/#ensemble-method">ensemble method</a> except that typically only one or a few expert models will be run rather than combining the results.</p>
<p>In 1991, MoE was first introduced by a research group that included deep-learning and Switch Transformer creator Geoff Hinton. In 2017, the Google Brain team and Hinton used MoE to create an NLP model based on recurrent neural networks (RNN) of 137 billion parameters, where it achieved state-of-the-art (SOTA) results on language modelling and machine translation benchmarks.</p>
<p>What does an expert learn? The ST-MoE authors observed that encoder experts specialize in a group of tokens or shallow concepts. For example, we might end with a punctuation expert, a proper noun expert, etc. On the other hand, the decoder experts have less specialization. The authors also trained in a multilingual setup. Although one could imagine each expert specializing in a language, the opposite happens: due to token routing and load balancing, there is no single expert specialized in any given language.</p>
<p><img alt="" src="../img/s/sparse_mixture_of_experts.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/RYZ0FMAKRFs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at :</p>
<ul>
<li>paper - <a href="http://www.cs.toronto.edu/~fritz/absps/jjnh91.pdf">http://www.cs.toronto.edu/~fritz/absps/jjnh91.pdf</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/Mixture_of_experts">https://en.wikipedia.org/wiki/Mixture_of_experts</a></li>
<li>iarticles<ul>
<li>in-depth - <a href="https://github.com/huggingface/blog/blob/main/moe.md">https://github.com/huggingface/blog/blob/main/moe.md</a></li>
</ul>
</li>
</ul>
<p>See also <a href="../m/">M</a>, <a href="./#sparsity">Sparsity</a>, <a href="./#switch-transformer-model">Switch Transformer</a></p>
<h2 id="sparsity">Sparsity<a class="headerlink" href="#sparsity" title="Permanent link">#</a></h2>
<p>Sparsity uses the idea of conditional computation. While in dense models all the parameters are used for all the inputs, sparsity allows us to only run some parts of the whole system.</p>
<p>There are several ways to do this:</p>
<ul>
<li>In the same model, you turn of some neurons</li>
<li>When using a [Model-Of-Experts architecture], you can select one model instead of all of them. This leaders to the [sparse model-of-experts architecture]</li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://github.com/huggingface/blog/blob/main/moe.md#what-is-sparsity">https://github.com/huggingface/blog/blob/main/moe.md#what-is-sparsity</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="sparrow-model">Sparrow Model<a class="headerlink" href="#sparrow-model" title="Permanent link">#</a></h2>
<p><a href="../g/#google-company">Google</a>'s answer to chatGPT. To be released in mid 2023.</p>
<object data="https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://medium.com/@tokamalpathak/chatgpt-and-google-sparrow-the-future-of-ai-powered-communication-5febb200f5ab">https://medium.com/@tokamalpathak/chatgpt-and-google-sparrow-the-future-of-ai-powered-communication-5febb200f5ab</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../c/#chatgpt-model">ChatGPT Model</a></p>
<h2 id="sparse-activation">Sparse Activation<a class="headerlink" href="#sparse-activation" title="Permanent link">#</a></h2>
<p>We have many different parts of our brain that are specialized for different tasks, yet we only call upon the relevant pieces for a given situation. There are close to a hundred billion neurons in your brain, but you rely on a small fraction of them to interpret this sentence. AI can work the same way. We can build a single model that is sparsely activated, which means only small pathways through the network are called into action as needed. In fact, the model dynamically learns which parts of the network are good at which tasks -- it learns how to route tasks through the most relevant parts of the model. A big benefit to this kind of architecture is that it not only has a larger capacity to learn a variety of tasks, but its also faster and much more energy efficient, because we dont activate the entire network for every task.</p>
<p>More at:</p>
<ul>
<li>pathways - <a href="https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/">https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../d/#dense-model">Dense Model</a>, <a href="../p/#pathways-model-architecture">Pathways Model Architecture</a></p>
<h2 id="sparse-matrix">Sparse Matrix<a class="headerlink" href="#sparse-matrix" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="./#sparse-vector">Sparse Vector</a></p>
<h2 id="sparse-model">Sparse Model<a class="headerlink" href="#sparse-model" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../u/#unstructured-pruning">Unstructured Pruning</a></p>
<h2 id="sparse-tensor">Sparse Tensor<a class="headerlink" href="#sparse-tensor" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="./#sparse-vector">Sparse Vector</a></p>
<h2 id="sparse-vector">Sparse Vector<a class="headerlink" href="#sparse-vector" title="Permanent link">#</a></h2>
<p>A vector/list that has mostly the 0 element.</p>
<p>See also <a href="./">S</a>, <a href="../v/#vector">Vector</a></p>
<h2 id="specificity">Specificity<a class="headerlink" href="#specificity" title="Permanent link">#</a></h2>
<p>~ true negative rate. = probability of a negative test given the patient is doing well. Specificity refers to the probability of a negative test, conditioned on truly being negative. </p>
<p>/// Examples | How many healthy people were CORRECTLY identified as not having the condition.
///</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a># P(Pos) = Probability of getting a positive test result
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a># P(D) = The probability of a person having diabetes
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a># P(~D) = The probabilitiy of a person NOT having diabetes
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>## Sensitivity = 
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>## Specificity =
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>P(Pos) = [P(D) * Sensitivity] + [P(~D) * (1-Specificity))]
</span></code></pre></div>
<p>More at:</p>
<ul>
<li><a href="https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5">https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a>, <a href="./#sensitivity">Sensitivity</a></p>
<h2 id="spectrogram">Spectrogram<a class="headerlink" href="#spectrogram" title="Permanent link">#</a></h2>
<p>Turn sound into frequencies represented in an image. That image can then be processed by CycleGAN or other!</p>
<p>See also <a href="./">S</a>, [CycleGAN]</p>
<h2 id="speech-recognition">Speech Recognition<a class="headerlink" href="#speech-recognition" title="Permanent link">#</a></h2>
<p>See [Automated Speech Recognition]</p>
<h2 id="speech-to-text-stt-model">Speech-To-Text (STT) Model<a class="headerlink" href="#speech-to-text-stt-model" title="Permanent link">#</a></h2>
<p>Speech-to-text models transcribe speech into text! The opposite of a <a href="../t/#text-to-speech-tts-model">Text-To-Speech (TTS) model</a></p>
<p>Models:</p>
<ul>
<li><a href="../w/#whisper-model">Whisper Model</a> by <a href="../o/#openai-company">OpenAI</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="speechx-model">SpeechX Model<a class="headerlink" href="#speechx-model" title="Permanent link">#</a></h2>
<p>Model developed by <a href="../m/#microsoft-company">Microsoft</a></p>
<p>Use-cases:</p>
<ul>
<li>Zero-shot text-to-speech</li>
<li>Spoken content editing</li>
<li>Background-preserving spoken content editing</li>
<li>Noise suppression</li>
<li>Target speaker extraction</li>
<li>Speech removal</li>
</ul>
<p>The proposed SpeechX is built upon VALL-E, which leverages the Transformer-based neural codec language model - EnCodec to generate neural codes conditioned on textual and acoustic prompts. More specifically, SpeechX uses autoregressive (AR) to output the neural codes of the first quantization layer of EnCodec and non-auto-regressive (NAR) Transformer models to produce the neural codes of all the layers above the first layer. The combination of these two models provides a reasonable trade-off between generation flexibility and inference speed.</p>
<p>To enable SpeechX to handle multiple tasks, the researchers adopt task-based prompting, which incorporates additional tokens in the multi-task learning setup, where the tokens collectively control what task to be executed. As a result, SpeechX is able to acquire knowledge of diverse tasks, facilitating a versatile and highly extensible speech generation process.</p>
<p><img alt="" src="../img/s/speechx_model_comparison.png" width="&quot;100%" /></p>
<p>In their empirical study, the team compared SpeechX to the baseline expert models on various tasks, e.g. noise suppression, target speaker extraction, zero-shot TTS, clean speech editing, speech removal and etc. SpeechX achieves comparable and even superior performance to baseline models across various tasks. The team believes their work is an important step toward unified generative speech models.</p>
<object data="https://arxiv.org/pdf/2308.06873" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2308.06873">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2308.06873">https://arxiv.org/abs/2308.06873</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="spot-robot">Spot Robot<a class="headerlink" href="#spot-robot" title="Permanent link">#</a></h2>
<p>A robot dog developed by <a href="../b/#boston-dynamics-company">Boston Dynamics</a></p>
<iframe src="https://www.youtube.com/embed/Fmj5r8ws2Mw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/7Wm6vy7yBNA" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://www.bostondynamics.com/products/spot">https://www.bostondynamics.com/products/spot</a></li>
<li>articles<ul>
<li><a href="https://www.wired.com/story/spot-boston-dynamics/">https://www.wired.com/story/spot-boston-dynamics/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="squad-benchmark">SQuAD Benchmark<a class="headerlink" href="#squad-benchmark" title="Permanent link">#</a></h2>
<p>A benchmark for NLP models for question answering.</p>
<p>See also <a href="./">S</a>, <a href="../b/#benchmark">Benchmark</a>, <a href="../q/#question-answering-qa">Question Answering</a></p>
<h2 id="stability-ai-company">Stability AI Company<a class="headerlink" href="#stability-ai-company" title="Permanent link">#</a></h2>
<p>The <a href="../c/#company">company</a> that created :</p>
<ul>
<li><a href="./#stable-code-model">Stable Code</a></li>
<li><a href="./#stable-diffusion-model">Stable Diffusion</a></li>
</ul>
<p>More at:</p>
<ul>
<li>site - <a href="https://stability.ai/">https://stability.ai/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="stable-code-model">Stable Code Model<a class="headerlink" href="#stable-code-model" title="Permanent link">#</a></h2>
<p>Stable Code offers a unique way for developers to become more efficient by using three different models to help in their coding. The base model was first trained on a diverse set of programming languages from the stack-dataset (v1.2) from BigCode and then trained further with popular languages like Python, Go, Java, Javascript, C, markdown and C++.  In total, we trained our models on 560B tokens of code on our HPC cluster. </p>
<p>After the base model had been established, the instruction model was then tuned for specific use cases to help solve complex programming tasks. ~120,000 code instruction/response pairs in Alpaca format were trained on the base model to achieve this result. </p>
<iframe src="https://www.youtube.com/embed/knt5svAL0SI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://stablecode.dev/">https://stablecode.dev/</a></li>
<li>announcement - <a href="https://stability.ai/blog/stablecode-llm-generative-ai-coding">https://stability.ai/blog/stablecode-llm-generative-ai-coding</a></li>
<li>models <ul>
<li>base - <a href="https://huggingface.co/stabilityai/stablecode-completion-alpha-3b-4k">https://huggingface.co/stabilityai/stablecode-completion-alpha-3b-4k</a></li>
<li>instruction - <a href="https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b">https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b</a></li>
</ul>
</li>
<li>stack dataset - <a href="https://www.bigcode-project.org/docs/about/the-stack/">https://www.bigcode-project.org/docs/about/the-stack/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="stable-diffusion-model">Stable Diffusion Model<a class="headerlink" href="#stable-diffusion-model" title="Permanent link">#</a></h2>
<p>[Denoising Diffusion Probabilistic Model] by <a href="./#stability-ai-company">Stability AI</a></p>
<p>There are 2 versions:</p>
<ul>
<li>v1.5 - support for NSFW, more custom models, better ControlNet support, more LoRA, TIs, have more artists and celebrities in the training data image set. Training set is 512x512, so optimal size for quick exploration is 512x512, which is kind of limited.</li>
<li>v2.x - Better support for photos, landscape. Training set is 768x768 so one get more interesting composition and detail, easier to explore and experiment starting at 768x768. Has one great model: Illuminati v1.1 that can produce interesting images with minimum prompting, kind of like Midjourney. Some "controversial" artist such as Greg Rutkowski has been removed. </li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://aituts.com/models">https://aituts.com/models</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="standard-knowledge-distillation">Standard Knowledge Distillation<a class="headerlink" href="#standard-knowledge-distillation" title="Permanent link">#</a></h2>
<p>A [knowledge distillation] method that aims to transfer the general knowledge of the teacher model to the student. For instance, you can gather a series of prompts and responses from ChatGPT and use them to train a smaller open-source LLM. However, its important to note that there are restrictions on training LLMs on data gathered from commercial models.</p>
<p>The challenge with standard knowledge distillation lies in accurately capturing the underlying data distributions. MiniLLM, a technique developed by researchers at Tsinghua University and Microsoft Research, addresses this issue. It employs different objective and optimization functions specifically designed for LLMs, enhancing the effectiveness of the distillation process.</p>
<p>More at:</p>
<ul>
<li><a href="https://bdtechtalks.com/2023/09/18/what-is-llm-compression/">https://bdtechtalks.com/2023/09/18/what-is-llm-compression/</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../e/#emergent-ability-distillation">Emergent Ability Distillation</a>, <a href="../m/#model-compression">Model Compression</a></p>
<h2 id="standardization">Standardization<a class="headerlink" href="#standardization" title="Permanent link">#</a></h2>
<p>Make mean 0 and variance 1</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="stanford-autonomous-helicopter">Stanford Autonomous Helicopter<a class="headerlink" href="#stanford-autonomous-helicopter" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/0JL04JJjocc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, <a href="../a/#apprentice-learning">Apprentice Learning</a>, <a href="./#stanford-university">Stanford University</a></p>
<h2 id="stanford-natural-language-inference-snli">Stanford Natural Language Inference (SNLI)<a class="headerlink" href="#stanford-natural-language-inference-snli" title="Permanent link">#</a></h2>
<p>Natural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), is the task of determining the inference relation between two (short, ordered) texts: entailment, contradiction, or neutral.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>Text                                                                    Judgments                 Hypothesis
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>A man inspects the uniform of a figure in some East Asian country.  C C C C C   The man is sleeping
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>                                                                       contradiction
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>An older and younger man smiling.                                       N N E N N       Two men are smiling and laughing at the cats playing on the floor.
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>                                                                        neutral
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>A black race car starts up in front of a crowd of people.               C C C C C       A man is driving down a lonely road.
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>                                                                       contradiction
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>A soccer game with multiple males playing.                              E E E E E       Some men are playing a sport.
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>                                                                        entailment
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>A smiling costumed woman is holding an umbrella.                        N N E C N       A happy woman in a fairy costume holds an umbrella.
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>                                                                         neutral
</span></code></pre></div>
<p>See also <a href="./">S</a>, <a href="../b/#benchmark">Benchmark</a>, <a href="./#stanford-university">Stanford University</a></p>
<h2 id="stanford-university">Stanford University<a class="headerlink" href="#stanford-university" title="Permanent link">#</a></h2>
<ul>
<li>Medical applications</li>
<li>AIMI or <a href="https://aimi.stanford.edu/">AI in Medicine and Imaging</a> or AIMI<ul>
<li>blog - <a href="https://aimi.stanford.edu/blog">https://aimi.stanford.edu/blog</a></li>
</ul>
</li>
<li>QIAI or <a href="https://rubinlab.stanford.edu/">Quantitative Imaging and Artificial Intelligence</a> - Daniel L. Rubin, MD, MS</li>
<li>CERC or <a href="https://med.stanford.edu/cerc.html">Clinical Excellence Research Center</a> - <a href="https://profiles.stanford.edu/arnold-milstein">Arnold Milstein</a><ul>
<li>blog - <a href="https://med.stanford.edu/cerc/research/computer-vision.html">https://med.stanford.edu/cerc/research/computer-vision.html</a>  </li>
</ul>
</li>
<li>Agentic</li>
<li>Stanford OVAL or <a href="https://newoval.netlify.app/">Open Virtual Assistant Lab</a> - Monica Lam. <ul>
<li>Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking or <a href="https://storm.genie.stanford.edu/">STORM</a></li>
<li>paper - <a href="https://arxiv.org/abs/2402.14207">https://arxiv.org/abs/2402.14207</a></li>
</ul>
</li>
<li>Robotics</li>
<li>ILIAD or <a href="https://iliad.stanford.edu/">Intelligent and Interactive Autonomous Systems Group</a> led by <a href="https://dorsa.fyi/">Dorsa Sadigh</a></li>
<li><a href="https://www.autonomousagents.stanford.edu/">Autonomous lab agent</a></li>
<li>CRFM or <a href="https://crfm.stanford.edu/">Center for Research on Foundation Model</a></li>
<li><a href="https://neuroscience.stanford.edu/">Neuroscience</a></li>
<li>SAIL or <a href="https://ai.stanford.edu/">Stanford AI Lab</a></li>
<li>blog - <a href="https://ai.stanford.edu/blog/">https://ai.stanford.edu/blog/</a></li>
<li>HAI or <a href="https://hai.stanford.edu/">Human Centered Artificial Intelligence</a> led by <a href="https://philosophy.stanford.edu/people/john-w-etchemendy">John Etchmendy</a> and <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a></li>
<li>blog - <a href="https://hai.stanford.edu/news/what-dall-e-reveals-about-human-creativity">https://hai.stanford.edu/news/what-dall-e-reveals-about-human-creativity</a></li>
<li>
<p>ai4all - <a href="https://nidhiparthasarathy.medium.com/my-summer-at-ai4all-f06eea5cdc2e">https://nidhiparthasarathy.medium.com/my-summer-at-ai4all-f06eea5cdc2e</a></p>
</li>
<li>
<p>Collaboration</p>
</li>
<li><a href="../a/#arc-institute">Arc Institute</a> - </li>
<li><a href="https://stanford-medai.github.io/">MedAI Group Exchange</a><ul>
<li>mailing list - <a href="https://mailman.stanford.edu/mailman/listinfo/medai_announce">https://mailman.stanford.edu/mailman/listinfo/medai_announce</a></li>
</ul>
</li>
<li>
<p><a href="../n/#national-artificial-intelligence-research-resource-nairr">National Artificial Intelligence Research Resource (NAIRR)</a> - connect U.S. researchers and educators to computational, data, and training resources needed to advance AI research and research that employs AI.</p>
</li>
<li>
<p>Assets</p>
</li>
<li>Algorithms<ul>
<li><a href="../g/#global-vector-glove-algorithm">GloVe</a> - vector representations for words</li>
</ul>
</li>
<li>Models</li>
</ul>
<iframe src="https://www.youtube.com/embed/4W2kXBBFDw4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/se4CQ5UZXaM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, ...</p>
<h2 id="state">State<a class="headerlink" href="#state" title="Permanent link">#</a></h2>
<p>In reinforcement learning, links the agent and the environment. 
 For every state the agent takes a decision to reach its goal. </p>
<div class="admonition warning">
<p class="admonition-title">Beware:</p>
<ul>
<li>Sometimes you do not know the state, but can make an observation that is strongly correlated to the state.</li>
</ul>
</div>
<p>A state represents a snapshot of the environment the agent is in at a point in time. State is a numerical representation of what an agent observes at a particular point in an environment. For AWS DeepRacer, a state is the representation of an image captured by the front-facing camera on the vehicle. The agent takes an action, guided by a strategy referred to as a policy, at a given environment state and reaches a new state.</p>
<p>See also <a href="./">S</a>, <a href="../o/#observation">Observation</a>, <a href="../r/#reinforcement-learning-rl">Reinforcement Learning</a></p>
<h2 id="state-model">State Model<a class="headerlink" href="#state-model" title="Permanent link">#</a></h2>
<p>When you go from one state to the other.</p>
<p>See also <a href="./">S</a>, <a href="../a/#adversarial-model">Adversarial Model</a>, [Hidden Markov Model], <a href="../m/#markov-decision-process-mdp">Markov Decision Process</a>, <a href="../m/#model-type">Model Type</a>, <a href="./#search-problem">Search Problem</a></p>
<h2 id="state-space">State Space<a class="headerlink" href="#state-space" title="Permanent link">#</a></h2>
<p>A state space is either:</p>
<ul>
<li>Discrete = A discrete state space refers to a system or problem that has a finite or countable number of distinct states. In this context, "discrete" means that the states are separate and distinct, with no intermediate values between them. Examples of discrete state spaces include a set of integers, a finite set of symbols, or a collection of states in a finite state machine. In contrast, a continuous state space would have an infinite number of possible states, such as real numbers within a specific range.</li>
<li>Continuous = A continuous state space refers to a system or problem that has an infinite number of possible states, typically described by real numbers within a certain range. In a continuous state space, the states can take on any value within a specified interval or domain, and there are infinitely many possible values between any two states. Examples of continuous state spaces include the position of an object along a continuous line, the temperature of a room, or the velocity of a moving vehicle. Continuous state spaces are often described using mathematical functions or equations.</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../o/#objective-function">Objective Function</a></p>
<h2 id="state-space-model-ssm">State Space Model (SSM)<a class="headerlink" href="#state-space-model-ssm" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/s/state_space_model.png" width="&quot;100%" /></p>
<p>More at:</p>
<ul>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/State-space_representation">https://en.wikipedia.org/wiki/State-space_representation</a></li>
<li>articles<ul>
<li>SSM with S4 Model - <a href="https://srush.github.io/annotated-s4/#part-1-state-space-models">https://srush.github.io/annotated-s4/#part-1-state-space-models</a></li>
<li>SSM - <a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3">https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="state-transition">State Transition<a class="headerlink" href="#state-transition" title="Permanent link">#</a></h2>
<p>A state transition occurs at each step in a period. If the agent is exploring, the action is taken randomly. If the agent is exploiting, the state-action pari with the highest Q-value is chosen. A transition from state s to state s' given an action is probabilistic (?) For example, with DeepRacer it is possible there is no friction on the road and therefore after an action the state s' is still state s'. A state is identified based on the agent sensing the environment.</p>
<p>In reinforcement learning, state transitions refer to how the environment changes from one state to another in response to the agent's actions. Here are some key points:</p>
<ul>
<li>At each timestep, the agent observes the current <a href="./#state">state</a>, takes an <a href="../a/#action">action</a>, and the <a href="../e/#environment">environment</a> transitions to a new state.</li>
<li>The state transition is the change from the current state to the next state as a result of the agent's action.</li>
<li>The dynamics of the environment determine the transitions. After taking an action At in state St, the environment updates to state St+1 according to these dynamics.</li>
<li>For example, a robot taking a step forward could transition from state "middle of room" to state "front of room". An enemy moved in a game transitions the state to reflect its new position.</li>
<li>State transitions can be stochastic - there may be a probability distribution over possible next states from the current state-action pair.</li>
<li>Understanding state transitions helps agents maximize long-term reward. Favorable transitions that lead closer to the goal are preferable.</li>
<li><a href="../m/#model-based-reinforcement-learning">Model-based RL</a> approaches explicitly learn a model of state transitions. <a href="../m/#model-free-reinforcement-learning">Model-free RL</a> methods like <a href="../q/#q-learning-algorithm">Q-learning</a> learn without modeling transitions.</li>
</ul>
<p>In summary, state transitions describe how the environment changes state in response to actions, which is key for agents to understand in order to optimize behavior.</p>
<p>See also [], ...</p>
<h2 id="state-action-pair">State-Action Pair<a class="headerlink" href="#state-action-pair" title="Permanent link">#</a></h2>
<p>Use to find the corresponding Q-value in the Q-Table.</p>
<p>In reinforcement learning, a state-action pair refers to the combination of a state and an action taken from that state. Some key points:</p>
<ul>
<li>A state captures the current situation or <a href="../e/#environment">environment</a> the <a href="../a/#agent">agent</a> is observing. It summarizes relevant details into a representation.</li>
<li>An action is one of the moves or decisions an agent can take from a given state. The set of valid actions may differ between states.</li>
<li>A state-action pair represents the agent taking a specific action while in a specific state. For example, moving left while at intersection A.</li>
<li>The core goal in RL is to learn which actions are optimal for each state - i.e. learn the best <a href="../p/#policy">policy</a> mapping <a href="./#state">states</a> to <a href="../a/#action">actions</a>.</li>
<li>Q-learning and other RL algorithms work by estimating value functions for state-action pairs - i.e. estimating the value or utility of taking given actions at given states.</li>
<li>Exploration strategies allow the agent to try different actions from a state to discover the optimal ones.</li>
<li>The full set of state-action pairs defines the environment's dynamics - how actions influence <a href="./#state-transition">transitions between states</a>.</li>
<li>State-action pairs are central to both planning and learning in RL. They form the basic building blocks for learning optimal behavior.</li>
</ul>
<p>So in summary, state-action pairs represent the core link between states, actions, and values that reinforcement learning agents leverage to maximize <a href="../c/#cumulative-reward">cumulative reward</a>.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="state-action-reward-state-action-sarsa-algorithm">State-Action-Reward-State-Action (SARSA) Algorithm<a class="headerlink" href="#state-action-reward-state-action-sarsa-algorithm" title="Permanent link">#</a></h2>
<p>SARSA is another [reinforcement learning algorithm] that is similar to <a href="../q/#q-learning-algorithm">Q-learning</a>. SARSA stands for State-Action-Reward-State-Action, which reflects the sequence of information that the algorithm uses to learn.</p>
<p>Like <a href="../q/#q-learning-algorithm">Q-learning</a>, SARSA is a <a href="../v/#value-based-algorithm">value-based algorithm</a> that aims to learn an optimal <a href="../p/#policy">policy</a> for decision-making in a <a href="../m/#markov-decision-process-mdp">Markov Decision Process (MDP)</a>. It is suitable for problems with discrete <a href="./#state">state</a> and <a href="../a/#action">action</a> spaces.</p>
<p>In SARSA, the <a href="../a/#agent">agent</a> interacts with the <a href="../e/#environment">environment</a> by taking <a href="../a/#action">actions</a> based on its current <a href="../p/#policy">policy</a>. After each <a href="../a/#action">action</a>, the <a href="../a/#agent">agent</a> receives a <a href="../r/#reward">reward</a> and transitions to a new <a href="./#state">state</a>. SARSA updates its <a href="../q/#q-value">Q-values</a> based on the observed <a href="./#state">state</a>, <a href="../a/#action">action</a>, <a href="../r/#reward">reward</a>, and the next state and action taken by following the current <a href="../p/#policy">policy</a>.</p>
<p>The SARSA update rule uses a form of temporal difference learning, similar to <a href="../q/#q-learning-algorithm">Q-learning</a> and based on the <a href="../b/#bellman-equation">Bellman equation</a>. It updates the <a href="../q/#q-value">Q-value</a> of the previous state-action pair based on the <a href="../r/#reward">reward</a> received, the <a href="../q/#q-value">Q-value</a> of the next state-action pair, and the agent's <a href="../l/#learning-rate">learning rate</a> and <a href="../d/#discount-factor">discount factor</a>.</p>
<p>The key difference between SARSA and Q-learning lies in the way they update their Q-values. While <a href="../q/#q-learning-algorithm">Q-learning</a> uses the maximum Q-value of the next state to update the <a href="../q/#q-value">Q-value</a> of the current state-action pair, SARSA uses the <a href="../q/#q-value">Q-value</a> of the next state-action pair that the <a href="../a/#agent">agent</a> actually chooses based on its current <a href="../p/#policy">policy</a>. In other words, SARSA is an on-policy algorithm that updates its Q-values based on the actions it takes during the learning process.</p>
<p>SARSA has been successfully applied in various domains, including game playing, <a href="../r/#robotics">robotics</a>, and <a href="../c/#control-system">control systems</a>. It allows the agent to learn an <a href="../o/#optimal-policy">optimal policy</a> by iteratively updating the <a href="../q/#q-value">Q-values</a> based on observed interactions with the <a href="../e/#environment">environment</a>.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="state-of-the-art-sota">State-Of-The-Art (SOTA)<a class="headerlink" href="#state-of-the-art-sota" title="Permanent link">#</a></h2>
<p>The model that scored the highest based on the available benchmarks.</p>
<p>See also <a href="./">S</a>, <a href="../m/#model-benchmark">Model Benchmark</a></p>
<h2 id="state-value-function">State-Value Function<a class="headerlink" href="#state-value-function" title="Permanent link">#</a></h2>
<p>The expected reward when entering a state. The state-value function tells us how good any given state is for the agent, whereas the <a href="../a/#action-value-function">action-value function</a> tells us how good it is for the agent to take any action from a given state.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="statistical-bias">Statistical Bias<a class="headerlink" href="#statistical-bias" title="Permanent link">#</a></h2>
<p>Difference between an estimator's expected value (take average because randomness) and the true value</p>
<ul>
<li>if systematically overshooting or undershooting = statistical bias</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../b/#bias">Bias</a></p>
<h2 id="statistical-machine-translation-smt">Statistical Machine Translation (SMT)<a class="headerlink" href="#statistical-machine-translation-smt" title="Permanent link">#</a></h2>
<p>A <a href="../m/#machine-translation">Machine Translation</a> paradigm where translations are generated on the basis of statistical models.</p>
<p>Has been superseded by [Neural Machine Translation]</p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">https://en.wikipedia.org/wiki/Statistical_machine_translation</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="statistical-model">Statistical Model<a class="headerlink" href="#statistical-model" title="Permanent link">#</a></h2>
<p>Completely different from <a href="../a/#artificial-neural-network-ann">artificial neural networks</a></p>
<p>Usage:</p>
<ul>
<li>[Statistical Model Translation]</li>
<li>...</li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Statistical_model">https://en.wikipedia.org/wiki/Statistical_model</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="./#scaling-law">Scaling Law</a></p>
<h2 id="statistics">Statistics<a class="headerlink" href="#statistics" title="Permanent link">#</a></h2>
<p>Statistics and probability are two closely related fields, but they have distinct differences.</p>
<p><a href="../p/#probability">Probability</a> is the branch of mathematics that deals with the study of random events or phenomena. It provides a way to quantify the likelihood of an event occurring. Probability theory is used to make predictions about the likelihood of future events based on past observations and data. Probability is used in many areas such as finance, physics, engineering, and computer science.</p>
<p>Statistics, on the other hand, is the science of collecting, analyzing, and interpreting data. It is concerned with making inferences and drawing conclusions from data. Statistics provides methods for summarizing and describing data, as well as making predictions and testing hypotheses. It is used in many fields such as business, medicine, social sciences, and economics.</p>
<p>In summary, probability is focused on the theoretical study of random events, while statistics is concerned with the practical application of data analysis to make inferences and draw conclusions.</p>
<p>See also <a href="./">S</a>, <a href="../b/#big-data">Big Data</a></p>
<h2 id="steerability">Steerability<a class="headerlink" href="#steerability" title="Permanent link">#</a></h2>
<p>~ Set the behavior of the <a href="../l/#large-language-model-llm">LLM</a> in a <a href="./#system-prompt">system prompt</a></p>
<p>A property of large language models, where you can use a system prompt to tell them to behave a certain way.
 This started being possible with the <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT-4</a> model, where you could specify it needs to behave like a Socratic tutor, ask questions, and never give the answer, and it would do it! </p>
<p>Using earlier model, such as <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT-3</a> and derivative, regardless of the direction you were putting in the prompt, the <a href="../l/#large-language-model-llm">LLM</a> would not follow the direction.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="step-activation-function">Step Activation Function<a class="headerlink" href="#step-activation-function" title="Permanent link">#</a></h2>
<p>When input is &lt;0, output is 0
 When input is &gt;0, output is 1</p>
<p>Not continuous in 0!</p>
<p>A preferred activation function which is continuous in 0 is the <a href="./#sigmoid-activation-function">sigmoid</a></p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Heaviside_step_function">https://en.wikipedia.org/wiki/Heaviside_step_function</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="step-back-prompting">Step-Back Prompting<a class="headerlink" href="#step-back-prompting" title="Permanent link">#</a></h2>
<p>A <a href="../p/#prompt-engineering">prompt engineering</a> method which involves just adding one additional prompt to give the model the freedom to do some abstract thinking before addressing the primary question.</p>
<p>Step-Back Prompting is broken down into 2 steps</p>
<ol>
<li>Abstraction: Rather than addressing the question head-on, we would first prompt the LLM to ask a more generic question about a high-level concept, still related to the main question</li>
<li>Reasoning: Using the first prompt and answer as a grounding mechanism, the LLM can now more accurately reason about a solution to the main question</li>
</ol>
<p>For example if the main question was What specific steps should I take to reduce my energy consumption at home?', the step-back question may be 'What are the general principles of energy conservation?'. Or, instead of diving straight into 'How do I fix the error in this specific line of code?', a step-back question may be 'What are the common causes of this type of error?'.</p>
<p><img alt="" src="../img/s/step_back_prompting.png" width="&quot;100%" /></p>
<object data="https://arxiv.org/pdf/2310.06117" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2310.06117">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://www.prompthub.us/blog/a-step-forward-with-step-back-prompting">https://www.prompthub.us/blog/a-step-forward-with-step-back-prompting</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="stereo-vision">Stereo Vision<a class="headerlink" href="#stereo-vision" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../a/#autonomous-vehicle">Autonomous Vehicle</a></p>
<h2 id="stochastic-gradient-descent-sgd-algorithm">Stochastic Gradient Descent (SGD) Algorithm<a class="headerlink" href="#stochastic-gradient-descent-sgd-algorithm" title="Permanent link">#</a></h2>
<p>An algorithm used by an optimizer to minimize the loss function and find the correct values of the parameters.</p>
<p>There are a few downsides of the gradient descent algorithm. We need to take a closer look at the amount of computation we make for each iteration of the algorithm. Say we have 10,000 data points and 10 features. The sum of squared residuals consists of as many terms as there are data points, so 10000 terms in our case. We need to compute the derivative of this function with respect to each of the features, so in effect we will be doing 10000 * 10 = 100,000 computations per iteration. It is common to take 1000 iterations, in effect we have 100,000 * 1000 = 100000000 computations to complete the algorithm. That is pretty much an overhead and hence gradient descent is slow on huge data. Stochastic gradient descent comes to our rescue! Stochastic, in plain terms means random. SGD randomly picks ONE data point (if more than one = <a href="../m/#mini-batch-gradient-descent-algorithm">mini-batch gradient descent</a> or <a href="../b/#batch-gradient-descent-algorithm">batch Gradient Descent</a> !) from the whole data set at each iteration/step to reduce the computations enormously.</p>
<p><img alt="" src="../img/s/stochastic_gradient_descent.png" width="&quot;100%" /></p>
<p><img alt="" src="../img/s/stochastic_gradient_descent_comparison.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, [Gradient Descent Algorithm]</p>
<h2 id="stochastic-node">Stochastic Node<a class="headerlink" href="#stochastic-node" title="Permanent link">#</a></h2>
<p>Input = mean + variance, i.e a distribution, but output = a sample of that distribution. Different from a deterministic node.</p>
<p>See also <a href="./">S</a>, <a href="../d/#deterministic-node">Deterministic Node</a>, [Variational Autoencoder Reparametrization Trick]</p>
<h2 id="streamlit">Streamlit<a class="headerlink" href="#streamlit" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li>site - <a href="https://streamlit.io/">https://streamlit.io/</a></li>
<li>gallery - <a href="https://streamlit.io/gallery">https://streamlit.io/gallery</a></li>
<li>articles<ul>
<li><a href="https://towardsdatascience.com/9-awesome-python-packages-for-machine-learning-that-should-deserve-more-credit-dbad17263145">https://towardsdatascience.com/9-awesome-python-packages-for-machine-learning-that-should-deserve-more-credit-dbad17263145</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="stretch-robot">Stretch Robot<a class="headerlink" href="#stretch-robot" title="Permanent link">#</a></h2>
<p>A robot dog developed by <a href="../b/#boston-dynamics-company">Boston Dynamics</a></p>
<iframe src="https://www.youtube.com/embed/8WZoVJIV9V0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.bostondynamics.com/products/stretch/">https://www.bostondynamics.com/products/stretch/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="strong-ai">Strong AI<a class="headerlink" href="#strong-ai" title="Permanent link">#</a></h2>
<p>~ <a href="../a/#artificial-general-intelligence-agi">Artificial General Intelligence</a> or <a href="../a/#artificial-general-intelligence-agi">AGI</a></p>
<p>Searle identified a philosophical position he calls "strong AI":</p>
<ul>
<li>The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.<a href="../b/">b</a>
 The definition depends on the distinction between simulating a mind and actually having a mind. Searle writes that "according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind."</li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Chinese_room#Strong_AI">https://en.wikipedia.org/wiki/Chinese_room#Strong_AI</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../w/#weak-ai">Weak AI</a></p>
<h2 id="strong-learner">Strong Learner<a class="headerlink" href="#strong-learner" title="Permanent link">#</a></h2>
<p>~ used in <a href="../e/#ensemble-method">ensemble methods</a> to reduce <a href="../v/#variance">variance</a> or [overfit]. If <a href="../w/#weak-learner">weak learners</a> are weak regressors, their outputs  are averaged to get the strong learner's prediction. In the case of weak classifiers, the strong learner's prediction is computed through voting.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="structured-data">Structured Data<a class="headerlink" href="#structured-data" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../d/#data">Data</a></p>
<h2 id="structured-pruning">Structured Pruning<a class="headerlink" href="#structured-pruning" title="Permanent link">#</a></h2>
<p>A <a href="../p/#pruning">pruning</a> method that involves removing entire parts of a model, such as neurons, channels, or layers. The advantage of structured pruning is that it simplifies model compression and improves hardware efficiency. For instance, removing an entire layer can reduce the computational complexity of the model without introducing irregularities in the model structure.</p>
<p>However, structured pruning requires a deep understanding of the models architecture and how different parts contribute to overall performance. Theres also a higher risk of significantly impacting the models accuracy, as removing entire neurons or layers can potentially eliminate important learned features.</p>
<p>One promising technique for structured pruning is LLM-Pruner. This task-agnostic method minimizes reliance on original training data and selectively removes non-critical coupled structures based on gradient information. This approach maximally preserves the majority of the LLMs functionality, making it an effective tool for <a href="../m/#model-compression">model compression</a>.</p>
<p>More at:</p>
<ul>
<li><a href="https://bdtechtalks.com/2023/09/18/what-is-llm-compression/">https://bdtechtalks.com/2023/09/18/what-is-llm-compression/</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../u/#unstructured-pruning">Unstructured Pruning</a></p>
<h2 id="structured-state-space-sequence-s4-model">Structured State Space Sequence (S4) Model<a class="headerlink" href="#structured-state-space-sequence-s4-model" title="Permanent link">#</a></h2>
<p>~ a new <a href="./#sequence-model">sequence model</a> based on the state space model that is continuous-time in nature, excels at modeling long dependencies, and is very computationally efficient. Explicitly trained to work on long sequences</p>
<p>A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including <a href="../r/#recurrent-neural-network-rnn">RNNs</a>, <a href="../c/#convolutional-neural-network-cnn">CNNs</a>, and [Transformers] have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental <a href="./#state-space-model-ssm">State Space Model (SSM)</a> <span class="arithmatex">\( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \)</span>, and showed that for appropriate choices of the state matrix <span class="arithmatex">\( A \)</span>, this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the <a href="./#state-space-model-ssm">SSM</a>, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning <span class="arithmatex">\( A \)</span> with a low-rank correction, allowing it to be diagonalized stably and reducing the <a href="./#state-space-model-ssm">SSM</a> to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\% accuracy on sequential <a href="../c/#cifar-dataset">CIFAR-10</a> with no data augmentation or auxiliary losses, on par with a larger 2-D [ResNet], (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60 faster (iii) <a href="./#state-of-the-art-sota">SoTA</a> on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.</p>
<p><img alt="" src="../img/s/structured_state_space_sequence_model.png" width="&quot;100%" /></p>
<iframe src="https://www.youtube.com/embed/luCBXCErkCs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2111.00396" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2111.00396">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>explanation - <a href="https://srush.github.io/annotated-s4/">https://srush.github.io/annotated-s4/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2111.00396">https://arxiv.org/abs/2111.00396</a></li>
<li>code - <a href="https://github.com/state-spaces/s4">https://github.com/state-spaces/s4</a></li>
<li>articles<ul>
<li><a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-1">https://hazyresearch.stanford.edu/blog/2022-01-14-s4-1</a></li>
<li><a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-2">https://hazyresearch.stanford.edu/blog/2022-01-14-s4-2</a></li>
<li><a href="https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3">https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="style-gan">Style GAN<a class="headerlink" href="#style-gan" title="Permanent link">#</a></h2>
<p>Other GANs focused on improving the discriminator in this case we improve the generator. This GAN generates by taking a reference picture.</p>
<p><img alt="" src="../img/s/style_gan.jpeg" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, [Generative Adversarial Network]</p>
<h2 id="sub-symbolic-ai">Sub-Symbolic AI<a class="headerlink" href="#sub-symbolic-ai" title="Permanent link">#</a></h2>
<p>See <a href="../n/#non-symbolic-ai">Non-Symbolic AI</a></p>
<h2 id="subsampling">Subsampling<a class="headerlink" href="#subsampling" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a></p>
<h2 id="sundar-pichai-person">Sundar Pichai Person<a class="headerlink" href="#sundar-pichai-person" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Sundar_Pichai">https://en.wikipedia.org/wiki/Sundar_Pichai</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="suno-ai-company">Suno AI Company<a class="headerlink" href="#suno-ai-company" title="Permanent link">#</a></h2>
<p>Suno is building a future where anyone can make great music. Whether you're a shower singer or a charting artist, we break barriers between you and the song you dream of making. No instrument needed, just imagination. From your mind to music.</p>
<p>More at:</p>
<ul>
<li>site - <a href="https://www.suno.ai/">https://www.suno.ai/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="suno-ai-model">Suno AI Model<a class="headerlink" href="#suno-ai-model" title="Permanent link">#</a></h2>
<p>A model to generate the music and lyrics based on a prompt</p>
<iframe src="https://www.youtube.com/embed/XEMPea4y9IU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, ...</p>
<h2 id="super-resolution-gan-srgan">Super Resolution GAN (SRGAN)<a class="headerlink" href="#super-resolution-gan-srgan" title="Permanent link">#</a></h2>
<p>The main purpose of this type of GAN is to make a low resolution picture into a more detailed picture. This is one of the most researched problems in Computer vision. The architecture of the SRGAN is given below</p>
<p><img alt="" src="../img/s/super_resolution_gan.jpeg" width="&quot;100%" /></p>
<p>As given in the above figure we observe that the Generator network and Discriminator both make use of Convolutional layers , the Generator make use of the Parametric Rectified Linear Unit (ReLU) as the activation function whereas the Discriminator uses the Leaky-ReLU.</p>
<p>See also <a href="./">S</a>, [Generative Adversarial Network], [Rectified Linear Unit Activation Function]</p>
<h2 id="superalignment">Superalignment<a class="headerlink" href="#superalignment" title="Permanent link">#</a></h2>
<p>A core challenge for aligning future superhuman AI systems (superalignment) is that humans will need to supervise AI systems much smarter than them.</p>
<p>We believe superintelligenceAI vastly smarter than humanscould be developed within the next ten years. However, we still do not know how to reliably steer and control superhuman AI systems. Solving this problem is essential for ensuring that even the most advanced AI systems in the future remain safe and beneficial to humanity.</p>
<iframe src="https://www.youtube.com/embed/Ft0gTO2K85A" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://openai.com/blog/introducing-superalignment">https://openai.com/blog/introducing-superalignment</a></li>
<li>research - <a href="https://openai.com/research/weak-to-strong-generalization">https://openai.com/research/weak-to-strong-generalization</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="superglue-benchmark">SuperGLUE Benchmark<a class="headerlink" href="#superglue-benchmark" title="Permanent link">#</a></h2>
<p>In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced one year ago, offered a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently come close to the level of non-expert humans, suggesting limited headroom for further research.</p>
<p>We take into account the lessons learnt from original GLUE benchmark and present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, improved resources, and a new public leaderboard.</p>
<object data="https://arxiv.org/pdf/1905.00537" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1905.00537">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://super.gluebenchmark.com/">https://super.gluebenchmark.com/</a></li>
<li>paper - <a href="https://arxiv.org/abs/1905.00537">https://arxiv.org/abs/1905.00537</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../b/#benchmark">Benchmark</a>, <a href="../g/#general-language-understanding-evaluation-glue-benchmark">GLUE Benchmark</a></p>
<h2 id="supertranslate-ai-company">Supertranslate AI Company<a class="headerlink" href="#supertranslate-ai-company" title="Permanent link">#</a></h2>
<p>An <a href="../c/#company">company</a> that focuses on generating subtitle for a given video (check the meditation video!)</p>
<p>More at:</p>
<ul>
<li>mediation video - <a href="https://twitter.com/ramsri_goutham/status/1619620737509396483">https://twitter.com/ramsri_goutham/status/1619620737509396483</a><ul>
<li>post - [<a href="https://ramsrigoutham.medium.com/create-ai-powered-personalized-meditation-videos-d2f76fee03a5(https://ramsrigoutham.medium.com/create-ai-powered-personalized-meditation-videos-d2f76fee03a5">https://ramsrigoutham.medium.com/create-ai-powered-personalized-meditation-videos-d2f76fee03a5(https://ramsrigoutham.medium.com/create-ai-powered-personalized-meditation-videos-d2f76fee03a5</a>)</li>
<li>video <a href="https://www.youtube.com/watch?v=YfxlC9Kreig&amp;t=44s">https://www.youtube.com/watch?v=YfxlC9Kreig&amp;t=44s</a></li>
</ul>
</li>
<li><a href="https://dashboard.supertranslate.ai/home">https://dashboard.supertranslate.ai/home</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="supervised-feedback">Supervised Feedback<a class="headerlink" href="#supervised-feedback" title="Permanent link">#</a></h2>
<p>Used in <a href="../r/#reinforcement-learning-rl">Reinforcement Learning (RL)</a>, not unlike <a href="./#supervised-learning">supervised learning</a>!</p>
<p>Ex:
  * points in a video game where rules are unknown</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="supervised-fine-tuning-sft">Supervised Fine-Tuning (SFT)<a class="headerlink" href="#supervised-fine-tuning-sft" title="Permanent link">#</a></h2>
<p><mark>A way to turn a generalist [pre-trained model] into a "fine-tuned" expert model, aka domain-specific model</mark> Normally done with <a href="./#supervised-learning">supervised learning</a> to minimize the number of samples required and be less compute intensive and be more compute friendly?</p>
<p>Alternatives:</p>
<ul>
<li><a href="../p/#parameter-efficient-fine-tuning-peft">PEFT</a> with <a href="../l/#low-rank-adaptation-lora-fine-tuning">Lora</a></li>
<li><a href="../h/#hypernetwork-architecture">Hypernetwork Architecture</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="../d/#domain-specific-model">Domain-Specific Model</a>, <a href="../r/#red-teaming">Red Teaming</a>, <a href="../t/#transfer-learning">Transfer Learning</a></p>
<h2 id="supervised-learning">Supervised Learning<a class="headerlink" href="#supervised-learning" title="Permanent link">#</a></h2>
<p><mark>provide labeled training data</mark> (picture of a dog, with label this is a dog!). Ex:</p>
<ul>
<li>Regression (predicting the price that a house will sell for)<ul>
<li>Simple <a href="../l/#linear-regression">linear regression</a></li>
<li>multi regression</li>
</ul>
</li>
<li>Classification (Cat or not cat?)</li>
<li>Random forest.</li>
</ul>
<p>Teaches the model by providing a dataset with example inputs and outputs. Human teacher's expertise is used to tell the model which outputs are correct. Input --&gt; Model --&gt; output/prediction. Further grouped into classification and regression. Learn the relationship between the input parameters and the output. For example: route calls to the correct agent-skills (hence recording of calls to be reviewed by supervisor/teacher). REQUIREMENTS: model should already be functioning and easy to observe! If that is not the case, maybe look at unsupervised learning! </p>
<p>These AI algorithms are used to analyze a pattern or variables that you have control over (X variables), when you want to figure out either what to do about it, or you have a particular outcome (Y variables) that you want to monitor. In a marketing context, the marketing mix can make up all the X variables that you have control over, and the sales and KPIs are the Y variables the algorithm will monitor.</p>
<p>Some possible uses for supervised learning in marketing!:</p>
<ul>
<li>Predicting sales based on a historical allocation of media mix spends.</li>
<li>Predicting what type of consumers will purchase a product based on their socioeconomic data.</li>
<li>Predicting how long it would take for a customer to purchase the item, and adjusting the price accordingly.</li>
<li>Predicting CPG (consumer product goods) market share based on historical data.</li>
<li>Predicting CLV (customer lifetime value) based on historical data.</li>
</ul>
<p>See also <a href="./">S</a>, <a href="../c/#classification-task">Classification</a>, <a href="../m/#mechanical-turk">Mechanical Turk</a>, <a href="../r/#random-forest">Random Forest</a>, <a href="../r/#regression-task">Regression</a>, <a href="../r/#reinforcement-learning-rl">Reinforcement Learning</a>, <a href="./#self-supervised-learning-ssl">Self-Supervised Learning</a>, <a href="./#semi-supervised-learning">Semi-Supervised Learning</a>, <a href="./#supervisor">Supervisor</a>, <a href="../u/#unsupervised-learning">Unsupervised Learning</a></p>
<h2 id="supervisor">Supervisor<a class="headerlink" href="#supervisor" title="Permanent link">#</a></h2>
<p>A teacher! Beware that the teach is not necessarily a 'person', it can also be a machine, the environment, etc. For example, historical data to predict future sales. For example, predict future earthquakes, the teacher is nature herself!</p>
<p>See also <a href="./">S</a>, <a href="./#supervised-learning">Supervised Learning</a></p>
<h2 id="supply-chain-vulnerability">Supply Chain Vulnerability<a class="headerlink" href="#supply-chain-vulnerability" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, <a href="../m/#model-scanning">Model Scanning</a>, <a href="../m/#model-threat-analysis">Model Threat Analysis</a></p>
<h2 id="support-vector">Support Vector<a class="headerlink" href="#support-vector" title="Permanent link">#</a></h2>
<p>Name of the type of points that are closed to the final SVM boundary and usd for the computation of the SMV boundary!</p>
<p>See also <a href="./">S</a>, <a href="./#support-vector-machine-svm">Support Vector Machine</a></p>
<h2 id="support-vector-machine-svm">Support Vector Machine (SVM)<a class="headerlink" href="#support-vector-machine-svm" title="Permanent link">#</a></h2>
<p><mark>Find a linear/planar/x-D/hyperplane to use as a decision boundary in real, transformed, or latent space!</mark> To find the boundary, only use the distance from the points/samples/support-vectors to the boundary and make sure it is as large/wide as possible to maximize the chance of success of the classification (i.e. minimize false positive). Mostly used for classification, but occasionally for regression.</p>
<p><img alt="" src="../img/s/support_vector_machine.png" width="&quot;100%" /></p>
<iframe src="https://www.youtube.com/embed/FB5EdxAGxQg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/T9UcK-TxQGw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<div class="admonition warning">
<p class="admonition-title">Beware:</p>
<ul>
<li>SVM can be used for binary classification (but also with a trick can be used for multi-class classification)</li>
</ul>
</div>
<p>More at:</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/">https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/</a></li>
</ul>
<p>See <a href="../c/#classification-task">Classification</a>, <a href="../d/#decision-boundary">Decision Boundary</a>, <a href="../k/#kernel-trick">Kernel Trick</a>, <a href="../h/#hyperplane">Hyperplane</a>, <a href="../r/#regression-task">Regression</a>, <a href="./#support-vector">Support Vector</a></p>
<h2 id="surrogate-model">Surrogate Model<a class="headerlink" href="#surrogate-model" title="Permanent link">#</a></h2>
<p>Can be done in second or minute. X: hyperparameter configuration, Y= model quality, no gradient.</p>
<p>See also <a href="./">S</a>, <a href="../h/#hyperparameter-optimization-hpo">HPO</a></p>
<h2 id="swarm-ai">Swarm AI<a class="headerlink" href="#swarm-ai" title="Permanent link">#</a></h2>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="switch-transformer-model">Switch Transformer Model<a class="headerlink" href="#switch-transformer-model" title="Permanent link">#</a></h2>
<p>Model developed by <a href="../g/#google-company">Google</a> and based on the <a href="../t/#text-to-text-transfer-transformer-t5-model-family">T5 model</a> uses sparse activation +</p>
<p>More at:</p>
<ul>
<li><a href="https://analyticsindiamag.com/a-deep-dive-into-switch-transformer-architecture/">https://analyticsindiamag.com/a-deep-dive-into-switch-transformer-architecture/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2101.03961">https://arxiv.org/abs/2101.03961</a></li>
</ul>
<p>See also <a href="./">S</a>, [Mixture Of Local Expect], <a href="./#sparse-activation">Sparse Activation</a>, <a href="../t/#text-to-text-transfer-transformer-t5-model-family">T5 Model</a></p>
<h2 id="symbolic-ai">Symbolic AI<a class="headerlink" href="#symbolic-ai" title="Permanent link">#</a></h2>
<p>You teach rules of work, where <a href="../r/#rule">rules</a> = logic</p>
<ul>
<li>A cat is an animal</li>
<li>this is right and this is wrong</li>
<li>turn text into words and find "intent, utterance, and slots"</li>
</ul>
<p>The opposite is <a href="../n/#non-symbolic-ai">non-symbolic AI</a> where the system finds the patterns itself by parsing tons data</p>
<p>Ex: Siri 2024, Alexa 2024</p>
<p>For example, for an intent to plan a trip (PlanMyTrip), you might write the following utterances:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>i am going on a trip on friday
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>i want to visit portland
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>i want to travel from seattle to portland next friday
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>i&#39;m driving from seattle to portland
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>i&#39;m driving to portland to go hiking
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>...(several more)
</span></code></pre></div>
<p>Then identify the slots of the intent</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>i am going on a trip on *friday*
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>i want to visit *portland*
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>i want to travel from *seattle* to *portland*  *next friday*
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>i&#39;m *driving* from *seattle* to *portland*
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>i&#39;m *driving* to *portland* to go *hiking*
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>i am going on a trip on {travelDate}
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>i want to visit {toCity}
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>I want to travel from {fromCity} to {toCity} {travelDate}
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>I&#39;m {travelMode} from {fromCity} to {toCity}
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>i&#39;m {travelMode} to {toCity} to go {activity}
</span></code></pre></div>
<p>Se also <a href="./">S</a>, <a href="../c/#complexity-ceiling">Complexity Ceiling</a>, <a href="../e/#expert-system">Expert System</a>, <a href="../r/#rule-interaction">Rule Interaction</a></p>
<h2 id="synapse">Synapse<a class="headerlink" href="#synapse" title="Permanent link">#</a></h2>
<p>A synapse is the connection between nodes, or neurons, in an artificial neural network (ANN). Similar to biological brains, the connection is controlled by the strength or amplitude of a connection between both nodes, also called the synaptic weight. Multiple synapses can connect the same neurons, with each synapse having a different level of influence (trigger) on whether that neuron is fired and activates the next neuron.</p>
<p><img alt="" src="../img/s/synapse.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, <a href="../a/#artificial-neuron">Artificial Neuron</a>, <a href="../a/#artificial-neural-network-ann">Artificial Neural Network</a>, <a href="../b/#biological-neuron">Biological Neuron</a>, <a href="../b/#brain">Brain</a>, <a href="./#synaptic-strength">Synaptic Strength</a></p>
<h2 id="synaptic-strength">Synaptic Strength<a class="headerlink" href="#synaptic-strength" title="Permanent link">#</a></h2>
<p>Analogous to the absolute value of a weight</p>
<p>See <a href="./">S</a>, ...</p>
<h2 id="synchronous-neural-network">Synchronous Neural Network<a class="headerlink" href="#synchronous-neural-network" title="Permanent link">#</a></h2>
<p>In each output generation (classification) trial proceeds by computing the outputs of each layer, starting with layer 0 through layer M.</p>
<p>Neurons are operating dependently (wait for the input for upstream layers)</p>
<p>See also <a href="./">S</a>, <a href="../a/#asynchronous-neural-network">Asynchronous Neural Network</a></p>
<h2 id="synthesia-company">Synthesia Company<a class="headerlink" href="#synthesia-company" title="Permanent link">#</a></h2>
<p>A <a href="../c/#company">company</a> that focuses on the creation of AI avatars</p>
<iframe src="https://www.youtube.com/embed/G-7jbNPQ0TQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/UVNUCBUrHL0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.synthesia.io/about">https://www.synthesia.io/about</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="synthesized-variable">Synthesized Variable<a class="headerlink" href="#synthesized-variable" title="Permanent link">#</a></h2>
<p>EX: cube on paper --&gt; visualize it as a 2-d object. Move from n --&gt; K dimensions (called eigenvectors).</p>
<p><img alt="" src="../img/s/synthesized_variable.png" width="&quot;100%" /></p>
<p>Use the centre of gravity, i.e regression line for the projection. --&gt; transpose to the projection on the 'best' regression line! The best line is used with the gradient descent. We use the 'best' line to project to the new dimension by losing the minimum quantity of information. (miximize the adjacent line of the triangle and minimize the T line. ... Q: How much information have we lost? ...</p>
<p>See also <a href="./">S</a>, <a href="../e/#eigenvalue">Eigenvalue</a>, <a href="../p/#principal-component-analysis-pca">Principal Component Analysis</a></p>
<h2 id="synthetic-data">Synthetic Data<a class="headerlink" href="#synthetic-data" title="Permanent link">#</a></h2>
<p>Information that is artificially generated rather than produced by real-world events.</p>
<p>It can be created using </p>
<ul>
<li>transformation</li>
<li>simulation</li>
</ul>
<p>It can be used to</p>
<ul>
<li>Liberate data, i.e. from top secret to confidential </li>
<li>Augment to improve performance = train on real data and augmented data + test on real data ==&gt; <a href="../m/#model-uplift">Model uplift</a></li>
<li>Fill gap in data</li>
<li>Test </li>
</ul>
<p>Synthetic data is a tool that addresses many data challenges, particularly artificial intelligence and analytics issues such as privacy protection, regulatory compliance, accessibility, data scarcity, and bias, as well as data sharing and time to data (and therefore time to market).</p>
<p>Synthetic data has the potential of solving the <a href="../d/#data-wall">data wall</a> .</p>
<p>{% pdf "img/s/synthetic_data_mostly_ai.pdf" %}</p>
<p>{% pdf "img/s/synthetic_data_datagen.pdf" %}</p>
<p>More at:</p>
<ul>
<li>Fair synthetic data generation - <a href="https://mostly.ai/blog/diving-deep-into-fair-synthetic-data-generation-fairness-series-part-5">https://mostly.ai/blog/diving-deep-into-fair-synthetic-data-generation-fairness-series-part-5</a></li>
</ul>
<p>See also <a href="./">S</a>, <a href="./#synthetic-data-privacy">Synthetic Data Privacy</a></p>
<h2 id="synthetic-data-privacy">Synthetic Data Privacy<a class="headerlink" href="#synthetic-data-privacy" title="Permanent link">#</a></h2>
<p>Beware: is it possible to reverser-engineer <a href="./#synthetic-data">synthetic data</a> to find out what the real data was?</p>
<p><img alt="" src="../img/s/synthetic_data_privacy.png" width="&quot;100%" /></p>
<p>Privacy levels:</p>
<ol>
<li>Obscure Personally Identifiable Information (PII)</li>
<li>Obscure Personally Identifiable Information (PII) + noise</li>
<li>Synthesized rows</li>
<li>Synthesized rows + tests</li>
<li>Simulation taught by looking at real data</li>
<li>Simulation taught without looking at real data</li>
</ol>
<p><img alt="" src="../img/s/synthetic_data_privacy_levels.png" width="&quot;100%" /></p>
<p>Level 1: Obscure Personally Identifiable Information (PII)</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_1.png" width="&quot;100%" /></p>
<p>Level 2: Obscure Personally Identifiable Information (PII) + noise</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_2.png" width="&quot;100%" /></p>
<p>Level 3: Synthesized rows</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_3.png" width="&quot;100%" /></p>
<p>Level 4: Synthesized rows + tests</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_4.png" width="&quot;100%" /></p>
<p>Level 5: Simulation based on input data</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_5.png" width="&quot;100%" /></p>
<p>Level 6: Simulation NOT based on input data</p>
<p><img alt="" src="../img/s/synthetic_data_privacy_level_6.png" width="&quot;100%" /></p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="synthetic-feature">Synthetic Feature<a class="headerlink" href="#synthetic-feature" title="Permanent link">#</a></h2>
<p>A <a href="../f/#feature">feature</a> not present among the input features, but assembled from one or more of them. Methods for creating synthetic features include the following:</p>
<ul>
<li><a href="../b/#bucketing">Bucketing</a> a continuous feature into range bins.</li>
<li>Creating a <a href="../f/#feature-cross">feature cross</a>.</li>
<li>Multiplying (or dividing) one feature value by other feature value(s) or by itself. For example, if a and b are input features, then the following are examples of synthetic features:</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>ab
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>a2
</span></code></pre></div>
<ul>
<li>Applying a transcendental function to a feature value. For example, if c is an input feature, then the following are examples of synthetic features:</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>sin(c)
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>ln(c)
</span></code></pre></div>
<p>Features created by normalizing or scaling alone are not considered synthetic features.</p>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="synthetic-users-company">Synthetic Users Company<a class="headerlink" href="#synthetic-users-company" title="Permanent link">#</a></h2>
<p>Test your idea or product with AI participants and take decisions with confidence.</p>
<p>More at:</p>
<ul>
<li>site - <a href="https://www.syntheticusers.com/">https://www.syntheticusers.com/</a></li>
<li>blog - <a href="https://www.syntheticusers.com/journal">https://www.syntheticusers.com/journal</a></li>
<li>articles<ul>
<li>deviation - <a href="https://www.syntheticusers.com/post/comparison-studies-the-opportunity-lies-in-the-deviation">https://www.syntheticusers.com/post/comparison-studies-the-opportunity-lies-in-the-deviation</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="synthid">SynthID<a class="headerlink" href="#synthid" title="Permanent link">#</a></h2>
<p>~ used to identify generated content by embedding watermarks directly into AI-generated images, audio, text, or video.</p>
<p>More at:</p>
<ul>
<li>site - <a href="https://deepmind.google/technologies/synthid/">https://deepmind.google/technologies/synthid/</a></li>
</ul>
<p>See also <a href="./">S</a>, ...</p>
<h2 id="system-prompt">System Prompt<a class="headerlink" href="#system-prompt" title="Permanent link">#</a></h2>
<p>A system prompt is always included in all new contexts/requests? Only if the model is steerable! <a href="./#steerability">Steerability</a> is a feature that emerged circa 2020 when GPT-3 was realeased</p>
<p>A system prompt includes:</p>
<ul>
<li>identity and purpose (name, intended function, boundaries)</li>
<li>interaction guideline (behavior, style, tone, protocols for complex/sensitive topics)</li>
<li>knowledge and capabilities (experience, scope of knowledge, skills/tools/area of expertise, etc)</li>
<li>response formatting (Markdown, json, etc)</li>
<li>contextual information (background, current date or temporal context, etc)</li>
<li>ethical considerations (principles for maintaining safety, guidelines, instruction for avoiding bias)</li>
<li>language preferences</li>
<li>task-specific instructions (problem solving method, etc.)</li>
<li>...</li>
<li>examples (?)</li>
</ul>
<p><img alt="" src="../img/s/system_prompt.png" width="&quot;100%" /></p>
<iframe src="https://www.youtube.com/embed/t94s5apFres" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/zNACfPuaqaI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">S</a>, <a href="../l/#llm-pricing">LLM Pricing</a></p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../r/" class="md-footer__link md-footer__link--prev" aria-label="Previous: R">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                R
              </div>
            </div>
          </a>
        
        
          
          <a href="../t/" class="md-footer__link md-footer__link--next" aria-label="Next: T">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                T
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>