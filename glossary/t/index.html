
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/t/">
      
      
        <link rel="prev" href="../s/">
      
      
        <link rel="next" href="../u/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>T - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="T - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/t.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/t/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="T - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/t.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#t" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              T
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../g/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../l/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    T
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#t-distributed-stochastic-neighbor-embedding-t-sne-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      T-Distributed Stochastic Neighbor Embedding (t-SNE) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#t-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      T-Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tabular-data" class="md-nav__link">
    <span class="md-ellipsis">
      Tabular Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tabular-prior-data-fitted-network-tabpfn" class="md-nav__link">
    <span class="md-ellipsis">
      Tabular Prior-Data Fitted Network (TabPFN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tanh-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#target-attribute" class="md-nav__link">
    <span class="md-ellipsis">
      Target Attribute
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task" class="md-nav__link">
    <span class="md-ellipsis">
      Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-based-learning-tbl" class="md-nav__link">
    <span class="md-ellipsis">
      Task-Based Learning (TBL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-driven-autonomous-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Task-Driven Autonomous Agent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#taxonomy" class="md-nav__link">
    <span class="md-ellipsis">
      Taxonomy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#techno-optimism" class="md-nav__link">
    <span class="md-ellipsis">
      Techno Optimism
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#techno-pessimism" class="md-nav__link">
    <span class="md-ellipsis">
      Techno Pessimism
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#temperature" class="md-nav__link">
    <span class="md-ellipsis">
      Temperature
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor-processing-unit-tpu" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Processing Unit (TPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-hub" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Hub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorrt-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT SDK
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-tf" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency (TF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-inverse-document-frequency-tf-idf-retrieval-model" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency-Inverse Document Frequency (TF-IDF) Retrieval Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-matrix-tfm" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency Matrix (TFM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#test-set" class="md-nav__link">
    <span class="md-ellipsis">
      Test Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Text Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Text Extraction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      Text Reconstruction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Text Summarization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-speech-tts-model" class="md-nav__link">
    <span class="md-ellipsis">
      Text-To-Speech (TTS) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-text-transfer-transformer-t5-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Text-To-Text Transfer Transformer (T5) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Textual Inversion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theano" class="md-nav__link">
    <span class="md-ellipsis">
      Theano
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theory-of-mind-tom" class="md-nav__link">
    <span class="md-ellipsis">
      Theory Of Mind (ToM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#thresholding" class="md-nav__link">
    <span class="md-ellipsis">
      Thresholding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#time-step" class="md-nav__link">
    <span class="md-ellipsis">
      Time Step
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#time-series-predictive-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Time-Series Predictive Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Token Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-id" class="md-nav__link">
    <span class="md-ellipsis">
      Token ID
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenizer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer-tax" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenizer Tax
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-k-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Top-K Random Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-k-similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      Top-K Similarity Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-p-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Top-P Random Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch" class="md-nav__link">
    <span class="md-ellipsis">
      Torch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchscript-format" class="md-nav__link">
    <span class="md-ellipsis">
      TorchScript Format
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traditional-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#train-testing-split" class="md-nav__link">
    <span class="md-ellipsis">
      Train Testing Split
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-set" class="md-nav__link">
    <span class="md-ellipsis">
      Training Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trajectory" class="md-nav__link">
    <span class="md-ellipsis">
      Trajectory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transform-function-tf" class="md-nav__link">
    <span class="md-ellipsis">
      Transform Function (TF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-based-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer-Based Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfusion-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transfusion Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translation" class="md-nav__link">
    <span class="md-ellipsis">
      Translation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transpose-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Transpose Matrix
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traveling-salesman-problem-tsp" class="md-nav__link">
    <span class="md-ellipsis">
      Traveling Salesman Problem (TSP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-of-thoughts-tot-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Tree of Thoughts (TOT) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-parzen-estimators-tpe" class="md-nav__link">
    <span class="md-ellipsis">
      Tree Parzen Estimators (TPE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triplet-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Triplet Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triton-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Triton Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triviaqa-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      TriviaQA Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trossen-robotics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Trossen Robotics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trocr-model" class="md-nav__link">
    <span class="md-ellipsis">
      TrOCR Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-negative-tn" class="md-nav__link">
    <span class="md-ellipsis">
      True Negative (TN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-negative-rate-tnr" class="md-nav__link">
    <span class="md-ellipsis">
      True Negative Rate (TNR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-positive-tp" class="md-nav__link">
    <span class="md-ellipsis">
      True Positive (TP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-positive-rate-tpr" class="md-nav__link">
    <span class="md-ellipsis">
      True Positive Rate (TPR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trust-region-policy-optimization-trpo-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Trust Region Policy Optimization (TRPO) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trustworthy-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Trustworthy AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#truth" class="md-nav__link">
    <span class="md-ellipsis">
      Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#truthfulqa-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      TruthfulQA Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tuning-parameter" class="md-nav__link">
    <span class="md-ellipsis">
      Tuning Parameter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turing-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Turing Machine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turing-test" class="md-nav__link">
    <span class="md-ellipsis">
      Turing Test
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#twin-delayed-deep-deterministic-td3-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Twin Delayed Deep Deterministic (TD3) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-tower-embeddings-tte" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Tower Embeddings (TTE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-tower-model" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Tower Model
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../v/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#t-distributed-stochastic-neighbor-embedding-t-sne-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      T-Distributed Stochastic Neighbor Embedding (t-SNE) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#t-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      T-Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tabular-data" class="md-nav__link">
    <span class="md-ellipsis">
      Tabular Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tabular-prior-data-fitted-network-tabpfn" class="md-nav__link">
    <span class="md-ellipsis">
      Tabular Prior-Data Fitted Network (TabPFN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tanh-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Tanh Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#target-attribute" class="md-nav__link">
    <span class="md-ellipsis">
      Target Attribute
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task" class="md-nav__link">
    <span class="md-ellipsis">
      Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-based-learning-tbl" class="md-nav__link">
    <span class="md-ellipsis">
      Task-Based Learning (TBL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-driven-autonomous-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Task-Driven Autonomous Agent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#taxonomy" class="md-nav__link">
    <span class="md-ellipsis">
      Taxonomy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#techno-optimism" class="md-nav__link">
    <span class="md-ellipsis">
      Techno Optimism
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#techno-pessimism" class="md-nav__link">
    <span class="md-ellipsis">
      Techno Pessimism
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#temperature" class="md-nav__link">
    <span class="md-ellipsis">
      Temperature
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor-processing-unit-tpu" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Processing Unit (TPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-hub" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Hub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      TensorFlow Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorrt-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT SDK
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-tf" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency (TF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-inverse-document-frequency-tf-idf-retrieval-model" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency-Inverse Document Frequency (TF-IDF) Retrieval Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#term-frequency-matrix-tfm" class="md-nav__link">
    <span class="md-ellipsis">
      Term Frequency Matrix (TFM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#test-set" class="md-nav__link">
    <span class="md-ellipsis">
      Test Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Text Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Text Extraction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      Text Reconstruction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Text Summarization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-speech-tts-model" class="md-nav__link">
    <span class="md-ellipsis">
      Text-To-Speech (TTS) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-text-transfer-transformer-t5-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Text-To-Text Transfer Transformer (T5) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Textual Inversion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theano" class="md-nav__link">
    <span class="md-ellipsis">
      Theano
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#theory-of-mind-tom" class="md-nav__link">
    <span class="md-ellipsis">
      Theory Of Mind (ToM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#thresholding" class="md-nav__link">
    <span class="md-ellipsis">
      Thresholding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#time-step" class="md-nav__link">
    <span class="md-ellipsis">
      Time Step
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#time-series-predictive-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Time-Series Predictive Analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Token Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#token-id" class="md-nav__link">
    <span class="md-ellipsis">
      Token ID
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenizer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer-tax" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenizer Tax
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-k-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Top-K Random Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-k-similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      Top-K Similarity Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#top-p-random-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Top-P Random Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch" class="md-nav__link">
    <span class="md-ellipsis">
      Torch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchscript-format" class="md-nav__link">
    <span class="md-ellipsis">
      TorchScript Format
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traditional-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#train-testing-split" class="md-nav__link">
    <span class="md-ellipsis">
      Train Testing Split
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-set" class="md-nav__link">
    <span class="md-ellipsis">
      Training Set
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trajectory" class="md-nav__link">
    <span class="md-ellipsis">
      Trajectory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transform-function-tf" class="md-nav__link">
    <span class="md-ellipsis">
      Transform Function (TF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-based-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer-Based Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfusion-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transfusion Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translation" class="md-nav__link">
    <span class="md-ellipsis">
      Translation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transpose-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Transpose Matrix
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traveling-salesman-problem-tsp" class="md-nav__link">
    <span class="md-ellipsis">
      Traveling Salesman Problem (TSP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-of-thoughts-tot-prompting" class="md-nav__link">
    <span class="md-ellipsis">
      Tree of Thoughts (TOT) Prompting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-parzen-estimators-tpe" class="md-nav__link">
    <span class="md-ellipsis">
      Tree Parzen Estimators (TPE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triplet-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Triplet Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triton-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Triton Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#triviaqa-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      TriviaQA Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trossen-robotics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Trossen Robotics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trocr-model" class="md-nav__link">
    <span class="md-ellipsis">
      TrOCR Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-negative-tn" class="md-nav__link">
    <span class="md-ellipsis">
      True Negative (TN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-negative-rate-tnr" class="md-nav__link">
    <span class="md-ellipsis">
      True Negative Rate (TNR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-positive-tp" class="md-nav__link">
    <span class="md-ellipsis">
      True Positive (TP)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#true-positive-rate-tpr" class="md-nav__link">
    <span class="md-ellipsis">
      True Positive Rate (TPR)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trust-region-policy-optimization-trpo-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Trust Region Policy Optimization (TRPO) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trustworthy-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Trustworthy AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#truth" class="md-nav__link">
    <span class="md-ellipsis">
      Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#truthfulqa-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      TruthfulQA Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tuning-parameter" class="md-nav__link">
    <span class="md-ellipsis">
      Tuning Parameter
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turing-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Turing Machine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turing-test" class="md-nav__link">
    <span class="md-ellipsis">
      Turing Test
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#twin-delayed-deep-deterministic-td3-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Twin Delayed Deep Deterministic (TD3) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-tower-embeddings-tte" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Tower Embeddings (TTE)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#two-tower-model" class="md-nav__link">
    <span class="md-ellipsis">
      Two-Tower Model
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="t">T<a class="headerlink" href="#t" title="Permanent link">#</a></h1>
<h2 id="t-distributed-stochastic-neighbor-embedding-t-sne-algorithm">T-Distributed Stochastic Neighbor Embedding (t-SNE) Algorithm<a class="headerlink" href="#t-distributed-stochastic-neighbor-embedding-t-sne-algorithm" title="Permanent link">#</a></h2>
<p>~ an algorithm used for <a href="../d/#dimensionality-reduction">dimensionality reduction</a></p>
<p>Algorithm created in 2008, so modern compared to other existing (but a bit more complex than <a href="../p/#principal-component-analysis-pca">PCA</a>!)</p>
<p>Another popular method is t-Stochastic Neighbor Embedding (t-SNE), which does non-linear <a href="../d/#dimensionality-reduction">dimensionality reduction</a>. People typically use t-SNE for data visualization, but you can also use it for machine learning tasks like reducing the feature space and clustering, to mention just a few. The next plot shows an analysis of the <a href="../m/#modified-national-institute-of-standards-and-technology-mnist-dataset">MNIST</a> database of handwritten digits. <a href="../m/#modified-national-institute-of-standards-and-technology-mnist-dataset">MNIST</a> contains thousands of images of digits from 0 to 9, which researchers use to test their clustering and <a href="../c/#classification-task">classification</a> algorithms. Each row of the <a href="../d/#dataset">dataset</a> is a vectorized version of the original image (size 28 x 28 = 784) and a label for each image (zero, one, two, three, …, nine). Note that we’re therefore reducing the dimensionality from 784 (pixels) to 2 (dimensions in our visualization). Projecting to two dimensions allows us to visualize the high-dimensional original dataset.</p>
<ul>
<li><a href="../p/#principal-component-analysis-pca">PCA</a> - Try to preserve global shape/structure of data</li>
<li>t-SNE - Can choose to preserved local structure </li>
</ul>
<p>Pros:</p>
<ul>
<li>Produces highly clustered, visually striking embeddings.</li>
<li>Non-linear reduction, captures local structure well.</li>
</ul>
<p>Cons:</p>
<ul>
<li>Global structure may be lost in favor of preserving local distances.</li>
<li>More computationally expensive.</li>
<li>Requires setting hyperparameters that influence quality of the embedding.</li>
<li>Non-deterministic algorithm.</li>
</ul>
<p><img alt="" src="../img/t/t_distributed_stochastic_neighbor_embedding_algorithm.gif" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/NEaUSP4YerM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/FQmCzpKWD48" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://www.jmlr.org/papers/v9/vandermaaten08a.html">https://www.jmlr.org/papers/v9/vandermaaten08a.html</a></li>
<li>embedding projector - <a href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a></li>
<li><a href="https://distill.pub/2016/misread-tsne/">https://distill.pub/2016/misread-tsne/</a></li>
<li><a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding</a></li>
<li><a href="https://dimensionality-reduction-293e465c2a3443e8941b016d.vercel.app/">https://dimensionality-reduction-293e465c2a3443e8941b016d.vercel.app/</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="t-distribution">T-Distribution<a class="headerlink" href="#t-distribution" title="Permanent link">#</a></h2>
<p>~ normal distribution with fatter tails!</p>
<p><img alt="" src="../img/t/t_distribution.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">https://en.wikipedia.org/wiki/Student%27s_t-distribution</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tabular-data">Tabular Data<a class="headerlink" href="#tabular-data" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tabular-prior-data-fitted-network-tabpfn">Tabular Prior-Data Fitted Network (TabPFN)<a class="headerlink" href="#tabular-prior-data-fitted-network-tabpfn" title="Permanent link">#</a></h2>
<p>TabPFN is radically different from previous ML methods. It is a meta-learned algorithm and it provably approximates Bayesian inference with a prior for principles of causality and simplicity. Qualitatively, its resulting predictions are very intuitive as well, with very smooth uncertainty estimates:</p>
<p><img alt="" src="../img/t/tabular-prior-data-fitted-network.png" width="100%" /></p>
<p>TabPFN happens to be a single transformer.</p>
<object data="https://arxiv.org/pdf/2207.01848" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2207.01848">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2207.01848">https://arxiv.org/abs/2207.01848</a></li>
<li>code - <a href="https://github.com/automl/TabPFN">https://github.com/automl/TabPFN</a></li>
<li>articles<ul>
<li><a href="https://www.automl.org/tabpfn-a-transformer-that-solves-small-tabular-classification-problems-in-a-second/">https://www.automl.org/tabpfn-a-transformer-that-solves-small-tabular-classification-problems-in-a-second/</a></li>
<li><a href="https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html">https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html</a></li>
</ul>
</li>
<li>code<ul>
<li><a href="https://www.kaggle.com/code/beezus666/titanic-space-total-overkill">https://www.kaggle.com/code/beezus666/titanic-space-total-overkill</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tanh-activation-function">Tanh Activation Function<a class="headerlink" href="#tanh-activation-function" title="Permanent link">#</a></h2>
<p>Pros:</p>
<ul>
<li>Regulate the values to be always between -1 and 1. Used in RNN.</li>
<li>solve exploding gradient problem</li>
</ul>
<p>Cons:</p>
<ul>
<li>vanishing gradient problem.</li>
</ul>
<p><img alt="" src="../img/t/tanh_activation_function.png" width="100%" /></p>
<p>See also <a href="./">T</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, [Recurrent Neural Network], <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="target-attribute">Target Attribute<a class="headerlink" href="#target-attribute" title="Permanent link">#</a></h2>
<p>This is the attribute that we want the XGBoost to predict. In unsupervised training, corresponds to a label in supervised training.</p>
<p>See also <a href="./">T</a>, <a href="../f/#feature">Feature</a>, <a href="../u/#unsupervised-learning">Unsupervised Learning</a>, <a href="../e/#extreme-gradient-boosting-xgboost">XGBoost</a></p>
<h2 id="task">Task<a class="headerlink" href="#task" title="Permanent link">#</a></h2>
<p>To discern a task:</p>
<ul>
<li>Will the activity engage learners’ interest?</li>
<li>Is there a primary focus on meaning?</li>
<li>Is there a goal or an outcome?</li>
<li>Is success judged in terms of the result?</li>
<li>Is completion a priority?</li>
<li>Does the activity relate to real-world activities?</li>
</ul>
<p>If your answer is yes to all the questions, you can be sure that the classroom activity you have in mind is task-like.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.teacheracademy.eu/blog/task-based-learning/">https://www.teacheracademy.eu/blog/task-based-learning/</a></li>
</ul>
<p>See also <a href="./">T</a>, [Task-Based Learning]</p>
<h2 id="task-based-learning-tbl">Task-Based Learning (TBL)<a class="headerlink" href="#task-based-learning-tbl" title="Permanent link">#</a></h2>
<p>Focus on completing the task, but use all your skills (and develop new ones) on the way. Example: Start a company? Start an AI club? Identify problem, opportunities, and improve + find new tools along the way.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.teacheracademy.eu/blog/task-based-learning/">https://www.teacheracademy.eu/blog/task-based-learning/</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../l/#learning-method">Learning Method</a>, <a href="./#task">Task</a></p>
<h2 id="task-driven-autonomous-agent">Task-Driven Autonomous Agent<a class="headerlink" href="#task-driven-autonomous-agent" title="Permanent link">#</a></h2>
<p>Instead of a prompt, you input a goal. The goal is broken down into smaller tasks and agents are spawn to complete this goals.</p>
<p>Open-source</p>
<ul>
<li><a href="../a/#autogpt-model">AutoGPT Model</a></li>
<li><a href="../b/#babyagi-model">BabyAGI Model</a></li>
<li>AgentGPT</li>
<li>GodMode</li>
</ul>
<p>Commercial</p>
<ul>
<li><a href="../c/#cognosys-ai-company">Cognosys AI</a></li>
</ul>
<iframe src="https://www.youtube.com/embed/5DykmpzbV90" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://medium.com/@maanna.stephenson/chatgpt-vs-autogpt-vs-agentgptvs-godmode-1077441a09a4">https://medium.com/@maanna.stephenson/chatgpt-vs-autogpt-vs-agentgptvs-godmode-1077441a09a4</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="taxonomy">Taxonomy<a class="headerlink" href="#taxonomy" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="techno-optimism">Techno Optimism<a class="headerlink" href="#techno-optimism" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="techno-pessimism">Techno Pessimism<a class="headerlink" href="#techno-pessimism" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="temperature">Temperature<a class="headerlink" href="#temperature" title="Permanent link">#</a></h2>
<p>This <a href="../i/#inference-configuration-parameter">inference configuration parameter</a> helps to control the randomness of the model output by modifying the shape of the next-token probability distribution. In general, the higher the temperature, the higher the randomness; the lower the temperature, the lower the randomness.</p>
<p>In contrast to [sample top-k] and [sample top-p], changing the temperature actually changes the next-token probability distribution, which ultimately affects the next-token prediction.</p>
<p>A low temperature, below 1 for example, results in stronger peaks where the probabilities are concentrated among a smaller subset of tokens. A higher temperature, above 1 for example, results in a flatter next-token probability distribution where the probabilities are more evenly spread across the tokens. Setting the temperature to 1 leaves the next-token probability distribution unaltered, which represents the distribution learned during model training and tuning.</p>
<p><img alt="" src="../img/t/temperature.png" width="100%" /></p>
<p>In both cases, the model selects the next token from the modified probability distribution using either [greedy sampling] or <a href="../r/#random-sampling">random sampling</a>, which is orthogonal to the temperature parameter.</p>
<p>Note that if the temperature value is too low, the model may generate more repetitions; if the temperature is too high, the model may generate nonsensical output. However, starting with a temperate value of 1 is usually a good strategy.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tensor">Tensor<a class="headerlink" href="#tensor" title="Permanent link">#</a></h2>
<p>A matrix (not a vector) of inputs. Ex an image is converted to a tensor and fed to the input of a convolutional neural network.</p>
<p>See also <a href="./">T</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a>, <a href="../v/#vector">Vector</a></p>
<h2 id="tensor-processing-unit-tpu">Tensor Processing Unit (TPU)<a class="headerlink" href="#tensor-processing-unit-tpu" title="Permanent link">#</a></h2>
<p>GPU-like hardware built by <a href="../g/#google-company">Google</a> specifically to run AI/ML training and accelerate deployed model inferences</p>
<p>See also <a href="./">T</a>, <a href="./#tensor">Tensor</a></p>
<h2 id="tensorflow-framework">TensorFlow Framework<a class="headerlink" href="#tensorflow-framework" title="Permanent link">#</a></h2>
<p>One of the leading AI/ML framework. Was developed by <a href="../g/#google-company">Google</a> and released as open-source.</p>
<p>More at:</p>
<ul>
<li>tutorials<ul>
<li><a href="https://developers.google.com/machine-learning/crash-course">https://developers.google.com/machine-learning/crash-course</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, <a href="../d/#deep-learning-framework">Deep Learning Framework</a>, <a href="../d/#distributed-training">Distributed Training</a>, <a href="../m/#machine-learning-framework">Machine Learning Framework</a></p>
<h2 id="tensorflow-hub">TensorFlow Hub<a class="headerlink" href="#tensorflow-hub" title="Permanent link">#</a></h2>
<p>~ A <a href="../m/#model-hub">model hub</a> for models buit with <a href="./#tensorflow-framework">TensorFlow</a></p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>tensorflow_hub
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_hub</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">hub</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="s2">&quot;https://tfhub.dev/google/nnlm-en-dim128/2&quot;</span><span class="p">)</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">([</span><span class="s2">&quot;The rain in Spain.&quot;</span><span class="p">,</span> <span class="s2">&quot;falls&quot;</span><span class="p">,</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>                    <span class="s2">&quot;mainly&quot;</span><span class="p">,</span> <span class="s2">&quot;In the plain!&quot;</span><span class="p">])</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1">#(4,128)</span>
</span></code></pre></div>
<p>More at:</p>
<ul>
<li>site - <a href="https://www.tensorflow.org/hub">https://www.tensorflow.org/hub</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tensorflow-python-module">TensorFlow Python Module<a class="headerlink" href="#tensorflow-python-module" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tensorrt-sdk">TensorRT SDK<a class="headerlink" href="#tensorrt-sdk" title="Permanent link">#</a></h2>
<p>A Software Development Kit (SDK) developed by <a href="../n/#nvidia-company">Nvidia</a></p>
<p>More at:
  * home - <a href="https://developer.nvidia.com/tensorrt">https://developer.nvidia.com/tensorrt</a></p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="term-frequency-tf">Term Frequency (TF)<a class="headerlink" href="#term-frequency-tf" title="Permanent link">#</a></h2>
<p>~ measures how frequently a term occurs in a document.</p>
<p>Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).
</span></code></pre></div>
<p>See also <a href="./">T</a>, <a href="./#term-frequency-inverse-document-frequency-tf-idf-retrieval-model">TF-IDF</a></p>
<h2 id="term-frequency-inverse-document-frequency-tf-idf-retrieval-model">Term Frequency-Inverse Document Frequency (TF-IDF) Retrieval Model<a class="headerlink" href="#term-frequency-inverse-document-frequency-tf-idf-retrieval-model" title="Permanent link">#</a></h2>
<p>TF-IDF stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in [information retrieval] and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. Variations of the tf-idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. One of the simplest ranking functions is computed by summing the tf-idf for each query term; many more sophisticated ranking functions are variants of this simple model. Tf-idf can be successfully used for stop-words filtering in various subject fields including text summarization and classification. Typically, the tf-idf weight is composed by two terms: the first computes the normalized <a href="./#term-frequency-tf">Term Frequency (TF)</a>, aka. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the <a href="../i/#inverse-document-frequency-idf">Inverse Document Frequency (IDF)</a>, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.</p>
<p><img alt="" src="../img/t/term_frequency_inverse_document_frequency_retrieval_model.jpeg" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="http://tfidf.com/">http://tfidf.com/</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../n/#natural-language-processing-nlp">NLP</a>, <a href="../r/#retrieval-based-model">Retrieval Model</a>, [Term Frequency Matrix]</p>
<h2 id="term-frequency-matrix-tfm">Term Frequency Matrix (TFM)<a class="headerlink" href="#term-frequency-matrix-tfm" title="Permanent link">#</a></h2>
<p>The simplest way to map text into a numerical representation is to compute the frequency of each word within each text document. Think of a matrix of integers where each row represents a text document and each column represents a word. This matrix representation of the word frequencies is commonly called Term Frequency Matrix (TFM).</p>
<p>See also <a href="./">T</a>, <a href="../n/#natural-language-processing-nlp">NLP</a>, [Term Frequency Inverse Document Frequency]</p>
<h2 id="test-set">Test Set<a class="headerlink" href="#test-set" title="Permanent link">#</a></h2>
<p>~ in ML, this testing data is input given to the AI system that it has not seen before and was not part of the <a href="./#training-set">training set</a></p>
<p>Use to see how the model built with the <a href="./#training-set">training set</a> and the <a href="../d/#development-subset">development subset</a> performs on new data. The performance of the model will show issues related to overfitting, etc. This subset includes only the <a href="../f/#feature">features</a> (and not the labels) since we want to predict the [labels]. The performance we see on the test set is what we can reasonably see in production. <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> The test set cannot be used at any time in the training or post-training phase (i.e model auto tuning, eg <a href="../o/#overfitting">overfitting</a> vs <a href="../u/#underfitting">underfitting</a>).</p>
<p><img alt="" src="../img/t/train_test_sets.png" width="100%" /></p>
<p>See also <a href="./">T</a>, <a href="../d/#dataset">Dataset</a></p>
<h2 id="text-embedding">Text Embedding<a class="headerlink" href="#text-embedding" title="Permanent link">#</a></h2>
<ul>
<li><a href="../w/#word-embedding">Word Embedding</a></li>
<li><a href="../s/#sentence-embedding">Sentence Embedding</a></li>
<li><a href="../d/#document-embedding">Document Embedding</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../e/#embedding">Embedding</a></p>
<h2 id="text-extraction">Text Extraction<a class="headerlink" href="#text-extraction" title="Permanent link">#</a></h2>
<p>~ Optical Character Recognition </p>
<p>Text extraction from an image (also known as OCR - Optical Character Recognition) is the process of detecting and converting text content within images into machine-readable, editable text.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">together</span><span class="w"> </span><span class="kn">import</span> <span class="n">Together</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">getDescriptionPrompt</span> <span class="o">=</span> <span class="s2">&quot;Extract out the details from each line item on the receipt image. Identify the name, price and quantity of each item. Also specify the total.&quot;</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">imageUrl</span> <span class="o">=</span> <span class="s2">&quot;https://ocr.space/Content/Images/receipt-ocr-original.webp&quot;</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="n">client</span> <span class="o">=</span> <span class="n">Together</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">TOGETHER_API_KEY</span><span class="p">)</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo&quot;</span><span class="p">,</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>        <span class="p">{</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>                <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">getDescriptionPrompt</span><span class="p">},</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>                <span class="p">{</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>                    <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>                        <span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="n">imageUrl</span><span class="p">,</span>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>                    <span class="p">},</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>                <span class="p">},</span>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>            <span class="p">],</span>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>        <span class="p">}</span>
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>    <span class="p">],</span>
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a><span class="p">)</span>
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a><span class="n">info</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span></code></pre></div>
<p>More at:</p>
<ul>
<li>notebooks<ul>
<li><a href="https://github.com/togethercomputer/together-cookbook/blob/main/Structured_Text_Extraction_from_Images.ipynb">https://github.com/togethercomputer/together-cookbook/blob/main/Structured_Text_Extraction_from_Images.ipynb</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="text-generation">Text Generation<a class="headerlink" href="#text-generation" title="Permanent link">#</a></h2>
<p>Text generation refers to the process of using algorithms to produce coherent and contextually relevant text. This can involve tasks such as:</p>
<ul>
<li>Completing sentences or paragraphs based on a prompt.</li>
<li>Creative writing like poetry or storytelling.</li>
<li>Generating responses in conversational AI systems.</li>
<li>Producing summaries, translations, or descriptions.</li>
</ul>
<p>The goal is for the generated text to appear as though it was written by a human, maintaining logical flow, grammar, and context.</p>
<p>Models capable of text generation include those trained using deep learning techniques, specifically in the domain of Natural Language Processing (NLP). Examples include:</p>
<ul>
<li><a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT models</a></li>
<li>mT5 and <a href="./#text-to-text-transfer-transformer-t5-model-family">T5 models</a></li>
<li>[Bert variants]</li>
<li>XLM-R</li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="text-reconstruction">Text Reconstruction<a class="headerlink" href="#text-reconstruction" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/t/text_reconstruction.png" width="100%" /></p>
<p>Above is a pipeline for text reconstruction. The input text is fed to DALL-E/SD to generate an image, whcih is fed to Flamingo/BLIP to generate a caption, which is fed to DALL-E/SD to reconstruct a text caption. The generated text-caption is compared with the input text using the CLIP text encoder in the embedding space.</p>
<p>See also <a href="./">T</a>, <a href="../b/#blip-model">BLIP Model</a>, <a href="../c/#clip-text-encoder">CLIP Text Encoder</a>, <a href="../i/#image-reconstruction">Image Reconstruction</a></p>
<h2 id="text-summarization">Text Summarization<a class="headerlink" href="#text-summarization" title="Permanent link">#</a></h2>
<p>Summarizing a text involves reducing its size while keeping key information and the essential meaning. Some everyday examples of text summarization are news headlines, movie previews, newsletter production, financial research, legal contract analysis, and email summaries, as well as applications delivering news feeds, reports, and emails.</p>
<p>Summarization can be evaluated using the <a href="../r/#recall-oriented-understudy-for-gisting-evaluation-rouge-score">ROUGE Score</a></p>
<p>For documents that are very long, the recommended approach is to use a summary of summaries! This also helps navigating a long document.</p>
<p><img alt="" src="../img/t/text_summarization_summary_of_summaries.png" width="100%" /></p>
<p>See also <a href="./">T</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a></p>
<h2 id="text-to-speech-tts-model">Text-To-Speech (TTS) Model<a class="headerlink" href="#text-to-speech-tts-model" title="Permanent link">#</a></h2>
<p>Turn text into speech. The opposite of [Speech-To-Text (STT)]</p>
<p>Models such as</p>
<ul>
<li>the <a href="../r/#riva-model">Riva</a> by <a href="../n/#nvidia-company">Nvidia</a></li>
<li>the <a href="../w/#wavenet-model">WaveNet</a> by <a href="../d/#deepmind-company">DeepMind</a></li>
</ul>
<p>More at:</p>
<ul>
<li>PDF 2 podcast - <a href="https://github.com/togethercomputer/together-cookbook/blob/main/PDF_to_Podcast.ipynb">https://github.com/togethercomputer/together-cookbook/blob/main/PDF_to_Podcast.ipynb</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../s/#sequence-to-sequence-seq2seq-model">Sequence To Sequence Model</a></p>
<h2 id="text-to-text-transfer-transformer-t5-model-family">Text-To-Text Transfer Transformer (T5) Model Family<a class="headerlink" href="#text-to-text-transfer-transformer-t5-model-family" title="Permanent link">#</a></h2>
<p>A sequence-to-sequence model built at <a href="../g/#google-company">Google</a></p>
<p>The T5 model, pre-trained on C4, achieves state-of-the-art results on many NLP benchmarks while being flexible enough to be fine-tuned to a variety of important downstream tasks.</p>
<p>Trained with <a href="../c/#colossal-clean-crawled-corpus-c4">Colossal Clean Crawled Corpus (C4)</a>. A <a href="./#transformer-based-model">Transformer-based model</a> that uses a text-to-text approach. Every task – including translation, question answering, and classification – is cast as feeding the model text as input and training it to generate some target text. This allows for the use of the same model, loss function, hyperparameters, etc. across our diverse set of tasks. The changes compared to <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT</a> include:</p>
<ul>
<li>adding a causal decoder to the bidirectional architecture.</li>
<li>replacing the fill-in-the-blank cloze task with a mix of alternative pre-training tasks.</li>
</ul>
<p>T5 claims the state of the art on more than twenty established NLP tasks. It’s extremely rare for a single method to yield consistent progress across so many tasks. That list includes most of the tasks in the <a href="../g/#general-language-understanding-evaluation-glue-benchmark">GLUE</a> and [SuperGLUE] benchmarks, which have caught on as one of the main measures of progress for applied language understanding work of this kind (and which my group helped to create). On many of these task datasets, T5 is doing as well as human crowdworkers, which suggests that it may be reaching the upper bound on how well it is possible to do on our metrics.</p>
<p><img alt="" src="../img/t/t5_model.jpeg" width="100%" /></p>
<p>In the same model family are:</p>
<ul>
<li>T5 (Original, 2020) – The first version introduced in the paper "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer." It used a text-to-text framework for various NLP tasks.</li>
<li>mT5 (Multilingual T5, 2021) – A version trained on 101 languages using the [multilingual Common Crawl dataset].</li>
<li>T5.1.1 – An improved version of the original T5 with modifications to training techniques, layer normalization, and the removal of dropout.</li>
<li>T5+ (T5 XXL &amp; T5 Ultimate, 2022) – Larger-scale versions of T5, including T5-XXL, which has 11 billion parameters.</li>
<li>UL2 (Unified Language Learning, 2022) – A more advanced model inspired by T5, improving pretraining techniques.</li>
<li>Flan-T5 (Fine-tuned LAnguage Net, 2022-2023) – A version fine-tuned using instruction-based learning, making it much better at following human prompts.</li>
<li>Flan-UL2 (2023) – A combination of UL2 and instruction tuning, making it even more generalizable.</li>
</ul>
<p>Each iteration has brought improvements in performance, scalability, and adaptability.</p>
<p>More at:</p>
<ul>
<li><a href="https://paperswithcode.com/method/t5">https://paperswithcode.com/method/t5</a></li>
<li>code - <a href="https://github.com/google-research/text-to-text-transfer-transformer">https://github.com/google-research/text-to-text-transfer-transformer</a></li>
<li>blog article - <a href="https://medium.com/syncedreview/google-t5-explores-the-limits-of-transfer-learning-a87afbf2615b">https://medium.com/syncedreview/google-t5-explores-the-limits-of-transfer-learning-a87afbf2615b</a></li>
<li><a href="https://paperswithcode.com/method/t5#:~:text=T5%2C%20or%20Text%2Dto%2D,to%20generate%20some%20target%20text.">https://paperswithcode.com/method/t5#:~:text=T5%2C%20or%20Text%2Dto%2D,to%20generate%20some%20target%20text.</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../s/#switch-transformer-model">Switch Transformer</a>, [Transformer Model]</p>
<h2 id="textual-inversion">Textual Inversion<a class="headerlink" href="#textual-inversion" title="Permanent link">#</a></h2>
<p>~ USED TO INTRODUCE A NEW CONCEPT, STYLE, (possibly object/subject) and associating it with a novel word </p>
<p>We learn to generate specific concepts, like personal objects or artistic styles, by describing them using new "words" in the <a href="../e/#embedding-space">embedding space</a> of pre-trained text-to-image models. These can be used in new sentences, just like any other word. This work builds on the publicly available [Latent Diffusion Models]</p>
<p><img alt="" src="../img/t/textual_inversion.jpeg" width="100%" /></p>
<object data="https://arxiv.org/pdf/2208.01618v1" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2208.01618v1">Download PDF</a>.
    </p>
</object>

<p>More at: </p>
<ul>
<li>site - <a href="https://textual-inversion.github.io">https://textual-inversion.github.io/</a></li>
<li>code - <a href="https://github.com/rinongal/textual_inversion">https://github.com/rinongal/textual_inversion</a></li>
<li>paper - <a href="https://arxiv.org/abs/2208.01618v1">https://arxiv.org/abs/2208.01618v1</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="theano">Theano<a class="headerlink" href="#theano" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="theory-of-mind-tom">Theory Of Mind (ToM)<a class="headerlink" href="#theory-of-mind-tom" title="Permanent link">#</a></h2>
<p>Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We administer classic false-belief tasks, widely used to test ToM in humans, to several language models, without any examples or pre-training. Our results show that models published before 2022 show virtually no ability to solve ToM tasks. Yet, the January 2022 version of <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT-3</a> (davinci-002) solved 70% of ToM tasks, a performance comparable with that of seven-year-old children. Moreover, its November 2022 version (ChatGPT/davinci-003), solved 93% of ToM tasks, a performance comparable with that of nine-year-old children. These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models’ improving language skills.</p>
<p>For example, to correctly interpret the sentence “Virginie believes that Floriane thinks that Akasha is happy,” one needs to understand the concept of the mental states (e.g., “Virginie believes” or “Floriane thinks”); that protagonists may have different mental states; and that their mental states do not necessarily represent reality (e.g., Akasha may not be happy, or Floriane may not really think that).</p>
<p>Beware:</p>
<ul>
<li><img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> abilities that rely on ToM ==&gt; empathy, moral judgment, or self-consciousness.</li>
</ul>
<p><img alt="" src="../img/t/theory_of_mind.webp" width="100%" /></p>
<object data="https://arxiv.org/pdf/2302.02083" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2302.02083">Download PDF</a>.
    </p>
</object>

<object data="https://arxiv.org/pdf/2402.06044" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2402.06044">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>philosophy - <a href="https://iep.utm.edu/theomind/">https://iep.utm.edu/theomind/</a></li>
<li>paper <ul>
<li>Tom tasks - <a href="https://arxiv.org/abs/2302.02083">https://arxiv.org/abs/2302.02083</a></li>
<li>OpenToM - [<a href="https://arxiv.org/abs/2402.06044](https://arxiv.org/abs/2402.060440">https://arxiv.org/abs/2402.06044](https://arxiv.org/abs/2402.060440</a></li>
</ul>
</li>
<li>colab - <a href="https://colab.research.google.com/drive/1zQKSDEhqEFcLCf5LuW--A-TGcAhF19hT">https://colab.research.google.com/drive/1zQKSDEhqEFcLCf5LuW--A-TGcAhF19hT</a></li>
<li>articles<ul>
<li><a href="https://towardsdatascience.com/is-chatgpt-intelligent-a-scientific-review-0362eadb25f9">https://towardsdatascience.com/is-chatgpt-intelligent-a-scientific-review-0362eadb25f9</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, <a href="../e/#emergent-ability">Emergent Ability</a>, <a href="../f/#for-stress-testing-machine-theory-of-mind-fantom-benchmark">FANToM Benchmark</a>, <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT Model</a>, <a href="../l/#large-language-model-llm">Large Language Model</a></p>
<h2 id="thresholding">Thresholding<a class="headerlink" href="#thresholding" title="Permanent link">#</a></h2>
<p>~ using a discriminatory threshold for separation</p>
<p>~ what you measure vs what you classify is as</p>
<p>In <a href="../i/#image-segmentation">image segmentation</a>, ...</p>
<p>In <a href="../c/#classification-task">classification</a>, ... each threshold correspond to a different <a href="../c/#confusion-matrix">confusion matrix</a> which in turn is then plotted as a point on the <a href="../r/#receiver-operating-characteristic-roc-curve">ROC Curve</a>. In aggregate, after all the thresholds and the ROC is plotted to calculate the <a href="../a/#area-under-the-receiver-operating-characteristic-auroc-curve">Area Under the Receiver Operating Characteristic (AUROC) Curve</a>.</p>
<p><img alt="" src="../img/t/thresholding_low_threshold.png" width="100%" /></p>
<p><img alt="" src="../img/t/thresholding_table.png" width="100%" /></p>
<p><img alt="" src="../img/t/thresholding_high_threshold.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://pair.withgoogle.com/explorables/uncertainty-calibration/">https://pair.withgoogle.com/explorables/uncertainty-calibration/</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="time-step">Time Step<a class="headerlink" href="#time-step" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="time-series-predictive-analysis">Time-Series Predictive Analysis<a class="headerlink" href="#time-series-predictive-analysis" title="Permanent link">#</a></h2>
<p><code>~ look at a sequence of elements/images, find the next element/image = time series representation</code>. For example, music can be represented with a time series. In this approach, music is represented as time-series data, where each note is based on the previous notes. </p>
<p>See also <a href="./">T</a>, <a href="../a/#autoregressive-ar-model">Autoregressive Model</a></p>
<h2 id="token-embedding">Token Embedding<a class="headerlink" href="#token-embedding" title="Permanent link">#</a></h2>
<p>~ The token embedding layer (sometimes called the embedding table or embedding matrix) transforms [token IDs] into token embeddings. It's one of the first layers in transformer models.</p>
<p>Token embeddings are dense vectors (arrays of numbers) that represent tokens in a high-dimensional space. For example, a token might be represented by a vector of 768 numbers. These vectors are learned during model training and capture semantic relationships between tokens. Similar words end up with similar embedding vectors.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>&quot;cat&quot;: [0.2, -0.5, 0.1, ...]
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>&quot;dog&quot;: [0.3, -0.4, 0.15, ...]
</span></code></pre></div>
<p>The similarity of these embedding vectors would reflect that cats and dogs are both animals. The model converts token IDs to embeddings as its first step in processing text.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="token-id">Token ID<a class="headerlink" href="#token-id" title="Permanent link">#</a></h2>
<p>Token Identifiers (IDs) are simply numbers assigned to each token in the vocabulary. They're like an index or ID number - for example, the word "hello" might be assigned token ID 234. These IDs are arbitrary numbers that just serve as labels. They have no mathematical relationship to each other - token ID 234 isn't "closer" to token ID 235 in any meaningful way.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tokenization">Tokenization<a class="headerlink" href="#tokenization" title="Permanent link">#</a></h2>
<p>Tokenization is the first step in any <a href="../n/#natural-language-processing-nlp">NLP</a> pipeline. It has an important effect on the rest of your pipeline. A <a href="./#tokenizer">tokenizer</a> breaks unstructured data and natural language text into chunks of information that can be considered as discrete elements. The token occurrences in a document can be used directly as a vector representing that document. Tokenization can separate sentences, words, characters, or subwords. When we split the text into sentences, we call it sentence tokenization. For words, we call it word tokenization.</p>
<p>Tokenization algorithms run after <a href="../p/#pre-tokenization">Pre-Tokenization</a>:</p>
<ul>
<li><a href="../b/#byte-pair-encoding-bpe-tokenization">Byte-Pair Encoding (BPE) tokenization</a></li>
<li>[WordPiece tokenization]</li>
<li><a href="../u/#unigram-tokenization">Unigram tokenization</a></li>
<li>...</li>
</ul>
<p>Tokenization pipeline:</p>
<p><img alt="" src="../img/t/tokenization_pipeline.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>tiktokenizer app - <a href="https://tiktokenizer.vercel.app/">https://tiktokenizer.vercel.app/</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../p/#pre-tokenization">Pre-Tokenization</a>, <a href="./#tokenizer">Tokenizer</a></p>
<h2 id="tokenizer">Tokenizer<a class="headerlink" href="#tokenizer" title="Permanent link">#</a></h2>
<p><img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> If you want to change a tokenizer for a model, you have to rebuild the model!</p>
<p><img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Pass the tokens and their positions (index in the list!) <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> The tokens are then coded in number / ~ line number of token in file <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Prefix and suffix may be added to token for multi-input processing (e.g. "[CLS]" or "[SEP]" )
 Two terms we see a lot when working with tokenization is uncased and cased (Note this has little to do with the BERT architecture, just tokenization!).</p>
<ul>
<li>uncased --&gt; removes accents, lower-case the input <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Usually better for most situation as case does NOT contribute to context</li>
<li>cased --&gt; does nothing to input <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" />  recommended where case does matter, such as Name Entity Recognition
 and more</li>
<li>clean_text : remove control characters and replace all whitespace with spaces</li>
<li>handle_chinese_chars : includes spaces around Chinese characters (if found in the dataset)</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>                           Hope, is the only thing string than fear! #Hope #Amal.M
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a># Space tokenizer (split)  [&#39;Hope,&#39;, &#39;is&#39;, &#39;the&#39;, &#39;only&#39;, &#39;thing&#39;, &#39;string&#39;, &#39;can&#39;, &#39;fear!&#39;, &#39;#hope&#39;, &#39;#Amal.M&#39;]
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a># Word tokenizer           [&#39;Hope&#39;, &#39;,&#39;, &#39;is&#39;, &#39;the&#39;,  &#39;only&#39;, &#39;thing&#39;, &#39;,string&#39;, &#39;than&#39;, &#39;fear&#39;, &#39;!&#39;,  &#39;#&#39;, &#39;Hope&#39;, &#39;#&#39;, &#39;Amal.M&#39;]
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a># Sentence tokenizer       [&#39;Hope, is the only thing string than fear!&#39;, &#39;#Hope #Amal.M&#39;]
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a># Word-Punct tokenizer     [&#39;Hope&#39;, &#39;,&#39;, &#39;is&#39;, &#39;the&#39;,  &#39;only&#39;, &#39;thing&#39;, &#39;,string&#39;, &#39;than&#39;, &#39;fear&#39;, &#39;!&#39;,  &#39;#&#39;, &#39;Hope&#39;, &#39;#&#39;, &#39;Amal&#39;, &#39;.&#39;, &#39;M&#39;]
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>                           What you don&#39;t want to be done to yourself, don&#39;t do to others...
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a># Treebank word tokenizer  [&#39;What&#39;, &#39;you&#39;, &#39;do&#39;, &quot;n&#39;t&quot;, &#39;want&#39;, &#39;to&#39;, &#39;be&#39;, &#39;done&#39;, &#39;to&#39;, &#39;yourself&#39;, &#39;,&#39;, &#39;do&#39;, &quot;n&#39;t&quot;, &#39;do&#39;, &#39;to&#39;, &#39;others&#39;, &#39;...&#39;]
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a># Wordpiece tokenizer :
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>   * It works by splitting words either into the full forms (e.g., one word becomes one token) or into word pieces — where one word can be broken into multiple tokens.
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>   * the original BERT uses.
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>Word            Token(s)
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>surf            [&#39;surf&#39;]
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>surfing         [&#39;surf&#39;, &#39;##ing&#39;]
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>surfboarding    [&#39;surf&#39;, &#39;##board&#39;, &#39;##ing&#39;]
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>surfboard   [&#39;surf&#39;, &#39;##board&#39;]
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>snowboard   [&#39;snow&#39;, &#39;##board&#39;]
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>snowboarding    [&#39;snow&#39;, &#39;##board&#39;, &#39;##ing&#39;]
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>snow            [&#39;snow&#39;]
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>snowing         [&#39;snow&#39;, &#39;##ing&#39;]
</span></code></pre></div>
<p>/// details | Why so many tokenizers?
    type:question</p>
<div class="language-text highlight"><pre><span></span><code>* Language coverage: Languages have vastly different structures and writing systems. A tokenizer optimized for English might perform poorly on Chinese or Arabic.
* Vocabulary size: Tokenizers make different choices about vocabulary size. Larger vocabularies can represent more words directly but require more memory and computation.
* Training data: Tokenizers are often trained on specific corpora that reflect their intended use. A tokenizer trained on scientific papers will develop different tokens than one trained on social media posts.
* Model architecture requirements: Some models work better with certain tokenization schemes. For example, byte-pair encoding (BPE) works well for transformer models, while character-level tokenization might be better for certain RNN architectures.
* Historical development: As NLP has evolved, different researchers and organizations developed their own approaches to tokenization. While some standardization might be beneficial, the field has grown organically with multiple competing approaches.
</code></pre></div>
<p>///</p>
<p>/// details | Do tokenizer consider semantic meaning or context when tokenizing words?
    type:question</p>
<div class="language-text highlight"><pre><span></span><code>* No, they operate based on statistical patterns and predefined rules, not meaning. So the word &quot;bank&quot; would be tokenized the same way whether it means: (1) A financial institution, (2) The edge of a river, (3) To tilt or turn (as in &quot;the plane banks left&quot;)
* No, the understanding of different meanings happens later in the model&#39;s processing through context and attention mechanisms. The tokenizer&#39;s job is just to convert text into numbers (tokens) that the model can process.
</code></pre></div>
<p>///</p>
<p>More at:</p>
<ul>
<li>tiktokenizer app - <a href="https://tiktokenizer.vercel.app/">https://tiktokenizer.vercel.app/</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT Model</a>, <a href="./#tokenization">Tokenization</a></p>
<h2 id="tokenizer-tax">Tokenizer Tax<a class="headerlink" href="#tokenizer-tax" title="Permanent link">#</a></h2>
<p>[Tokenizers] break words into token. LLM are priced based on submitted-input and generated-output token. </p>
<p>Therefore token pricing is only half of the story when comparing costs across LLM providers. Different models use different tokenizers, and tokenizers can create different number of tokens for the same number of words.</p>
<p>For example, Claude-Sonnet tokenizers uses ~ 20% more tokens than OpenAI GPT-4o tokenizer for English news and 45% more tokens for Python code. Therefore when looking at <a href="../l/#llm-pricing">LLM pricing</a> for the SAME PROMPT to both OpenAI GPT model and Anthropic Claude Sonnet in addition to  paying a higher base price ($ / million token), you will also pay 20% more on typical English text, and 45% more on Python code with Anthropic Claude Sonnet 3.5.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="top-k-random-sampling">Top-K Random Sampling<a class="headerlink" href="#top-k-random-sampling" title="Permanent link">#</a></h2>
<p>~ an <a href="../i/#inference-configuration-parameter">inference configuration parameter</a> used to limit the number of tokens to select from. A variation on <a href="./#top-p-random-sampling">top-p random sampling</a>.</p>
<p>One of the most common [inference configuration parameters] when using <a href="../r/#random-sampling">random sampling</a>. These parameters provide more fine-grained control for the random sample which, if used properly, should improve the model’s response yet allow it to be creative enough to fulfill the generative task.</p>
<p>Sample top-k limits the model to choose a token randomly from only the top-k tokens with the highest probability. For example, if k is set to 3, you are restricting the model to choose from only the top-3 tokens using the weighted random-sampling strategy. In this case, the model randomly chooses “from” as the next token, although it could have selected from one of the other two, as shown in</p>
<p><img alt="" src="../img/t/top_k_random_sampling.png" width="100%" /></p>
<p>Note that setting top-k to a higher number can help reduce repetitiveness, while setting top k to 1 basically gives you [greedy sampling].</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="top-k-similarity-search">Top-K Similarity Search<a class="headerlink" href="#top-k-similarity-search" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/t/top_k_similary_search.gif" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/8YtfmOqj28c" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://community.fullstackretrieval.com/retrieval-methods/top-k-similarity-search">https://community.fullstackretrieval.com/retrieval-methods/top-k-similarity-search</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="top-p-random-sampling">Top-P Random Sampling<a class="headerlink" href="#top-p-random-sampling" title="Permanent link">#</a></h2>
<p>~ an <a href="../i/#inference-configuration-parameter">inference configuration parameter</a> used to limit the number of tokens to select from. A variation on <a href="./#top-k-random-sampling">top-K random sampling</a>.</p>
<p>Sample top-p limits the model to randomly sample from the set of tokens whose cumulative probabilities do not exceed p, starting from the highest probability working down to the lowest probability. To illustrate this, first sort the tokens in descending order based on the probability. Then select a subset of tokens whose cumulative probability scores do not exceed p.</p>
<p>For example, if p = 0.32, the options are “learns”, “from”, and “student” since their probabilities of 0.20, 0.10, and 0.02, respectively, add up to 0.32. The model then uses the weighted random-sampling strategy to choose the next token, “student” in this case, from this subset of tokens, as shown below</p>
<p><img alt="" src="../img/t/top_p_random_sampling.png" width="100%" /></p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="torch">Torch<a class="headerlink" href="#torch" title="Permanent link">#</a></h2>
<p>at the origin of pytorch?</p>
<p>See also <a href="./">T</a>, <a href="../p/#pytorch-python-module">PyTorch</a></p>
<h2 id="torchscript-format">TorchScript Format<a class="headerlink" href="#torchscript-format" title="Permanent link">#</a></h2>
<p>TorchScript is a way to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency.</p>
<p>More at:</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/jit.html">https://pytorch.org/docs/stable/jit.html</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="traditional-programming">Traditional Programming<a class="headerlink" href="#traditional-programming" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>          +-------------------------+
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>Input --&gt; | Traditional Programming | --&gt; Outout
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>          |        Algorithm        |
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>          +-------------------------+
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>                   +------------------+
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>        Input  --&gt; | Machine Learning |
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>Desired Output --&gt; |     Training     | --&gt; Model
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>                   +------------------+
</span></code></pre></div>
<p>See also <a href="./">T</a>, [Machine Learning]</p>
<h2 id="train-testing-split">Train Testing Split<a class="headerlink" href="#train-testing-split" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="training-loss">Training Loss<a class="headerlink" href="#training-loss" title="Permanent link">#</a></h2>
<p>Training loss is a measure used in [machine learning] to evaluate the performance of a model during the training phase. It quantifies how well the model's [predictions] match the actual target values in the <a href="./#training-set">training set</a> or training dataset. Training loss is calculated using a <a href="../l/#loss-function">loss function</a>, which is a mathematical formula that measures the difference between the model's predictions and the actual data. Common examples of [loss functions] include <a href="../m/#mean-square-error-mse-loss-function">mean squared error (MSE)</a> for <a href="../r/#regression-task">regression tasks</a> and [cross-entropy loss] for <a href="../c/#classification-task">classification tasks</a>.</p>
<p>The primary goal during training is to minimize this loss. A lower training loss indicates that the model's predictions are close to the true values, which means the model is learning effectively. During training, algorithms like gradient descent are used to adjust the model's parameters (like weights in neural networks) to reduce the training loss.</p>
<p>It's important to balance the training loss with the model's performance on unseen data (validation loss). A model with very low training loss might be overfitting, which means it's memorizing the training data rather than learning to generalize from it.</p>
<p>Training loss is also a crucial feedback tool for tuning hyperparameters and making decisions about model architecture.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="training-set">Training Set<a class="headerlink" href="#training-set" title="Permanent link">#</a></h2>
<p>Use with the development subset to build the model.</p>
<p>See also <a href="./">T</a>, <a href="../c/#cross-validation-sampling-method">Cross-validation Sampling Method</a>, <a href="../d/#dataset">Dataset</a>, <a href="../d/#development-subset">Development Subset</a>, <a href="../o/#overfitting">Overfitting</a>, <a href="./#test-set">Test Set</a></p>
<h2 id="trajectory">Trajectory<a class="headerlink" href="#trajectory" title="Permanent link">#</a></h2>
<p>In [Reinforcement Learning (RL)], a trajectory is the sequence of <a href="../s/#state">states</a> that an <a href="../a/#agent">agent</a> goes through given a fixed <a href="../p/#policy">policy</a>.</p>
<p>A trajectory refers to a sequence of <a href="../s/#state">states</a>, <a href="../a/#action">actions</a>, <a href="../r/#reward">rewards</a>, and potentially other information that an agent encounters during its interaction with an environment. It represents the history of the agent's experience while navigating the environment and is often used to learn and improve the agent's <a href="../p/#policy">policy</a> or value function.</p>
<p>A trajectory typically starts from an initial state and extends over a certain number of time steps. At each time step, the agent observes the current state, selects an action based on its <a href="../p/#policy">policy</a>, receives a reward from the environment, and transitions to the next state. This process continues until a termination condition is met, such as reaching a goal state or a predefined time limit.</p>
<p>By examining a trajectory, an RL algorithm can gather information about the agent's past experiences, the consequences of its actions, and the resulting rewards. Trajectories are commonly used in RL algorithms that involve [model-free learning], such as Monte Carlo methods or temporal difference learning, to estimate value functions, compute policy updates, or assess the performance of the agent.</p>
<p>In practice, RL algorithms often sample multiple trajectories from the environment to gather a diverse set of experiences and improve the estimation and learning process. These trajectories provide the necessary data for updating policies, estimating state-action values, or training value function approximators.</p>
<p><img alt="" src="../img/t/trajectory.png" width="100%" /></p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="transfer-learning">Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permanent link">#</a></h2>
<p>~ Learning on one use-case can be reused for another case. Benefits:</p>
<ul>
<li>training cost is reduced</li>
<li>the way human work!</li>
<li>Training when not enough data? --&gt; reuse previous learning to build new model and change only a delta</li>
</ul>
<p>Approach:</p>
<ul>
<li>select a source model from a model repository (ex: huggingface)</li>
<li>reuse and train model</li>
</ul>
<p>Example:</p>
<ul>
<li>BERT + financial data --&gt; FinBERT</li>
<li>BERT + classification layer --&gt; BERT for classification !!!!!</li>
</ul>
<p>Let’s pretend that you’re a data scientist working in the retail industry. You’ve spent months training a high-quality model to classify images as shirts, t-shirts and polos. Your new task is to build a similar model to classify images of dresses as jeans, cargo, casual, and dress pants. Can you transfer the knowledge built into the first model and apply it to the second model? Yes, you can, using Transfer Learning. <code>Transfer Learning refers to re-using part of a previously trained neural net and adapting it to a new but similar task</code> Specifically, once you train a neural net using data for a task, you can transfer a fraction of the trained layers and combine them with a few new layers that you can train using the data of the new task. By adding a few layers, the new neural net can learn and adapt quickly to the new task. The main advantage of transfer learning is that you need less data to train the neural net, which is particularly important because training for deep learning algorithms is expensive in terms of both time and money (computational resources) — and of course it’s often very difficult to find enough labeled data for the training. Let’s return to our example and assume that for the shirt model you use a neural net with 20 hidden layers. After running a few experiments, you realize that you can transfer 18 of the shirt model layers and combine them with one new layer of parameters to train on the images of pants. The pants model would therefore have 19 hidden layers. The inputs and outputs of the two tasks are different but the re-usable layers may be summarizing information that is relevant to both, for example aspects of cloth. Transfer learning has become more and more popular and there are now many solid pre-trained models available for common deep learning tasks like image and text classification.</p>
<p>Transfer learning is one of the most useful discoveries to come out of the computer vision community. Stated simply, transfer learning allows one model that was trained on different types of images, e.g. dogs vs cats, to be used for a different set of images, e.g. planes vs trains, while reducing the training time dramatically. When Google released !ImageNet, they stated it took them over 14 days to train the model on some of the most powerful GPUs available at the time. Now, with transfer learning, we will train an, albeit smaller, model in less than 5 minutes.</p>
<p><img alt="" src="../img/t/transfer_learning.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/BqqfQnyjmgg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>To execute transfer learning, transfer the weights of the trained model to the new one. Those weights can be retrained entirely, partially (layering), or not at all (prepend a new process such as classification on an encoder output!) <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> BEWARE: When using transfer learning, you transfer the bias for the pretrained model</p>
<p>See also <a href="./">T</a>, <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT Model</a>, <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT Model</a>, <a href="../i/#imagenet-dataset">ImageNet Dataset</a>, <a href="../i/#insufficient-data-algorithm">Insufficient Data Algorithm</a>, [Pre-Trained Model]</p>
<h2 id="transform-function-tf">Transform Function (TF)<a class="headerlink" href="#transform-function-tf" title="Permanent link">#</a></h2>
<p>A function to transform the input dataset. For ex: rotate image in the right position.</p>
<p>See also <a href="./">T</a>, <a href="../l/#labeling-function">Labeling Function</a>, <a href="../s/#slicing-function">Slicing Function</a>, <a href="../s/#snorkel-program">Snorkel Program</a></p>
<h2 id="transformer-architecture">Transformer Architecture<a class="headerlink" href="#transformer-architecture" title="Permanent link">#</a></h2>
<p>The Transformer is a recent deep learning model for use with sequential data such as text, time series, music, and genomes. Whereas older sequence models such as <a href="../r/#recurrent-neural-network-rnn">recurrent neural networks (RNNs)</a> or [Long Short-Term Memory (LSTM) Networks] process data sequentially, the Transformer processes data in parallel (can therefore be parallelised on machines in the cloud!). This allows them to process massive amounts of available training data by using powerful GPU-based compute resources. Furthermore, traditional <a href="../r/#recurrent-neural-network-rnn">RNNs</a> and <a href="../l/#long-short-term-memory-lstm-network">LSTMs</a> can have difficulty modeling the long-term dependencies of a sequence because they can forget earlier parts of the sequence. Transformers use an attention mechanism to overcome this memory shortcoming by directing each step of the output sequence to pay “attention” to relevant parts of the input sequence. For example, when a Transformer-based conversational AI model is asked “How is the weather now?” and the model replies “It is warm and sunny today,” the attention mechanism guides the model to focus on the word “weather” when answering with “warm” and “sunny,” and to focus on “now” when answering with “today.” This is different from traditional <a href="../r/#recurrent-neural-network-rnn">RNNs</a> and <a href="../l/#long-short-term-memory-lstm-network">LSTMs</a>, which process sentences from left to right and forget the context of each word as the distance between the words increases.</p>
<ul>
<li>word positioning (feed the work and its position in the sentence)</li>
<li>Attention</li>
<li>self-attention (link pronouns, subject to verbs, adjectives to nouns, adverbs)</li>
<li>cross-attention (positioning of words between languages, i.e. input and output)</li>
</ul>
<p><img alt="" src="../img/t/transformer_model_architecture.png" width="100%" /></p>
<p><img alt="" src="../img/t/transformer_model_architecture_overview.png" width="100%" /></p>
<object data="https://arxiv.org/abs/1706.03762" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/abs/1706.03762">Download PDF</a>.
    </p>
</object>

<p>The transformer is a current-state of the art NLP model. It relies almost entirely on self-attention to model the relationship between tokens in a sentence rather than relying on recursion like RNNs and LSTMs do.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>“Adept’s technology sounds plausible in theory, [but] talking about Transformers needing to be ‘able to act’ feels a bit like misdirection to me,” Mike Cook, an AI researcher at the Knives &amp; Paintbrushes research collective, which is unaffiliated with Adept, told TechCrunch via email. “Transformers are designed to predict the next items in a sequence of things, that’s all. To a Transformer, it doesn’t make any difference whether that prediction is a letter in some text, a pixel in an image, or an API call in a bit of code. So this innovation doesn’t feel any more likely to lead to artificial general intelligence than anything else, but it might produce an AI that is better suited to assisting in simple tasks.”
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a># https://techcrunch.com/2022/04/26/2304039/
</span></code></pre></div>
<iframe src="https://www.youtube.com/embed/wjZofJX0v4M" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/zxQyTK8quyY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/g2BRIuln4uc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2302.07730" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2302.07730">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <ul>
<li>original (2017) - <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></li>
<li>transformer catalog - <a href="https://arxiv.org/abs/2302.07730">https://arxiv.org/abs/2302.07730</a></li>
</ul>
</li>
<li>code explanation - <a href="https://nlp.seas.harvard.edu/annotated-transformer/">https://nlp.seas.harvard.edu/annotated-transformer/</a></li>
<li>transformer in pytorch - <a href="https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch">https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch</a></li>
<li>Articles<ul>
<li><a href="https://towardsdatascience.com/breakthroughs-in-speech-recognition-achieved-with-the-use-of-transformers-6aa7c5f8cb02">https://towardsdatascience.com/breakthroughs-in-speech-recognition-achieved-with-the-use-of-transformers-6aa7c5f8cb02</a></li>
<li><a href="https://venturebeat.com/business/why-transformers-offer-more-than-meets-the-eye/">https://venturebeat.com/business/why-transformers-offer-more-than-meets-the-eye/</a></li>
<li>explanation - <a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a></li>
<li><a href="https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0">https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0</a></li>
<li><a href="https://bdtechtalks.com/2022/05/02/what-is-the-transformer/">https://bdtechtalks.com/2022/05/02/what-is-the-transformer/</a></li>
</ul>
</li>
<li>Code samples<ul>
<li>write with transformers - <a href="https://transformer.huggingface.co/">https://transformer.huggingface.co/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, <a href="../a/#action-transformer">Action Transformer</a>, <a href="../a/#attention-score">Attention Score</a>, <a href="../a/#attention-based-model">Attention-Based Model</a>, <a href="../a/#autoregressive-ar-model">Autoregressive Model</a>, <a href="../g/#generative-model">Generative Model</a>, <a href="../m/#masked-self-attention">Masked Self-Attention</a>, <a href="../m/#multi-head-attention">Multi-Head Attention</a>, <a href="../s/#self-attention">Self-Attention</a></p>
<h2 id="transformer-based-model">Transformer-Based Model<a class="headerlink" href="#transformer-based-model" title="Permanent link">#</a></h2>
<p>Models that are based on the <a href="./#transformer-architecture">transformer architecture</a> are:</p>
<ul>
<li><a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT models</a> - use the encoder side of the transformer</li>
<li><a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT models</a> - use the decoder side of the transformer</li>
<li><a href="./#text-to-text-transfer-transformer-t5-model-family">T5 models</a> - use the encode-decoder, the whole transformer !</li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="transfusion-architecture">Transfusion Architecture<a class="headerlink" href="#transfusion-architecture" title="Permanent link">#</a></h2>
<p>Architecture based on transformer and diffusion</p>
<object data="https://www.arxiv.org/pdf/2408.11039" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://www.arxiv.org/pdf/2408.11039">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://www.arxiv.org/abs/2408.11039">https://www.arxiv.org/abs/2408.11039</a></li>
<li>announcement - <a href="https://x.com/BensenHsu/status/1828837369778450447">https://x.com/BensenHsu/status/1828837369778450447</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="translation">Translation<a class="headerlink" href="#translation" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, <a href="../e/#emergent-ability">Emergent Ability</a></p>
<h2 id="transpose-matrix">Transpose Matrix<a class="headerlink" href="#transpose-matrix" title="Permanent link">#</a></h2>
<p>A matrix that represent a reverse linear transformation (?) (no, because would be A^-1 ?)</p>
<iframe src="https://www.youtube.com/embed/g4ecBFmvAYU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">T</a>, ...</p>
<h2 id="traveling-salesman-problem-tsp">Traveling Salesman Problem (TSP)<a class="headerlink" href="#traveling-salesman-problem-tsp" title="Permanent link">#</a></h2>
<p>Requires a <a href="../s/#search-algorithm">search algorithm</a>, ...</p>
<p>The Traveling Salesperson Problem (TSP) is a well-known algorithmic problem in computer science and operations research that deals with finding the shortest and most efficient route for a person to take, given a list of specific destinations. The problem is to find a path that visits each city once, returns to the starting city, and minimizes the distance traveled. It is an NP-hard problem in combinatorial optimization, important in theoretical computer science and operations research. The TSP has real-world applications for logistics and delivery businesses.</p>
<iframe src="https://www.youtube.com/embed/q8nQTNvCrjE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>colab - <a href="https://colab.research.google.com/github/Gurobi/modeling-examples/blob/master/traveling_salesman/tsp_gcl.ipynb">https://colab.research.google.com/github/Gurobi/modeling-examples/blob/master/traveling_salesman/tsp_gcl.ipynb</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../o/#objective-function">Objective Function</a></p>
<h2 id="tree-of-thoughts-tot-prompting">Tree of Thoughts (TOT) Prompting<a class="headerlink" href="#tree-of-thoughts-tot-prompting" title="Permanent link">#</a></h2>
<p>This video explains the 'Tree of Thought' prompting technique, designed to emulate human brainstorming and prove beneficial in problem-solving, particularly in mathematical reasoning.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>1. Carlos is at the swimming pool.
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>2. He walks to the locker room, carrying a towel.
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>5. He leaves the towel at the snack bar, then walks to the diving board.
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>Think through each step logically.
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>Imagine three different experts are answering this question.
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>All experts will write down 1 step of their thinking,
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>then share it with the group.
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>They will each critique their response, and the all the responses of others
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>They will check their answer based on science and the laws of physics
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>Then all experts will go on to the next step and write down this step of their thinking.
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred 
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>If any expert realises they&#39;re wrong at any point then they acknowledges this and start another train of thought
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>Each expert will assign a likelihood of their current assertion being correct
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>Continue until the experts agree on the single most likely location
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>The question is...
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>Here is my attempt at step-by-step reasoning for this question:
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>Expert 1: 
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>Step 1: Carlos walked to the locker room with his towel. The watch was still in/on the towel at this point. 
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>Likelihood: 100%
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>Expert 2:
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>Step 2: Carlos shook out the towel vigorously before walking to the snack bar. The watch likely fell out of the towel at this point, so it&#39;s most likely location is the area around the lounger. 
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>Likelihood: 80% 
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>Expert 3: 
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>Step 3: However, Carlos did not notice the watch fall out at that time. He then left the towel behind at the snack bar, so it&#39;s possible the watch remained entangled in the towel and is now at the snack bar.
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>Likelihood: 70%
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>Expert 1: 
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a>Step 4: But when Carlos shook out the towel, the watch could have landed anywhere in the area around the lounger, not necessarily in the towel. It may have landed on the ground, by the poolside, in the grass, etc. The snack bar is less likely given the details provided.
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>Likelihood: 60%
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>Expert 2:
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>Step 5: After considering the laws of physics, the single most likely location of the watch is on the ground around the pool lounger that Carlos was using, since that is where the towel was most vigorously shaken out. The watch likely fell out at that location. 
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>Likelihood: 90%
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>Expert 3: 
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>Agreed. Based on the sequence of events and the details provided, the area around the pool lounger where Carlos shook out his towel is the single most likely location of the lost watch.
</span></code></pre></div>
<p><img alt="" src="../img/t/tree_of_thoughts_prompting.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/2lnW1PSB2_g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2305.10601" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2305.10601">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper <a href="https://arxiv.org/abs/2305.10601">https://arxiv.org/abs/2305.10601</a></li>
<li>code - <a href="https://github.com/princeton-nlp/tree-of-thought-llm">https://github.com/princeton-nlp/tree-of-thought-llm</a></li>
<li>twitter - <a href="https://twitter.com/ShunyuYao12/status/1659357547474681857">https://twitter.com/ShunyuYao12/status/1659357547474681857</a></li>
</ul>
<p>See also <a href="./">T</a>, <a href="../p/#prompt-engineering">Prompt Engineering</a></p>
<h2 id="tree-parzen-estimators-tpe">Tree Parzen Estimators (TPE)<a class="headerlink" href="#tree-parzen-estimators-tpe" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, <a href="../g/#gaussian-process">Gaussian Process</a>, <a href="../r/#random-forest">Random Forest</a></p>
<h2 id="triplet-loss-function">Triplet Loss Function<a class="headerlink" href="#triplet-loss-function" title="Permanent link">#</a></h2>
<p>Handle 3 things at the same time</p>
<p>See also <a href="./">T</a>, <a href="../c/#contrastive-learning">Contrastive Learning</a></p>
<h2 id="triton-framework">Triton Framework<a class="headerlink" href="#triton-framework" title="Permanent link">#</a></h2>
<p>A low level framework to compile code on any GPU developed by <a href="../o/#openai-company">OpenAI</a>. A major step toward bypassing CUDA and the <a href="../n/#nvidia-company">NVIDIA</a> lock in!</p>
<p>More at :</p>
<ul>
<li>home - <a href="https://openai.com/research/triton">https://openai.com/research/triton</a></li>
<li>code - <a href="https://github.com/openai/triton">https://github.com/openai/triton</a></li>
<li>documentation - <a href="https://triton-lang.org/master/index.html">https://triton-lang.org/master/index.html</a></li>
<li><a href="https://openai.com/blog/triton/">https://openai.com/blog/triton/</a></li>
<li>articles</li>
<li><a href="https://www.semianalysis.com/p/nvidiaopenaitritonpytorch">https://www.semianalysis.com/p/nvidiaopenaitritonpytorch</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="triviaqa-dataset">TriviaQA Dataset<a class="headerlink" href="#triviaqa-dataset" title="Permanent link">#</a></h2>
<p>TriviaQA is a reading comprehension <a href="../d/#dataset">dataset</a> containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions.</p>
<p>More at:</p>
<ul>
<li><a href="https://nlp.cs.washington.edu/triviaqa/">https://nlp.cs.washington.edu/triviaqa/</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="trossen-robotics-company">Trossen Robotics Company<a class="headerlink" href="#trossen-robotics-company" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/g-oNjPtah8g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://www.trossenrobotics.com/">https://www.trossenrobotics.com/</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="trocr-model">TrOCR Model<a class="headerlink" href="#trocr-model" title="Permanent link">#</a></h2>
<p>A Transformer-based Optical Character Recognition with Pre-trained models</p>
<p><img alt="" src="../img/t/trocr_model.jpeg" width="100%" /></p>
<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2109.10282">https://arxiv.org/abs/2109.10282</a></li>
<li>code - <a href="https://github.com/rsommerfeld/trocr">https://github.com/rsommerfeld/trocr</a></li>
</ul>
<p>See also <a href="./">T</a>, [Optical Character Recognition]</p>
<h2 id="true-negative-tn">True Negative (TN)<a class="headerlink" href="#true-negative-tn" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a></p>
<h2 id="true-negative-rate-tnr">True Negative Rate (TNR)<a class="headerlink" href="#true-negative-rate-tnr" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a></p>
<h2 id="true-positive-tp">True Positive (TP)<a class="headerlink" href="#true-positive-tp" title="Permanent link">#</a></h2>
<p>See also <a href="./">T</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a></p>
<h2 id="true-positive-rate-tpr">True Positive Rate (TPR)<a class="headerlink" href="#true-positive-rate-tpr" title="Permanent link">#</a></h2>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>        TP             Positive detected Positives
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>TPR = -------  =  ---------------------------------
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>      TP + FN            Total positive
</span></code></pre></div>
<p><img alt="" src="../img/t/true_positive_rate.png" width="100%" /></p>
<p>See also <a href="./">T</a>, <a href="../c/#confusion-matrix">Confusion Matrix</a></p>
<h2 id="trust-region-policy-optimization-trpo-algorithm">Trust Region Policy Optimization (TRPO) Algorithm<a class="headerlink" href="#trust-region-policy-optimization-trpo-algorithm" title="Permanent link">#</a></h2>
<p>TRPO, which stands for Trust Region Policy Optimization, is an algorithm for policy optimization in [Reinforcement Learning (RL)]. It is designed to iteratively improve a policy to maximize the expected cumulative reward in an RL task.</p>
<p>TRPO belongs to the class of <a href="../o/#on-policy-learning-algorithm">on-policy learning algorithms</a> for optimization and is known for its stability and strong performance in complex RL domains. It aims to address the challenge of policy updates in RL without causing significant deviations from the current policy distribution, which could lead to unstable learning.</p>
<p>The key idea behind TRPO is to ensure that the policy update remains within a trust region, which constrains the magnitude of policy changes. By limiting the deviation from the current policy, TRPO ensures that the learned policy does not diverge too far and maintains a stable learning process.</p>
<p>TRPO utilizes a surrogate objective function that approximates the expected improvement in the policy. It then computes a search direction that maximizes this objective function while staying within the trust region. The policy update is performed by solving a constrained optimization problem to find the optimal policy parameters.</p>
<p>One of the advantages of TRPO is that it offers theoretical guarantees on the monotonic improvement of the policy. However, TRPO can be computationally expensive and may require careful [HyperParameter Tuning (HPT)] to achieve good performance.</p>
<p>TRPO has been widely used in various RL applications and has served as a foundation for subsequent algorithms like <a href="../p/#proximal-policy-optimization-ppo-algorithm">Proximal Policy Optimization (PPO)</a>, which further improves upon TRPO's computational efficiency.</p>
<iframe src="https://www.youtube.com/embed/KjWF8VIMGiY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/1502.05477v5" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1502.05477v5">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1502.05477v5">https://arxiv.org/abs/1502.05477v5</a></li>
<li>code - <a href="https://paperswithcode.com/paper/trust-region-policy-optimization#code">https://paperswithcode.com/paper/trust-region-policy-optimization#code</a></li>
<li><a href="https://paperswithcode.com/method/trpo">https://paperswithcode.com/method/trpo</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="trustworthy-ai">Trustworthy AI<a class="headerlink" href="#trustworthy-ai" title="Permanent link">#</a></h2>
<p>See [Responsible AI]</p>
<h2 id="truth">Truth<a class="headerlink" href="#truth" title="Permanent link">#</a></h2>
<p>Can sometimes be discovered by observation and inductive reasoning, but not always!</p>
<p>See also <a href="./">T</a>, <a href="../i/#inductive-reasoning">Inductive Reasoning</a></p>
<h2 id="truthfulqa-benchmark">TruthfulQA Benchmark<a class="headerlink" href="#truthfulqa-benchmark" title="Permanent link">#</a></h2>
<p>An AI <a href="../b/#benchmark">Benchmark</a> for <a href="../l/#large-language-model-llm">LLM</a></p>
<p>We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.</p>
<p><img alt="" src="../img/t/truthfulqa_benchmark.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/osKWmYzIsG0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/AkLkZgsaKp4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2109.07958" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2109.07958">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2109.07958">https://arxiv.org/abs/2109.07958</a></li>
<li>code - <a href="https://github.com/sylinrl/TruthfulQA">https://github.com/sylinrl/TruthfulQA</a></li>
<li>colab - <a href="https://github.com/sylinrl/TruthfulQA/blob/main/TruthfulQA-demo.ipynb">https://github.com/sylinrl/TruthfulQA/blob/main/TruthfulQA-demo.ipynb</a></li>
<li>questions - <a href="https://github.com/sylinrl/TruthfulQA/blob/main/TruthfulQA.csv">https://github.com/sylinrl/TruthfulQA/blob/main/TruthfulQA.csv</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="tuning-parameter">Tuning Parameter<a class="headerlink" href="#tuning-parameter" title="Permanent link">#</a></h2>
<p>See <a href="../h/#hyperparameter">Hyperparameter</a></p>
<h2 id="turing-machine">Turing Machine<a class="headerlink" href="#turing-machine" title="Permanent link">#</a></h2>
<p>A Turing machine is a machine proposed by the Alan Turing in 1936 that became the foundation for theories about computing and computers. The machine was a device that printed symbols on paper tape in a manner that emulated a person following logical instructions.</p>
<iframe src="https://www.youtube.com/embed/dNRDvLACg5Q" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/DILF8usqp7M" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.computerhope.com/jargon/t/turnmach.htm">https://www.computerhope.com/jargon/t/turnmach.htm</a></li>
<li><a href="https://www.computerhope.com/issues/ch000984.htm">https://www.computerhope.com/issues/ch000984.htm</a></li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="turing-test">Turing Test<a class="headerlink" href="#turing-test" title="Permanent link">#</a></h2>
<p>Conceptualized by <a href="../a/#alan-turing-person">Alan Turing</a> and published in the 1950 paper, Computing Machinery and Intelligence. The test proposed if a computer's output responses were indistinguishable from a human, it could be said to be able to "think."</p>
<p>The "standard interpretation" of the Turing test, in which the interrogator (C) is given the task of trying to determine which player – A or B – is a computer and which is a human. The interrogator is limited to using the responses to written questions to make the determination.</p>
<p>A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer.</p>
<p><img alt="" src="../img/t/turing_test.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://www.computerhope.com/jargon/t/turntest.htm">https://www.computerhope.com/jargon/t/turntest.htm</a></li>
<li><a href="https://en.wikipedia.org/wiki/Turing_test">https://en.wikipedia.org/wiki/Turing_test</a></li>
<li>articles<ul>
<li>does <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT-4</a> pass the turing test? - <a href="https://arxiv.org/abs/2310.20216">https://arxiv.org/abs/2310.20216</a></li>
<li><a href="../c/#chatgpt-model">chatGPT</a> broke turing test - <a href="https://www.nature.com/articles/d41586-023-02361-7">https://www.nature.com/articles/d41586-023-02361-7</a></li>
<li><a href="../e/#eliza-chatbot">Eliza</a> beat <a href="../c/#chatgpt-model">chatgpt</a> - <a href="https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/">https://arstechnica.com/information-technology/2023/12/real-humans-appeared-human-63-of-the-time-in-recent-turing-test-ai-study/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="twin-delayed-deep-deterministic-td3-algorithm">Twin Delayed Deep Deterministic (TD3) Algorithm<a class="headerlink" href="#twin-delayed-deep-deterministic-td3-algorithm" title="Permanent link">#</a></h2>
<ul>
<li>[Model-free learning algorithm]</li>
<li><a href="../o/#off-policy-learning-algorithm">Off-policy learning algorithm</a></li>
<li>continuous action space</li>
<li>continuous state space</li>
<li><a href="../v/#value-based-algorithm">Value-based algorithm</a></li>
</ul>
<p>The TD3 (Twin Delayed Deep Deterministic [Policy Gradient]) algorithm is a <a href="../r/#reinforcement-learning-rl-algorithm">State-Of-The-Art (SOTA)</a> that combines elements of both value-based and policy gradient methods. It is primarily used for continuous <a href="../a/#action-space">action spaces</a>.</p>
<p>TD3 is an extension of the <a href="../d/#deep-deterministic-policy-gradient-ddpg-algorithm">Deep Deterministic Policy Gradient (DDPG)</a> algorithm, which is itself a <a href="../p/#policy-gradient-algorithm">policy gradient algorithm</a> for continuous control problems. The key enhancements in TD3 address issues such as overestimation of <a href="../q/#q-value">Q-values</a> and instability in training.</p>
<p>Here are the main features and components of the TD3 algorithm:
  1. Twin Networks: TD3 employs two sets of <a href="../d/#deep-q-network-dqn">deep Q-networks</a>, known as twin networks. Having two separate networks reduces the overestimation bias commonly encountered in [value-based methods].
  1. Delayed Updates: TD3 introduces delayed updates for the target networks. Instead of updating the target networks at every time step, the updates are performed less frequently. This helps stabilize the learning process and mitigates the issues related to correlated samples.
  1. Target Policy Smoothing: To further improve stability, TD3 applies target policy smoothing. It adds noise to the target actions during the learning process, encouraging the <a href="../a/#agent">agent</a> to explore different <a href="../a/#action">actions</a> and reducing the sensitivity to small policy updates.
  1. Replay Buffer: TD3 utilizes an <a href="../e/#experience-replay">experience replay</a> buffer, which stores past experiences (<a href="../s/#state">state</a>, <a href="../a/#action">action</a>, <a href="../r/#reward">reward</a>, next state) for training. The replay buffer helps to decorrelate samples and provides a diverse set of experiences for learning.
  1. <a href="../a/#actor-critic-architecture">Actor-Critic Architecture</a>: TD3 combines an <a href="../a/#actor-network">actor network</a>, which generates actions based on the current state, and a <a href="../c/#critic-network">critic network</a>, which estimates the <a href="../q/#q-value">Q-value</a> for state-action pairs. Both networks are typically implemented using deep neural networks.</p>
<p>Through iterations of interacting with the environment, collecting experiences, and updating the network parameters using [gradient descent], TD3 aims to learn an <a href="../o/#optimal-policy">optimal policy</a> that maximizes the cumulative reward. It leverages the policy gradient approach to update the <a href="../a/#actor-network">actor network</a> and the value-based approach to update the [critic networks].</p>
<p>TD3 has shown impressive performance in various challenging continuous control tasks, providing a balance between <a href="../e/#exploration">exploration</a> and <a href="../e/#exploitation">exploitation</a> and achieving [state-of-the-art] results in terms of <a href="../s/#sample-efficiency">sample efficiency</a> and stability.</p>
<p>See also <a href="./">T</a>, ...</p>
<h2 id="two-tower-embeddings-tte">Two-Tower Embeddings (TTE)<a class="headerlink" href="#two-tower-embeddings-tte" title="Permanent link">#</a></h2>
<p>Two-tower embeddings are the <a href="../e/#embedding">embeddings</a> generated by a special deep learning architecture named two towers. TTE model architecture usually consists of a query tower and an item tower: query tower encodes search query and user profile to query embeddings, and item tower encodes store, grocery item, geo location to item embeddings.</p>
<object data="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://www.uber.com/blog/innovative-recommendation-applications-using-two-tower-embeddings/">https://www.uber.com/blog/innovative-recommendation-applications-using-two-tower-embeddings/</a></li>
</ul>
<h2 id="two-tower-model">Two-Tower Model<a class="headerlink" href="#two-tower-model" title="Permanent link">#</a></h2>
<p>~ architecture for <a href="../r/#recommendation-engine">recommendation engines</a> that need to compute recommendations in real time without introducing large latencies.</p>
<p>The Two-Tower model is widely used in the recommendation system retrieval stage. The idea is quite simple for this model architecture; it consists of two fully separated towers, one for the user and one for the item, as shown in the figure below. Through [deep neural networks], the model is able to learn high-level abstract representations for both a user and an item with past user-item interactions. The output is the <a href="../s/#similarity-metric">similarity</a> between user <a href="../e/#embedding">embedding</a> and item <a href="../e/#embedding">embedding</a>, which represents how interested the user is in the given item.</p>
<p>To further accelerate online serving, user <a href="../e/#embedding">embeddings</a> and item <a href="../e/#embedding">embeddings</a> can be precomputed and stored offline. Thus, we only need to compute the <a href="../s/#similarity-metric">similarity</a> between user and item embeddings during online serving.</p>
<p><img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> This model is similar to a RAG platform where you try to match a question to sections of documents.</p>
<p><img alt="" src="../img/t/two_tower_model.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>articles<ul>
<li><a href="https://hackernoon.com/understanding-the-two-tower-model-in-personalized-recommendation-systems">https://hackernoon.com/understanding-the-two-tower-model-in-personalized-recommendation-systems</a></li>
<li><a href="https://medium.com/tech-p7s1/video-recommendations-at-joyn-two-tower-or-not-to-tower-that-was-never-a-question-6c6f182ade7c">https://medium.com/tech-p7s1/video-recommendations-at-joyn-two-tower-or-not-to-tower-that-was-never-a-question-6c6f182ade7c</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">T</a>, <a href="../d/#dot-product-similarity">Dot Product Similarity</a></p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../s/" class="md-footer__link md-footer__link--prev" aria-label="Previous: S">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                S
              </div>
            </div>
          </a>
        
        
          
          <a href="../u/" class="md-footer__link md-footer__link--next" aria-label="Next: U">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                U
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>