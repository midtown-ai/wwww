
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/b/">
      
      
        <link rel="prev" href="../a/">
      
      
        <link rel="next" href="../c/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>B - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="B - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/b.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/b/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="B - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/b.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#b" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              B
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    B
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#b-spline" class="md-nav__link">
    <span class="md-ellipsis">
      B-Spline
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baby-x-digital-human" class="md-nav__link">
    <span class="md-ellipsis">
      Baby-X Digital Human
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#babyagi-model" class="md-nav__link">
    <span class="md-ellipsis">
      BabyAGI Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Through Time
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backtesting" class="md-nav__link">
    <span class="md-ellipsis">
      Backtesting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bag-of-words-bow" class="md-nav__link">
    <span class="md-ellipsis">
      Bag Of Words (BOW)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bagging" class="md-nav__link">
    <span class="md-ellipsis">
      Bagging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baidu-company" class="md-nav__link">
    <span class="md-ellipsis">
      Baidu Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#balanced-fitting" class="md-nav__link">
    <span class="md-ellipsis">
      Balanced Fitting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bard-model" class="md-nav__link">
    <span class="md-ellipsis">
      Bard Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch" class="md-nav__link">
    <span class="md-ellipsis">
      Batch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-gradient-descent-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Gradient Descent Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-normalization-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-of-experience" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Of Experience
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-training" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-theorem" class="md-nav__link">
    <span class="md-ellipsis">
      Bayes' Theorem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Inference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-inference_1" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Inference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-network" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-optimization-sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Optimization Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-search" class="md-nav__link">
    <span class="md-ellipsis">
      Bayes Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beam-search" class="md-nav__link">
    <span class="md-ellipsis">
      Beam Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavioural-cloning" class="md-nav__link">
    <span class="md-ellipsis">
      Behavioural Cloning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#belief-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Belief Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#belief-desire-intention-bdi-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Belief-Desire-Intention (BDI) Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bellman-equation" class="md-nav__link">
    <span class="md-ellipsis">
      Bellman Equation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#berkeley-university" class="md-nav__link">
    <span class="md-ellipsis">
      Berkeley University
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bernoulli-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Bernoulli Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bert-classification" class="md-nav__link">
    <span class="md-ellipsis">
      BERT Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beta-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Beta Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-match-25-bm25-retrieval-model" class="md-nav__link">
    <span class="md-ellipsis">
      Best Match 25 (BM25) Retrieval Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bhuman-company" class="md-nav__link">
    <span class="md-ellipsis">
      BHuman Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beyond-the-imitation-game-benchmark-big-bench" class="md-nav__link">
    <span class="md-ellipsis">
      Beyond the Imitation Game Benchmark (BIG Bench)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias" class="md-nav__link">
    <span class="md-ellipsis">
      Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-benchmark-for-question-answering-bbq" class="md-nav__link">
    <span class="md-ellipsis">
      Bias Benchmark For Question Answering (BBQ)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-neuron" class="md-nav__link">
    <span class="md-ellipsis">
      Bias Neuron
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-variance-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Bias-Variance Trade-off
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bidirectional-encoder-representation-from-transformer-bert-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional Encoder Representation from Transformer (BERT) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bidirectional-rnn-brnn" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional RNN (BRNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#big-data" class="md-nav__link">
    <span class="md-ellipsis">
      Big Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bigram" class="md-nav__link">
    <span class="md-ellipsis">
      Bigram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bilingual-evaluation-understudy-bleu-score" class="md-nav__link">
    <span class="md-ellipsis">
      Bilingual Evaluation Understudy (BLEU) Score
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bill-gates-person" class="md-nav__link">
    <span class="md-ellipsis">
      Bill Gates Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bin" class="md-nav__link">
    <span class="md-ellipsis">
      Bin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binary-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binary-cross-entropy-bce-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Cross-Entropy (BCE) Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bing-search-engine" class="md-nav__link">
    <span class="md-ellipsis">
      Bing Search Engine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binomial-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Binomial Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#biological-neuron" class="md-nav__link">
    <span class="md-ellipsis">
      Biological Neuron
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#blip-model" class="md-nav__link">
    <span class="md-ellipsis">
      BLIP Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#black-box-model" class="md-nav__link">
    <span class="md-ellipsis">
      Black Box Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#block-sparse-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Block-Sparse Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bloomberggpt-model" class="md-nav__link">
    <span class="md-ellipsis">
      BloombergGPT Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boltzmann-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Boltzmann Machine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting" class="md-nav__link">
    <span class="md-ellipsis">
      Boosting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting-step-size" class="md-nav__link">
    <span class="md-ellipsis">
      Boosting Step Size
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bootstrap-sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Bootstrap Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boston-dynamics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Boston Dynamics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bounding-box" class="md-nav__link">
    <span class="md-ellipsis">
      Bounding Box
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#box-cox-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      Box Cox Transformation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#brain" class="md-nav__link">
    <span class="md-ellipsis">
      Brain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#brain-computer-interface-bci" class="md-nav__link">
    <span class="md-ellipsis">
      Brain Computer Interface (BCI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bucket" class="md-nav__link">
    <span class="md-ellipsis">
      Bucket
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bucketing" class="md-nav__link">
    <span class="md-ellipsis">
      Bucketing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#buffered-online-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Buffered Online Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#byte-pair-encoding-bpe-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Byte-Pair Encoding (BPE) Tokenization
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../g/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../l/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../v/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#b-spline" class="md-nav__link">
    <span class="md-ellipsis">
      B-Spline
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baby-x-digital-human" class="md-nav__link">
    <span class="md-ellipsis">
      Baby-X Digital Human
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#babyagi-model" class="md-nav__link">
    <span class="md-ellipsis">
      BabyAGI Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Through Time
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backtesting" class="md-nav__link">
    <span class="md-ellipsis">
      Backtesting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bag-of-words-bow" class="md-nav__link">
    <span class="md-ellipsis">
      Bag Of Words (BOW)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bagging" class="md-nav__link">
    <span class="md-ellipsis">
      Bagging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baidu-company" class="md-nav__link">
    <span class="md-ellipsis">
      Baidu Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#balanced-fitting" class="md-nav__link">
    <span class="md-ellipsis">
      Balanced Fitting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bard-model" class="md-nav__link">
    <span class="md-ellipsis">
      Bard Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch" class="md-nav__link">
    <span class="md-ellipsis">
      Batch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-gradient-descent-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Gradient Descent Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-normalization-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-of-experience" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Of Experience
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-training" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-theorem" class="md-nav__link">
    <span class="md-ellipsis">
      Bayes' Theorem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Inference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-inference_1" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Inference
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-network" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayesian-optimization-sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Bayesian Optimization Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bayes-search" class="md-nav__link">
    <span class="md-ellipsis">
      Bayes Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beam-search" class="md-nav__link">
    <span class="md-ellipsis">
      Beam Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavioural-cloning" class="md-nav__link">
    <span class="md-ellipsis">
      Behavioural Cloning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#belief-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Belief Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#belief-desire-intention-bdi-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Belief-Desire-Intention (BDI) Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bellman-equation" class="md-nav__link">
    <span class="md-ellipsis">
      Bellman Equation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#berkeley-university" class="md-nav__link">
    <span class="md-ellipsis">
      Berkeley University
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bernoulli-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Bernoulli Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bert-classification" class="md-nav__link">
    <span class="md-ellipsis">
      BERT Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beta-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Beta Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-match-25-bm25-retrieval-model" class="md-nav__link">
    <span class="md-ellipsis">
      Best Match 25 (BM25) Retrieval Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bhuman-company" class="md-nav__link">
    <span class="md-ellipsis">
      BHuman Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#beyond-the-imitation-game-benchmark-big-bench" class="md-nav__link">
    <span class="md-ellipsis">
      Beyond the Imitation Game Benchmark (BIG Bench)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias" class="md-nav__link">
    <span class="md-ellipsis">
      Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-benchmark-for-question-answering-bbq" class="md-nav__link">
    <span class="md-ellipsis">
      Bias Benchmark For Question Answering (BBQ)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-neuron" class="md-nav__link">
    <span class="md-ellipsis">
      Bias Neuron
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-variance-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Bias-Variance Trade-off
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bidirectional-encoder-representation-from-transformer-bert-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional Encoder Representation from Transformer (BERT) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bidirectional-rnn-brnn" class="md-nav__link">
    <span class="md-ellipsis">
      Bidirectional RNN (BRNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#big-data" class="md-nav__link">
    <span class="md-ellipsis">
      Big Data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bigram" class="md-nav__link">
    <span class="md-ellipsis">
      Bigram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bilingual-evaluation-understudy-bleu-score" class="md-nav__link">
    <span class="md-ellipsis">
      Bilingual Evaluation Understudy (BLEU) Score
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bill-gates-person" class="md-nav__link">
    <span class="md-ellipsis">
      Bill Gates Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bin" class="md-nav__link">
    <span class="md-ellipsis">
      Bin
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binary-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binary-cross-entropy-bce-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Cross-Entropy (BCE) Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bing-search-engine" class="md-nav__link">
    <span class="md-ellipsis">
      Bing Search Engine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#binomial-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Binomial Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#biological-neuron" class="md-nav__link">
    <span class="md-ellipsis">
      Biological Neuron
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#blip-model" class="md-nav__link">
    <span class="md-ellipsis">
      BLIP Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#black-box-model" class="md-nav__link">
    <span class="md-ellipsis">
      Black Box Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#block-sparse-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Block-Sparse Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bloomberggpt-model" class="md-nav__link">
    <span class="md-ellipsis">
      BloombergGPT Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boltzmann-machine" class="md-nav__link">
    <span class="md-ellipsis">
      Boltzmann Machine
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting" class="md-nav__link">
    <span class="md-ellipsis">
      Boosting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting-step-size" class="md-nav__link">
    <span class="md-ellipsis">
      Boosting Step Size
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bootstrap-sampling-method" class="md-nav__link">
    <span class="md-ellipsis">
      Bootstrap Sampling Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boston-dynamics-company" class="md-nav__link">
    <span class="md-ellipsis">
      Boston Dynamics Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bounding-box" class="md-nav__link">
    <span class="md-ellipsis">
      Bounding Box
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#box-cox-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      Box Cox Transformation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#brain" class="md-nav__link">
    <span class="md-ellipsis">
      Brain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#brain-computer-interface-bci" class="md-nav__link">
    <span class="md-ellipsis">
      Brain Computer Interface (BCI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bucket" class="md-nav__link">
    <span class="md-ellipsis">
      Bucket
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bucketing" class="md-nav__link">
    <span class="md-ellipsis">
      Bucketing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#buffered-online-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Buffered Online Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#byte-pair-encoding-bpe-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Byte-Pair Encoding (BPE) Tokenization
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="b">B<a class="headerlink" href="#b" title="Permanent link">#</a></h1>
<h2 id="b-spline">B-Spline<a class="headerlink" href="#b-spline" title="Permanent link">#</a></h2>
<p>Formally, b-splines [3] are a sophisticated curve-fitting method and a specific type of spline [4] - a mathematical term for a flexible, piecewise-polynomial function that defines a smooth curve through a series of points. Informally, imagine youve plotted dots on a graph to represent how your spending has fluctuated over the past 10 months, and now you want a smooth line that best shows trends over those months. To do so we could use a polynomial fit, so lets see how that might look.</p>
<p><img alt="" src="../img/b/b_spline_polynomial.png" width="100%" /></p>
<p>It works! We have a smooth line that shows my wild spending habits over the last 10 months. But if we look closer, specifically after the first data point, why does the line drop so drastically instead of just curving upwards towards the second data point? This issue with polynomial fitting is due to their tendency to exhibit wild oscillations, a problem known as [Runges phenomenon].</p>
<p>How can we fit this line betterlets try splines! A spline divides the data into segments and fits individual polynomials to each. Lets see what a spline fit looks like.</p>
<p><img alt="" src="../img/b/b_spline_spline.png" width="100%" /></p>
<p>This fit is much smoother, but perhaps its a bit too gentle and underfits the data. This is where B-splines can step in to fix things. B-splines, a type of spline that uses control points to pull the curve and guide the polynomials to fit better, offer a more precise solution. Lets take a look at a B-spline fit on the data.</p>
<p><img alt="" src="../img/b/b_spline.png" width="100%" /></p>
<p>Perfect! The B-spline doesnt oscillate wildly or underfit; instead, it captures the data perfectly. B-splines provide superior smoothness and crucial accuracy for modeling complex functions. They can adapt easily to changes in data patterns without requiring a complete overhaul of the model, making them a versatile and robust tool for data fitting.</p>
<p>Mathematically, we can define a b-spline as:
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>...
</span></code></pre></div></p>
<p>More at:</p>
<ul>
<li><a href="https://daniel-bethell.co.uk/posts/kan/">https://daniel-bethell.co.uk/posts/kan/</a></li>
</ul>
<p>See also <a href="./">B</a>, [Kolmogorov-Arnold Network]</p>
<h2 id="baby-x-digital-human">Baby-X Digital Human<a class="headerlink" href="#baby-x-digital-human" title="Permanent link">#</a></h2>
<p>~ a digital human developed by [Soul Machines]</p>
<p>Baby-X is based on and informed by significant research in key fields that have been integrated into a cohesive research and development effort. These include:</p>
<ul>
<li>Advanced CGI</li>
<li>Biologically Inspired Cognitive Architectures</li>
<li>Neuroscience</li>
<li>Cognitive Science</li>
<li>Developmental Psychology</li>
<li>Cognitive Linguistics</li>
<li>Affective Computing</li>
</ul>
<p>Together they enable Baby-X to manifest and apply various models of the brain to enable scaled interactions and responses, creating a bridge to the human world.</p>
<p><img alt="" src="../img/b/baby_x_digital_brain.webp" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/PHQhCiVLRpE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/yzFW4-dvFDA" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://www.soulmachines.com/resources/research/baby-x/">https://www.soulmachines.com/resources/research/baby-x/</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="babyagi-model">BabyAGI Model<a class="headerlink" href="#babyagi-model" title="Permanent link">#</a></h2>
<p>A task-driven autonomous agent</p>
<p>In this research, we propose a novel task-driven autonomous agent that leverages OpenAIs GPT-4 language model, [Pinecone vector search], and <a href="../l/#langchain-python-module">LangChain</a> to perform a wide range of tasks across diverse domains. Our system is capable of completing tasks, generating new tasks based on completed results, and prioritizing tasks in real-time. We discuss potential future improvements, including the integration of a security/safety agent, expanding functionality, generating interim milestones, and incorporating real-time priority updates. The significance of this research lies in demonstrating the potential of AI-powered language models to autonomously perform tasks within various constraints and contexts.</p>
<p><img alt="" src="../img/b/babyagi_model.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>code - <a href="https://github.com/yoheinakajima/babyagi">https://github.com/yoheinakajima/babyagi</a></li>
<li>docs - <a href="https://babyagi.org/">https://babyagi.org/</a></li>
<li>paper - <a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/">https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/</a></li>
<li>tweet - <a href="https://twitter.com/yoheinakajima/status/1640934493489070080">https://twitter.com/yoheinakajima/status/1640934493489070080</a></li>
<li>langchain - <a href="https://python.langchain.com/en/latest/use_cases/autonomous_agents.html">https://python.langchain.com/en/latest/use_cases/autonomous_agents.html</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="backpropagation">Backpropagation<a class="headerlink" href="#backpropagation" title="Permanent link">#</a></h2>
<p>~ The way for machine to learn from their mistakes! (or to get better!)</p>
<p>= imagine you are given all the ingredients to prepare an apple pie, but you are not given the recipe. You goal is to try to bake one. So, you try and fail! Then you adjust the recipe and try again! Until you get an apple pie. Then you try again to improve it.... you try and try again, until it cannot be improved with the ingredient you were given anymore. The final recipe is the model. The ingredients are the input features. The learning process is backpropagation (look at the results and update upstream operations as a result!)</p>
<p>= a brute force approach, where you pick random weight and you iterate on them until they arrive at a stable solution. This is a <code>widely used algorithm for training feedforward neural networks and other ANN</code>. Approach discovered in 1986 that re-stimulated AI. Help a model learn from its mistakes by leveraging the chain rule of derivatives. The backpropagation algorithm consists in modifying the weight and bias of each cell in each layer based on their impact on the estimated output, or loss function (diff between estimated output and real output).</p>
<iframe src="https://www.youtube.com/embed/Ilg3gGewQ5U" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/tIeHLnjs5U8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>Backpropagation can find the</p>
<ol>
<li>weights + biases (?)</li>
<li>[image kernel] filters in a <a href="../c/#convolutional-neural-network-cnn">CNN</a>
 Beware:</li>
<li>If you only use 2 in training sample, you may have a model where all images are recognized as 2, which is not correct. ==&gt; the weights need to be computed with all the samples (i,e, an epoch or a mini-batch)!</li>
<li>If your ANN is multi-layered, deep, and use activation functions, backpropagation may not be able to compute all the weights, an issue that is known as the vanishing gradient problem.</li>
<li>In a variational autoencoder, you cannot run backpropagation because of the sampling between the encoder and decoder. The solution here is to us the "VAE reparametrization trick"</li>
</ol>
<p>See also <a href="./">B</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../d/#derivative-chain-rule">Derivative Chain Rule</a>, <a href="../f/#feedforward-neural-network">Feedforward Neural Network</a>, <a href="../l/#loss-function">Loss Function</a>, <a href="../n/#neural-network">Neural Network</a>, <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a>, [Variational Autoencoder Reparametrization Trick]</p>
<h2 id="backpropagation-through-time">Backpropagation Through Time<a class="headerlink" href="#backpropagation-through-time" title="Permanent link">#</a></h2>
<p><a href="./#backpropagation">Backpropagation</a> is also used with <a href="../r/#recurrent-neural-network-rnn">Recurrent Neural Netowkr (RNN)</a></p>
<iframe src="https://www.youtube.com/embed/0XdPIqi0qpg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, ...</p>
<h2 id="backtesting">Backtesting<a class="headerlink" href="#backtesting" title="Permanent link">#</a></h2>
<p>~ <a href="../c/#cross-validation-sampling-method">cross-validation</a> on historical data</p>
<p>Try a strategy on a past period to see what would have been the output of my model. For example, to be used in finance applications.</p>
<iframe src="https://www.youtube.com/embed/V2qAHYmDqpY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, ...</p>
<h2 id="bag-of-words-bow">Bag Of Words (BOW)<a class="headerlink" href="#bag-of-words-bow" title="Permanent link">#</a></h2>
<p>The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.</p>
<p>A technique for <a href="../n/#natural-language-processing-nlp">natural language processing</a> that extracts the words (features) used in a sentence, document, website, etc. and classifies them by frequency of use. This technique can also be applied to <a href="../i/#image-processing">image processing</a>. In NLP deprecated was by <a href="../r/#recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</a>, which take into consideration the word order.</p>
<p>More at:</p>
<ul>
<li>spam detector - <a href="https://medium.com/coinmonks/spam-detector-using-naive-bayes-c22cc740e257">https://medium.com/coinmonks/spam-detector-using-naive-bayes-c22cc740e257</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../n/#naive-bayes-classifier">Naive Bayes Classifier</a>, <a href="../w/#word2vec-model">Word2Vec</a></p>
<h2 id="bagging">Bagging<a class="headerlink" href="#bagging" title="Permanent link">#</a></h2>
<p>~ <a href="./#bootstrap-sampling-method">Bootstrap sampling</a> + aggregation</p>
<p>~ Bagging is a way to create <a href="../w/#weak-learner">weak learners</a>. If weak learners are classifiers, the <a href="../s/#strong-learner">strong learner</a> is built with voting. If regressors, then averaging.</p>
<p>Bagging, also known as Bootstrap Aggregating. Build random sets by drawing random points from the dataset (with replacement). Train a different model on each of the sets. These models are the <a href="../w/#weak-learner">weak learners</a>. The <a href="../s/#strong-learner">strong learner</a> is then formed as a combination of the weak models, and the <a href="../p/#prediction">prediction</a> is done by voting (if it is a classification model) or averaging the predictions (if it is a regression model). It is used to improve <a href="../a/#accuracy">accuracy</a> and make the model more generalize by reducing the <a href="../v/#variance">variance</a>, i.e., avoiding <a href="../o/#overfitting">overfitting</a>. In this, we take multiple subsets of the training dataset. For each subset, we take a model with the same learning algorithms like <a href="../d/#decision-tree">Decision tree</a>, [Logistic regression], etc., to predict the output for the same set of test data. Once we predict each model, we use a model averaging technique to get the final prediction output. One of the famous techniques used in Bagging is <a href="../r/#random-forest">Random Forest</a>. In the <a href="../r/#random-forest">Random forest</a>, we use multiple <a href="../d/#decision-tree">decision trees</a>.</p>
<iframe src="https://www.youtube.com/embed/RtrBtAKwcxQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, <a href="./#boosting">Boosting</a>, <a href="../e/#ensemble-method">Ensemble Method</a></p>
<h2 id="baidu-company">Baidu Company<a class="headerlink" href="#baidu-company" title="Permanent link">#</a></h2>
<p>Baidu, Inc. (meaning "hundred times") is a Chinese multinational technology company specializing in Internet-related services, products, and artificial intelligence (AI), headquartered in Beijing's Haidian District. It is one of the largest AI and Internet companies in the world. </p>
<p>Models:
  * <a href="../e/#ernie-bot">Ernie Bot</a></p>
<p>See also <a href="./">B</a>, <a href="../c/#company">Company</a></p>
<h2 id="balanced-fitting">Balanced Fitting<a class="headerlink" href="#balanced-fitting" title="Permanent link">#</a></h2>
<p>Good generalization for other data.</p>
<p><img alt="" src="../img/b/balanced_fitting_comparison.png" width="100%" /></p>
<p>See also <a href="./">B</a>, <a href="./#bias">Bias</a>, <a href="../o/#overfitting">Overfitting</a>, <a href="../u/#underfitting">Underfitting</a>, <a href="../v/#variance">Variance</a></p>
<h2 id="bard-model">Bard Model<a class="headerlink" href="#bard-model" title="Permanent link">#</a></h2>
<p>A lightweight version of [Lambda Model], meant to counter MSFT Bing + <a href="../c/#chatgpt-model">ChatGPT</a></p>
<iframe src="https://www.youtube.com/embed/5X1O5AS4nTc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://bard.google.com/">https://bard.google.com/</a></li>
<li>Gotcha! - <a href="https://www.reuters.com/technology/google-unveils-magic-wand-draft-documents-ai-race-tightens-2023-03-14/">https://www.reuters.com/technology/google-unveils-magic-wand-draft-documents-ai-race-tightens-2023-03-14/</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="batch">Batch<a class="headerlink" href="#batch" title="Permanent link">#</a></h2>
<p>A batch represents all the samples in a dataset. When the training dataset is large, it needs to be broken into chunks called <a href="../m/#mini-batch">mini-batches</a>.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a> ![](img/b/epoch_batch_iteration.png ){: width=&quot;100%&quot;}
</span></code></pre></div>
<p>See also <a href="./">B</a>, <a href="./#batch-size">Batch Size</a>, <a href="../e/#epoch">Epoch</a>, <a href="../i/#iteration">Iteration</a></p>
<h2 id="batch-gradient-descent-algorithm">Batch Gradient Descent Algorithm<a class="headerlink" href="#batch-gradient-descent-algorithm" title="Permanent link">#</a></h2>
<p>~ Use all the training samples for one forward pass and then adjust weights ==&gt; good for small training set. If too much computation --&gt; <a href="../s/#stochastic-gradient-descent-sgd-algorithm">SGD</a> or <a href="../m/#mini-batch-gradient-descent-algorithm">Mini-Batch gradient Descent</a></p>
<p>~ standard gradient descent. In Batch Gradient Descent, all the training data is taken into consideration to take a single step. We take the average of the gradients of all the training examples and then use that mean gradient to update our parameters. So thats just one step of gradient descent in one epoch. Batch Gradient Descent is great for convex or relatively smooth error manifolds. In this case, we move somewhat directly towards an optimum solution.</p>
<p><img alt="" src="../img/b/batch_gradient_descent.png" width="20%" /></p>
<p><img alt="" src="../img/b/batch_gradient_descent_comparison.png" width="20%" /></p>
<p>See also <a href="./">B</a>, [Gradient Descent Algorithm], <a href="../m/#mini-batch-gradient-descent-algorithm">Mini-Batch Gradient Descent Algorithm</a></p>
<h2 id="batch-normalization">Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permanent link">#</a></h2>
<p>~ collapse inputs to be between 0 and 1</p>
<ol>
<li>Speeds up training (use same learning rate for all features/dimensions)</li>
<li>Decrease the importance of weight initialization (allows sub-optimal starts)</li>
<li>Acts (a little) as a regularizer (the mean and variance for every neuron activations is function of the randomized batch)<ul>
<li>Dropout layer ==&gt; randomness, batch normalization ==&gt; some randomness</li>
</ul>
</li>
</ol>
<p>Batch normalization layers can potentially resolve the vanishing gradient problem. Indeed, this problem arises when a large input space is mapped to a small one, causing the derivatives to disappear. In Image 1, this is most clearly seen at when <code>|x|</code> is big. Batch normalization reduces this problem by simply normalizing the input so <code>|x|</code> doesnt reach the outer edges of the sigmoid function. As seen in diagram, it normalizes the input so that most of it falls in the green region, where the derivative isnt too small.</p>
<p><img alt="" src="../img/b/batch_normalization.png" width="30%" /></p>
<iframe src="https://www.youtube.com/embed/DtEq44FTPM4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/1502.03167" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1502.03167">Download PDF</a>.
    </p>
</object>

<object data="https://arxiv.org/pdf/1805.11604" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1805.11604">Download PDF</a>.
    </p>
</object>

<object data="https://arxiv.org/pdf/1905.05928" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1905.05928">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/Batch_normalization">https://en.wikipedia.org/wiki/Batch_normalization</a></li>
<li>covariance shift (2015)<ul>
<li>paper - <a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a></li>
</ul>
</li>
<li>help optimization? (2018) <ul>
<li>paper - <a href="https://arxiv.org/abs/1805.11604">https://arxiv.org/abs/1805.11604</a></li>
</ul>
</li>
<li>BN and dropout layer <ul>
<li>paper - <a href="https://arxiv.org/abs/1905.05928">https://arxiv.org/abs/1905.05928</a></li>
</ul>
</li>
<li>articles<ul>
<li>[<a href="https://medium.com/analytics-vidhya/internal-covariate-shift-an-overview-of-how-to-speed-up-neural-network-training-3e2a3dcdd5cc(https://medium.com/analytics-vidhya/internal-covariate-shift-an-overview-of-how-to-speed-up-neural-network-training-3e2a3dcdd5cc">https://medium.com/analytics-vidhya/internal-covariate-shift-an-overview-of-how-to-speed-up-neural-network-training-3e2a3dcdd5cc(https://medium.com/analytics-vidhya/internal-covariate-shift-an-overview-of-how-to-speed-up-neural-network-training-3e2a3dcdd5cc</a>)</li>
</ul>
</li>
</ul>
<p>See also <a href="./">B</a>, <a href="../d/#dropout-layer">Dropout layer</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, <a href="../s/#sigmoid-activation-function">Sigmoid Activation Function</a>, <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="batch-normalization-layer">Batch Normalization Layer<a class="headerlink" href="#batch-normalization-layer" title="Permanent link">#</a></h2>
<p>~ A layer where the normalization function takes effect.</p>
<p>This layer is normally before the <a href="../a/#activation-layer">activation layer</a></p>
<p>Although normalization requires more calculation per epoch, to achieve the same performance, you will need fewer epochs!</p>
<iframe src="https://www.youtube.com/embed/yXOMHOpbon8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, ...</p>
<h2 id="batch-of-experience">Batch Of Experience<a class="headerlink" href="#batch-of-experience" title="Permanent link">#</a></h2>
<p>A set of experience, mostly likely sampled randomly from the replay memory.</p>
<p>See also <a href="./">B</a>, <a href="../d/#deep-q-network-dqn">Deep Q-Network</a>, <a href="../e/#experience">Experience</a>, <a href="../r/#replay-memory">Replay Memory</a> </p>
<h2 id="batch-size">Batch Size<a class="headerlink" href="#batch-size" title="Permanent link">#</a></h2>
<p>The number of samples (rows) in a batch. Configured to optimize the utilization of the <a href="../g/#graphical-processing-unit-gpu">GPU</a></p>
<p>The larger the batch size, the faster the training is.
 If the batch is too large, the model degrades does not generatlize well.
 ==&gt; maximize the resource/GPU utilization</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a># of batches  *  batch size  =  1 epoch
</span></code></pre></div>
<iframe src="https://www.youtube.com/embed/U4WB9p6ODjM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/how-to-increase-training-performance-through-memory-optimization-1000d30351c8">https://towardsdatascience.com/how-to-increase-training-performance-through-memory-optimization-1000d30351c8</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="./#batch">Batch</a></p>
<h2 id="batch-training">Batch Training<a class="headerlink" href="#batch-training" title="Permanent link">#</a></h2>
<p>The parameters of a machine learning model are usually updated multiple times during each <a href="../e/#epoch">epoch</a>. In most cases, the training data is divided into batches, and the model is updated after processing each <a href="./#batch">batch</a> of data. This is known as batch training or mini-batch training.</p>
<p>For example, suppose we have a dataset with 1000 examples, and we choose a batch size of 100. During each epoch, the model will process 10 batches, with each batch consisting of 100 examples. After processing each batch, the model will update its parameters based on the error it made on that batch, using an optimization algorithm such as <a href="../s/#stochastic-gradient-descent-sgd-algorithm">stochastic gradient descent (SGD)</a> or <a href="../a/#adaptive-moment-adam-estimation-algorithm">Adaptive Moment Estimation (Adam)</a>.</p>
<p>Batch training has several advantages over updating the model after processing the entire <a href="../d/#dataset">dataset</a> (known as batch training or full-batch training), including faster convergence, better memory efficiency, and the ability to handle large datasets that may not fit into memory. However, it also introduces some additional noise in the parameter updates due to the smaller sample size, which can be mitigated by adjusting the learning rate and other <a href="../h/#hyperparameter">hyperparameters</a>.</p>
<h2 id="bayes-theorem">Bayes' Theorem<a class="headerlink" href="#bayes-theorem" title="Permanent link">#</a></h2>
<p>Bayes' theorem is used to find the reverse probabilities <code>p(A|B)</code> if we know the conditional probability of an event, i.e p(A) and p(B), and <code>p(B|A)</code></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a># Probability of having feature A and B
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a># is equal to
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a># Probability of having B knowing A
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a># multiplied by
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a># probability of feature A
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>p(A,B) = p(B|A) * p(A)
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>         = p(A|B) * p(B)
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a># therefore
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>           p(B|A) * p(A)
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>p(A|B) = ----------------
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>               p(B)
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>Where P(A) and P(B) are the probabilities of events A and B.
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>P(A|B) is the probability of event A given B
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>P(B|A) is the probability of event B given A.
</span></code></pre></div>
<p>See also <a href="./">B</a>, <a href="./#bayesian-inference">Bayesian Inference</a>, [Naive Bayes]</p>
<h2 id="bayesian-inference">Bayesian Inference<a class="headerlink" href="#bayesian-inference" title="Permanent link">#</a></h2>
<p>Used by <a href="../r/#reinforcement-learning-rl-agent">RL agent</a> in stochastic <a href="../e/#environment">environments</a></p>
<p>Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Some key points about Bayesian inference:</p>
<ul>
<li>It is based on Bayes' theorem, which describes the probability of an event based on prior knowledge of conditions that might be related to the event.
It allows you to combine prior beliefs with observed data to get posterior beliefs. The prior beliefs are your initial probabilities for a hypothesis before seeing any evidence.</li>
<li>As new evidence is gathered, the prior probability is updated to become the posterior probability. This allows you to adjust your beliefs about a hypothesis as you gather more information.</li>
<li>It involves computing the posterior probability distribution - the probability of a hypothesis given the observed data.
Bayesian inference uses Bayes' rule to compute and update probabilities after obtaining new data. This allows you to update your beliefs sequentially as you gather more information.</li>
<li>A major advantage is that it accounts for uncertainty and allows explicit use of prior information.
Bayes' theorem provides a principled way to update beliefs in light of new evidence. This allows Bayesian inference to combine new data with prior knowledge in a coherent way.</li>
</ul>
<p>In summary, Bayesian inference uses Bayes' theorem to update probabilities after observing data. It incorporates prior beliefs, models uncertainty, and allows for sequential analysis, making it very useful for data analysis and modeling.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>Here&#39;s a simple example of how a person could use Bayesian inference in a real-world situation:
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>Suppose you take a medical test to screen for a rare disease. The test has a 98% accuracy rate - meaning if you have the disease, there is a 98% chance of a positive result, and if you don&#39;t have the disease, there is a 98% chance of a negative result.
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>The disease affects 1 in 10,000 people in the general population. You take the test and receive a positive result. You want to figure out the probability that you actually have the disease, given the evidence of the positive test result.
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>Using Bayesian inference:
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>Let D be the event that you have the disease
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>Let T+ be the event of a positive test
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>We start with the initial prior probability of having the disease P(D) = 1/10,000 = 0.0001
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>The probability of a positive test given that you do have the disease: P(T+|D) = 0.98
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>And the probability of a positive test given you don&#39;t have the disease: P(T+|~D) = 0.02
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>Using Bayes&#39; theorem:
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>P(D|T+) = P(T+|D) x P(D) / P(T+)
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>P(T+) can be calculated using the law of total probability:
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>P(T+) = P(T+|D) x P(D) + P(T+|~D) x P(~D)
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>= 0.98 x 0.0001 + 0.02 x 0.9999
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>= 0.0298
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>Plugging this all in gives:
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>P(D|T+) = 0.98 x 0.0001 / 0.0298 = 0.0033
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>So the probability you have the disease after getting a positive test is only about 0.33% or 1 in 300 people, much lower than the 1 in 10,000 prior probability. This shows how a positive test result updates our beliefs using Bayesian inference.
</span></code></pre></div>
<p>See also <a href="./">B</a>, <a href="./#belief-distribution">Belief Distribution</a>, <a href="../p/#prior-belief">Prior Belief</a></p>
<h2 id="bayesian-inference_1">Bayesian Inference<a class="headerlink" href="#bayesian-inference_1" title="Permanent link">#</a></h2>
<p>How confident are you in the result? A method of statistical learning - using a small amount of historical data and combining it with new data
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>          P(B|A) x P (A)
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>P(A|B) = ----------------
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>            P(B)
</span></code></pre></div></p>
<p>See also <a href="./">B</a>, <a href="./#bayes-theorem">Bayes' Theorem</a>, <a href="./#bayesian-network">Bayesian Network</a></p>
<h2 id="bayesian-network">Bayesian Network<a class="headerlink" href="#bayesian-network" title="Permanent link">#</a></h2>
<p>Bayesian networks are graphical models that use <a href="./#bayesian-inference">Bayesian inference</a> to represent variables and their conditional dependencies. The goal of Bayesian networks is to model likely causation (conditional dependence), by representing these conditional dependencies as connections between nodes in a directed acyclic graph (DAG). The graphs nodes are just the models variables, whether observable quantities, latent variables, unknown parameters or subjective hypotheses. Once graphed, researchers can then fairly simply calculate the probability tables for each node and find the joint probability effect of even independent, random variables on the models final outcome.</p>
<p><img alt="" src="../img/b/bayesian_network.png" width="100%" /></p>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bayesian-optimization-sampling-method">Bayesian Optimization Sampling Method<a class="headerlink" href="#bayesian-optimization-sampling-method" title="Permanent link">#</a></h2>
<p>Use ML to optimize your model. Given N samples, what would be the best next step to for my sample (given that I am looking for a local maxima) . This optimization method is an INFORMED method where the search DOES use previous results to pick the next input values to try.  <code>The concept is to limit evals of the objective function * which is time consuming/expensive * by spending more time choosing the next values to try.</code> (Think dichotomy, + awareness of correlation between parameters, etc? ==&gt; <code>from which next sample will I learn the most?</code>)</p>
<p>Beware:</p>
<ul>
<li>To use when</li>
<li>getting a sample is expensive ==&gt; smart sampling required!</li>
<li>observations are noisy (?)</li>
<li>function is black box, with no closed form or gradient (?)</li>
<li>you are looking for a minima and do not care about the distribution (?)</li>
</ul>
<p>More</p>
<ul>
<li><a href="https://scikit-optimize.github.io/notebooks/hyperparameter-optimization.html">https://scikit-optimize.github.io/notebooks/hyperparameter-optimization.html</a></li>
<li><a href="https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0">https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../a/#active-learning">Active Learning</a>, <a href="../g/#grid-search">Grid Search</a>, <a href="../h/#hyperparameter">Hyperparameter</a>, <a href="../r/#random-search">Random Search</a>, <a href="../s/#surrogate-model">Surrogate Model</a></p>
<h2 id="bayes-search">Bayes Search<a class="headerlink" href="#bayes-search" title="Permanent link">#</a></h2>
<p>Searching for a value using the <a href="./#bayesian-optimization-sampling-method">bayesian optimization sampling method</a>.</p>
<p>Bayes Search uses the Bayesian optimization technique to model the search space to arrive at optimized parameter values as soon as possible. It uses the structure of search space to optimize the search time. Bayes Search approach uses the past evaluation results to sample new candidates that are most likely to give better results (shown in the figure below).</p>
<p><img alt="" src="../img/b/bayes_search.webp" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d">https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d</a></li>
</ul>
<p>See also <a href="./">B</a>, [Hyperparameter Optimization]</p>
<h2 id="beam-search">Beam Search<a class="headerlink" href="#beam-search" title="Permanent link">#</a></h2>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="behavioural-cloning">Behavioural Cloning<a class="headerlink" href="#behavioural-cloning" title="Permanent link">#</a></h2>
<p>~ Trying to duplicate the behavior of an expect. Early approaches to imitation learning seek to learn a policy as a machine learning model that maps environment observations to (optimal) actions taken by the expert using supervised learning. The method is called Behavioral Cloning (BC), but it has a drawback: BC has loose, or no, guarantees that the model will generalize to unseen environmental observations. A key issue is that when the agent ends up in an situation that is unlike any of the expert trajectories, BC is prone to failures.</p>
<p><img alt="" src="../img/b/behavioural_cloning.png" width="100%" /></p>
<p>For example, in the figure above, the car agent doesnt know what to do if it goes away from the expert trajectory and it crashes. To avoid making a mistake, BC requires expert data on all possible trajectories in the environment, making it a heavily data-inefficient approach.</p>
<p>See also <a href="./">B</a>, [Imitation Learning]</p>
<h2 id="belief-distribution">Belief Distribution<a class="headerlink" href="#belief-distribution" title="Permanent link">#</a></h2>
<p>A belief distribution, also known as a probability distribution, is a mathematical function that describes all the possible values a random variable can take and the probability associated with each value.</p>
<p>In Bayesian inference, belief distributions represent the probabilities assigned to different hypotheses or parameter values before (prior distribution) and after (posterior distribution) observing evidence.</p>
<p>Some key points about belief distributions:</p>
<ul>
<li>They summarize current beliefs about plausible values a quantity can take by assigning probabilities.</li>
<li>The area under the belief distribution sums to 1, representing all possible outcomes.</li>
<li>Common belief distributions include the normal, binomial, Poisson, etc. Each models different processes and assumptions.</li>
<li>The <a href="../p/#prior-belief">prior belief</a> distribution captures initial beliefs about a quantity before evidence is considered. It may be based on previous data, a physical model, or just a subjective guess.</li>
<li>The <a href="../p/#posterior-belief">posterior belief</a> distribution is the result of updating the prior with new evidence using Bayes' theorem. It represents updated knowledge.</li>
<li>Belief updating refers to transforming a prior distribution into a posterior distribution when new data is observed.</li>
<li>Bayes' theorem describes how to update beliefs mathematically by combining prior knowledge with likelihood functions from new data.</li>
</ul>
<p>So in summary, a belief distribution models uncertainty by assigning probabilities over a range of values. Bayesian inference updates beliefs from the prior to posterior distribution as evidence is gathered.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a># Example:
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>Here is a simple example to illustrate belief distributions:
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>Suppose there is a bag with 20 marbles. You believe 5 of them are red and the rest are blue, but you&#39;re not completely certain. Your belief can be represented by a probability distribution:
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>Prior belief distribution:
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>Red marbles: 5, with probability 0.25
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>Blue marbles: 15, with probability 0.75
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>This shows your initial belief before observing any evidence. The probability sums to 1 over all possibilities.
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>Now suppose you draw a sample of 5 marbles randomly, and get:
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>Red: 3
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>Blue: 2
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>You can now update your belief using Bayes&#39; theorem:
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>P(Red|Data) = P(Data|Red)*P(Red) / P(Data)
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>The posterior probability of red is now 0.4 after seeing the data. The full posterior distribution is:
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>Posterior belief distribution:
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>Red marbles: 8, with probability 0.4
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>Blue marbles: 12, with probability 0.6
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>Your belief has shifted towards more red marbles based on the observed data. The posterior distribution represents your updated knowledge about the marble bag after combining your prior belief with the evidence.
</span></code></pre></div>
<h2 id="belief-desire-intention-bdi-framework">Belief-Desire-Intention (BDI) Framework<a class="headerlink" href="#belief-desire-intention-bdi-framework" title="Permanent link">#</a></h2>
<p>The belief-desire-intention (BDI) framework for intelligent agents is the foundation for [Procedural Reasoning System] or PRS. A person's beliefs are what they hold to be true about how the world is right now, while their desires and intentions are what they are doing to work toward those goals. In addition, unlike purely reactive systems like the subsumption architecture, each of these three components is within the PRS agent.</p>
<ul>
<li>Beliefs consist of what the agent believes to be true about the current state of the world</li>
<li>Desires consist of the agent's goals</li>
<li>Intentions consist of the agent's current plans for achieving those goals.</li>
</ul>
<p>Furthermore, each of these three components is typically explicitly represented somewhere within the memory of the PRS agent at runtime, which is in contrast to purely reactive systems, such as the subsumption architecture.</p>
<p>More at:</p>
<ul>
<li><a href="https://indiaai.gov.in/article/understanding-procedural-reasoning-systems-in-ai">https://indiaai.gov.in/article/understanding-procedural-reasoning-systems-in-ai</a></li>
</ul>
<h2 id="bellman-equation">Bellman Equation<a class="headerlink" href="#bellman-equation" title="Permanent link">#</a></h2>
<p>They are a class of reinforcement Learning algorithms that are used particularly for deterministic <a href="../e/#environment">environments</a>. Beware:
  * if we have large state spaces, it becomes extremely difficult and close to impossible to solve this system of equations explicitly.
 First the target Q-value equation (which is used to compute the loss function? Yes!)</p>
<p><img alt="" src="../img/b/bellman_equation_target_qvalue.png" width="100%" /></p>
<p>Notice that we first must compute the " max Q * (s',a') " with s' and a' are the state and action that occur in the following [timestep]. This value is found </p>
<ul>
<li>in the Q-table when using one</li>
<li>or by passing s' to the DQN and taking the maximum of its output, i.e q(s',a_?). &lt;== &lt;!&gt; That's 2 forward passes(one for s or s_t and one for s' or s_t+1) before an type of gradient update</li>
</ul>
<p>The loss function used for DQN training is calculated </p>
<ul>
<li>by subtracting the Q-Value for a given state-action pair given by the policy network (DQN) FROM the optimal Q-value for the same state-action pair. </li>
<li>or by subtracting the Q value given by the policy network for the state action pair from our original experience tuple FROM the target optimal key value for the same state action pair </li>
</ul>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> updates are such that the output Q_values will be as close as possible to the target_q_values given by the bellman equation. This will approximate te optimal Q function which will give us the optimal policy. </p>
<p><img alt="" src="../img/b/bellman_equation_loss_function.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>loss - <a href="https://deeplizard.com/learn/video/0bt0SjbS3xc">https://deeplizard.com/learn/video/0bt0SjbS3xc</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../d/#deep-q-network-dqn">Deep Q-Network</a>, <a href="../q/#q-value-function">Q-Value Function</a>, <a href="../s/#state-space">State Space</a></p>
<h2 id="benchmark">Benchmark<a class="headerlink" href="#benchmark" title="Permanent link">#</a></h2>
<ul>
<li><a href="../g/#general-artificial-intelligence-assistant-gaia-benchmark">General AI Assitant (GAIA)</a></li>
</ul>
<p>NLP Benchmarks:</p>
<ul>
<li>[Beyond The Imitation Game (BIG Bench)]</li>
<li>Coref -  Links pronouns to antecedents. Also capable to take the perspective of a speak, e.g. I, you, my sister, etc refers to different people function of who said it.</li>
<li><a href="../g/#general-language-understanding-evaluation-glue-benchmark">GLUE</a> -</li>
<li><a href="../n/#named-entity-recognition-ner">Named Entity Recognition (NER)</a> - identify places, people, dates, etc</li>
<li>Language Parser : Identify which group of words go together (as phrase) and which words are the subject or object of a verb.</li>
<li>[Multi-Turn Question Set (MT-Bench)] - Rate conversational AI using human preference modeled by a <a href="../l/#llm-as-a-judge">LLM-as-a-judge</a></li>
<li>SNLI - relation between 2 statements (contradict, neutral, or entailment)</li>
<li>[SQuAD] - Question and answering</li>
<li>[SuperGLUE] -</li>
<li>SRL - Semantic understanding (machine translation, information extraction, text summarization, question answering)</li>
<li>SST-5 - Sentiment analysis - <a href="https://paperswithcode.com/sota/sentiment-analysis-on-sst-5-fine-grained">https://paperswithcode.com/sota/sentiment-analysis-on-sst-5-fine-grained</a></li>
<li><a href="../t/#truthfulqa-benchmark">TruthfulQA</a> - avoid generating false answers learned from imitating human texts (conspiracies, rumors, etc)</li>
</ul>
<p>Bias</p>
<ul>
<li><a href="./#bias-benchmark-for-question-answering-bbq">Bias Benchmark for Question Answering (BBQ)</a> - Measure learn social biases of a NLP model</li>
</ul>
<p>Knowledge:</p>
<ul>
<li><a href="../m/#massive-multitask-language-understanding-mmlu-benchmark">Massive Multitask Language Understanding (MMLU)</a> - Broad set of questions testing undergraduate-level knowledge</li>
<li>[Google-Proof Questions And Answers (GPQA)] - PhD level questions</li>
</ul>
<p>Graph Neural Network (GNN) Benchmarks:</p>
<ul>
<li><a href="../r/#relational-deep-learning-benchmark-relbench">Relational Deep Learning Benchmark (RelBench)</a> - GNN on relational databases</li>
</ul>
<p>Psychoanalysis</p>
<ul>
<li><a href="../f/#for-stress-testing-machine-theory-of-mind-fantom-benchmark">FANToM</a> - stress-testing machine theory of mind in interactions</li>
<li><a href="../e/#emotional-intelligence-benchmark-eq-bench">EQ-Bench</a> - emotional intelligence benchmark</li>
</ul>
<p>All of those are included in the <a href="../h/#holistic-evaluation-of-language-model-helm-benchmark">HELM Benchmark</a></p>
<p>Scientific</p>
<ul>
<li><a href="../m/#matbench-discovery-benchmark">Matbench Discovery</a> - </li>
</ul>
<p>See also <a href="../n/">N</a>, <a href="../c/#coreference">Coreference</a>, <a href="../e/#entity-extraction">Entity Extraction</a>, <a href="../l/#language-parsing">Language Parsing</a>, <a href="../m/#model-benchmark">Model Benchmark</a>, <a href="../q/#question-answering-qa">Question Answering</a>, <a href="../s/#semantic-understanding">Semantic Understanding</a>, <a href="../s/#sentiment-analysis">Sentiment Analysis</a>, <a href="../s/#stanford-natural-language-inference-snli">SNLI</a></p>
<h2 id="berkeley-university">Berkeley University<a class="headerlink" href="#berkeley-university" title="Permanent link">#</a></h2>
<p>Models</p>
<ul>
<li><a href="https://bair.berkeley.edu/blog/2023/04/03/koala/">Koala</a></li>
<li>...</li>
</ul>
<p>Research</p>
<ul>
<li>BLAIR Blog - <a href="https://bair.berkeley.edu/blog/">https://bair.berkeley.edu/blog/</a></li>
<li><a href="https://ml.berkeley.edu/research">Berkeley</a> <a href="https://twitter.com/berkeley_ai">@berkeley_ai</a></li>
</ul>
<h2 id="bernoulli-distribution">Bernoulli Distribution<a class="headerlink" href="#bernoulli-distribution" title="Permanent link">#</a></h2>
<p>the discrete probability distribution of a random variable which takes the value 1 with probability P and the value 0 with probability Q=1-P. Less formally, it can be thought of as a model for the set of possible outcomes of any single experiment that asks a yesno question. Such questions lead to outcomes that are boolean-valued: a single bit whose value is success/yes/true/one with probability p and failure/no/false/zero with probability Q. It can be used to represent a (possibly biased) coin toss where 1 and 0 would represent "heads" and "tails", respectively, and P would be the probability of the coin landing on heads (or vice versa where 1 would represent tails and P would be the probability of tails). In particular, unfair coins would have P =/= 1/2. The Bernoulli distribution is a special case of the binomial distribution where a single trial is conducted (so n would be 1 for such a binomial distribution). It is also a special case of the two-point distribution, for which the possible outcomes need not be 0 and 1.</p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">https://en.wikipedia.org/wiki/Bernoulli_distribution</a></li>
</ul>
<h2 id="bert-classification">BERT Classification<a class="headerlink" href="#bert-classification" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/b/bert_classification.png" width="100%" /></p>
<ul>
<li>E = word embeddings ?     &lt;=== Maybe wrong use of embedding, rather token, i.e. tokenized?</li>
<li>Embedding is an integer from a tokenizer? No!</li>
<li>Sparse vector (of tokenised sentence) fed to <a href="../w/#word2vec-model">word2vec</a> (or similar) ? No!</li>
<li>R = representation ( token after transformation by encoder stack )</li>
<li>Representation is a matrix/tensor (of square dimension 768?)</li>
<li>"What is the cost?" and "Is it expensive?" have almost the same SEP_representation !</li>
</ul>
<p>See also <a href="./">B</a>, [Bidirectional Encoder Representations from Transformer Model]</p>
<h2 id="beta-distribution">Beta Distribution<a class="headerlink" href="#beta-distribution" title="Permanent link">#</a></h2>
<p>A popular <a href="../d/#distribution">distribution</a> that models a probability of a probability</p>
<ul>
<li>value is between 0 and 1</li>
<li>mean is close to sample proportion</li>
<li>std to be ...</li>
</ul>
<p>2 parameters</p>
<ul>
<li>alpha - number of successes/wins/true</li>
<li>beta - number of failures/losses/false</li>
</ul>
<p><img alt="" src="../img/b/beta_distribution.png" width="30%" /></p>
<iframe src="https://www.youtube.com/embed/juF3r12nM5A" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/1k8lF3BriXM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<h2 id="best-match-25-bm25-retrieval-model">Best Match 25 (BM25) Retrieval Model<a class="headerlink" href="#best-match-25-bm25-retrieval-model" title="Permanent link">#</a></h2>
<p>A widely used text <a href="../r/#retrieval-based-model">retrieval model</a> based on probabilistic [information retrieval] theory. It ranks documents based on term frequencies and inverse document frequencies, considering both the relevance and rarity of terms within a corpus.</p>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bhuman-company">BHuman Company<a class="headerlink" href="#bhuman-company" title="Permanent link">#</a></h2>
<p>Produce a single viedo of yourself and personalize it for thousands of recipients.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.bhuman.ai/">https://www.bhuman.ai/</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../c/#company">Company</a></p>
<h2 id="beyond-the-imitation-game-benchmark-big-bench">Beyond the Imitation Game Benchmark (BIG Bench)<a class="headerlink" href="#beyond-the-imitation-game-benchmark-big-bench" title="Permanent link">#</a></h2>
<p>Focus on task that are not easy to solve</p>
<iframe src="https://www.youtube.com/embed/ZpImxa0tK2Y" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/ydfJ16RWJL8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2206.04615" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2206.04615">Download PDF</a>.
    </p>
</object>

<object data="https://arxiv.org/pdf/2210.09261" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2210.09261">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper -</li>
<li>task code - <a href="https://github.com/google/BIG-bench">https://github.com/google/BIG-bench</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bias">Bias<a class="headerlink" href="#bias" title="Permanent link">#</a></h2>
<p>~ a predisposition in favor or against something that is often considered to be unfair</p>
<ul>
<li><a href="../s/#statistical-bias">Statistical Bias</a> = The gap between the prediction and the actual value. Where is bias coming from? Issues with the data sampling?</li>
<li><a href="../a/#artificial-neuron-bias">Artificial Neuron Bias</a> = When using bias in the connect of activation function, it is an integer that represent a threshold the weighted input should exceed to trigger the neuron. There is a bias at each node of the ANN. The node weighted input is = sum(aL . wL) + bias</li>
<li><a href="../d/#dataset-bias">Dataset Bias</a> and</li>
<li>[Algorithmic Bias] which can lead to <a href="../a/#ai-bias">AI Bias</a></li>
<li><a href="../i/#inductive-bias">Inductive Bias</a> or Learning bias related to the assumption we make in our model</li>
<li>
<p><a href="../s/#social-bias">Social Bias</a> = when a model knowledge is extracted from humans, such as from the internet (Stereotypes)</p>
</li>
<li>
<p>statistics ==&gt; The gap between the prediction and the actual value. Where is bias coming from? Issues with the data sampling?</p>
</li>
<li>data sample ==&gt; data that is used for learning is biased, ex: all nurse are female ==&gt; implies unwanted correlation in data</li>
<li>algorithmic bias ==&gt; algorithm is trained using biased data</li>
<li>neural network learning ==&gt; When using bias in the connect of activation function, it is an integer that represent a threshold the weighted input should exceed to trigger the neuron. There is a bias at each node of the ANN. The node weighted input is = sum(aL . wL) + bias.</li>
</ul>
<iframe src="https://www.youtube.com/embed/mG-cTS3fnnw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="./#balanced-fitting">Balanced Fitting</a>, [Bias Benchmark For Question Answering], <a href="./#bias-variance-trade-off">Bias-Variance Trade-off</a>, <a href="../f/#fair-ai">Fair AI</a>, <a href="../o/#overfitting">Overfitting</a>, <a href="../u/#underfitting">Underfitting</a>, <a href="../v/#variance">Variance</a></p>
<h2 id="bias-benchmark-for-question-answering-bbq">Bias Benchmark For Question Answering (BBQ)<a class="headerlink" href="#bias-benchmark-for-question-answering-bbq" title="Permanent link">#</a></h2>
<p>It is well documented that NLP models learn social biases, but little work has been done on how these biases manifest in model outputs for applied tasks like question answering (QA). We introduce the Bias Benchmark for QA (BBQ), a dataset of question-sets constructed by the authors that highlight attested social biases against people belonging to protected classes along nine social dimensions relevant for U.S. English-speaking contexts. Our task evaluate model responses at two levels: (i) given an under-informative context, we test how strongly responses reflect social biases, and (ii) given an adequately informative context, we test whether the models biases override a correct answer choice. We find that models often rely on stereotypes when the context is under-informative, meaning the models outputs consistently reproduce harmful biases in this setting. Though models are more accurate when the context provides an informative answer, they still rely on stereotypes and average up to 3.4 percentage points higher accuracy when the correct answer aligns with a social bias than when it conflicts, with this difference widening to over 5 points on examples targeting gender for most models tested.</p>
<p><img alt="" src="../img/b/bias_benchmark_for_question_answering.png" width="100%" /></p>
<object data="https://aclanthology.org/2022.findings-acl.165.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://aclanthology.org/2022.findings-acl.165.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://aclanthology.org/2022.findings-acl.165/">https://aclanthology.org/2022.findings-acl.165/</a></li>
</ul>
<h2 id="bias-neuron">Bias Neuron<a class="headerlink" href="#bias-neuron" title="Permanent link">#</a></h2>
<p>The value of a bias neuron is always equal to 1. The input and [hidden layers] always have a bias neuron (while the output layer does not, since not useful). What is different is the weight between the bias neuron and all the neurons in the following layer. The weight is the value of the bias (since bias = value * 1). </p>
<p>In the case of the simplest neural network, with 1 input neuron + 1 input bias neuron --&gt; single output neuron, the value of that output neuron is given by a line v = input * weight + weight_bias * 1, in other words, a line!</p>
<p><img alt="" src="../img/b/bias_neuron_1.png" width="&quot;100%" /></p>
<p><img alt="" src="../img/b/bias_neuron_line.png" width="&quot;100%" /></p>
<h2 id="bias-variance-trade-off">Bias-Variance Trade-off<a class="headerlink" href="#bias-variance-trade-off" title="Permanent link">#</a></h2>
<p>~ bias means that the model has a systematic error that prevent it from reaching perfection regardless of input data (e.g. Accuracy cannot be higher than 70% when we use a linear regression, when the underlying distribution is  quadratic!)</p>
<p>~ variance means the model performs differently between datasets (input data) (e.g. Accuracy is at 95% on training data, but 42% on test data &lt;-- <a href="../o/#overfitting">overfitting</a> )</p>
<p>Ideally, a model will have both low bias and variance, but efforts to decrease one will frequently increase the other. This is known as the bias-variance trade-off.</p>
<p>Let us consider that we have a very accurate model, this model has a low error in predictions and its not from the target (which is represented by bulls eye). This model has low bias and variance. Now, if the predictions are scattered here and there then that is the symbol of high variance, also if the predictions are far from the target then that is the symbol of high bias.
 Sometimes we need to choose between low <a href="../v/#variance">variance</a> and low <a href="./#bias">bias</a>. There is an approach that prefers some <a href="./#bias">bias</a> over high <a href="../v/#variance">variance</a>, this approach is called <a href="../r/#regularization">Regularization</a>. It works well for most of the <a href="../c/#classification-task">classification</a> / <a href="../r/#regression-task">regression</a> problems.</p>
<p>Note that the bias-variance tradeoff is closely related to the concept of <a href="../i/#inductive-bias">inductive bias</a></p>
<p><img alt="" src="../img/b/bias_variance_tradeoff.jpeg" width="&quot;100%" /></p>
<p><img alt="" src="../img/b/bias_variance_tradeoff_model_complexity.jpeg" width="&quot;100%" /></p>
<iframe src="https://www.youtube.com/embed/EuBBz3bI-aA" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/">https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bidirectional-encoder-representation-from-transformer-bert-model-family">Bidirectional Encoder Representation from Transformer (BERT) Model Family<a class="headerlink" href="#bidirectional-encoder-representation-from-transformer-bert-model-family" title="Permanent link">#</a></h2>
<p>A NLP model that was built by <a href="../g/#google-company">Google</a> in 2017. It is an Open-Source project by Google AI researchers with a great power of understanding the context of sentence (language) showing high performance in various nlp tasks such as <a href="./#bert-classification">classification</a> such as <a href="../s/#sentiment-analysis">sentiment analysis</a>, <a href="../q/#question-answering-qa">question answering</a>, <a href="../n/#named-entity-recognition-ner">named entity recognition</a>, <a href="../m/#machine-translation">machine Translation</a> and many more.</p>
<ul>
<li>Use the <a href="../t/#transformer-architecture">transformer architecture</a></li>
<li>BIDIRECTIONAL = use words before and after the [MASK] to predict the Masked word. This is different from unidirectional (used by GPT) such as predicting what the next word is.</li>
<li>Can be extended, i.e. FinBERT for financial docs, SpanBERT for Spanish</li>
</ul>
<p>Trained using</p>
<ul>
<li><a href="../m/#masked-language-modeling-mlm">Masked Language Modeling (MLM)</a>     &lt;== pre-train work embedding and contextual understanding using [MASK]</li>
<li>and <a href="../n/#next-sentence-prediction-nsp">next sentence prediction (NSP)</a>.  &lt;== pre-train the [CLS] token (used to perform sequence/sentence-wide task)<ul>
<li>Note that the representation of the [CLS] token include both the sentences, the one before and the one after the [SEP] token (separation token) (?)</li>
</ul>
</li>
</ul>
<p>Superseded by the <a href="../r/#robustly-optimized-bert-approach-roberta-model">RoBERTa model</a></p>
<p><img alt="" src="../img/b/bert_embeddings.png" width="35%" /></p>
<object data="https://arxiv.org/pdf/1810.04805" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1810.04805">Download PDF</a>.
    </p>
</object>

<iframe src="https://www.youtube.com/embed/wjZofJX0v4M" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805</a></li>
<li>derivative models<ul>
<li>spanBERT - <a href="https://skimai.com/roberta-language-model-for-spanish/">https://skimai.com/roberta-language-model-for-spanish/</a></li>
<li><a href="https://arxiv.org/abs/1907.10529">https://arxiv.org/abs/1907.10529</a></li>
<li>RoBERTa - <a href="https://arxiv.org/abs/1907.11692">https://arxiv.org/abs/1907.11692</a></li>
<li>Sentence-BERT (SBERT) - create sentence embeddings</li>
</ul>
</li>
<li>articles<ul>
<li>embeddings (token + segment + position) - <a href="https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a">https://medium.com/@<em>init</em>/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a</a></li>
<li><a href="https://medium.com/@mromerocalvo/6dcf5360b07f">https://medium.com/@mromerocalvo/6dcf5360b07f</a></li>
<li><a href="https://medium.com/dissecting-bert/dissecting-bert-part2-335ff2ed9c73">https://medium.com/dissecting-bert/dissecting-bert-part2-335ff2ed9c73</a></li>
<li><a href="https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853">https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">B</a>, <a href="../a/#attention-score">Attention Score</a>, <a href="../a/#attention-based-model">Attention-Based Model</a>, <a href="../t/#tokenizer">Tokenizer</a></p>
<h2 id="bidirectional-rnn-brnn">Bidirectional RNN (BRNN)<a class="headerlink" href="#bidirectional-rnn-brnn" title="Permanent link">#</a></h2>
<p>Bidirectional recurrent neural networks (BRNN) connect two hidden layers running in opposite directions to a single output, allowing them to receive information from both past and future states. This generative deep learning technique is more common in supervised learning approaches, rather than unsupervised or semi-supervised because how difficult it is to calculate a reliable probabilistic model.</p>
<p><img alt="" src="../img/b/bidirectional_recurrent_neural_network.png" width="30%" /></p>
<p>See also <a href="./">B</a>, [Recurrent Neural Network]</p>
<h2 id="big-data">Big Data<a class="headerlink" href="#big-data" title="Permanent link">#</a></h2>
<blockquote>
<p>"Move the processing where the data is!"</p>
</blockquote>
<p>Big data primarily refers to data sets that are too large or complex to be dealt with by traditional data-processing application software.
 Big data analysis challenges include capturing data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating, information privacy, and data source. Big data was originally associated with three key concepts: volume, variety, and velocity.</p>
<p><img alt="" src="../img/b/big_data_1986_to_2007.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Big_data">https://en.wikipedia.org/wiki/Big_data</a></li>
</ul>
<p>See also <a href="./">B</a>, [Deep Learning], [Machine Learning], <a href="../m/#mapreduce-process">MapReduce Process</a></p>
<h2 id="bigram">Bigram<a class="headerlink" href="#bigram" title="Permanent link">#</a></h2>
<p>In a bigram model, each word is predicted based on the word directly preceding it. So, the model looks at pairs of words that frequently occur together in the training data. For instance, if the previous word is "sunny," the model might predict that words like "day" or "weather" are likely to follow, based on its learned bigrams like "sunny day" or "sunny weather."</p>
<p>The essence of a bigram model is this: it uses the immediate past word to predict the next one. It's a simple yet effective way to capture the context in language processing.</p>
<p>See also <a href="./">B</a>, <a href="../n/#n-gram">N-Gram</a></p>
<h2 id="bilingual-evaluation-understudy-bleu-score">Bilingual Evaluation Understudy (BLEU) Score<a class="headerlink" href="#bilingual-evaluation-understudy-bleu-score" title="Permanent link">#</a></h2>
<p>This is an algorithm for evaluating the quality of text which has been <a href="../m/#machine-translation">machine-translated</a> from one natural language to another. Quality is considered to be the correspondence between a machine's output and that of a human: "the closer a machine translation is to a professional human translation, the better it is"  this is the central idea behind BLEU.</p>
<p>BLEU was one of the first metrics to claim a high correlation with human judgements of quality, and remains one of the most popular automated and inexpensive metrics. Scores are calculated for individual translated segmentsgenerally sentencesby comparing them with a set of good quality reference translations. Those scores are then averaged over the whole corpus to reach an estimate of the translation's overall quality. Intelligibility or grammatical correctness are not taken into account. </p>
<p>BLEU's output is always a number between 0 and 1. This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts. Few human translations will attain a score of 1, since this would indicate that the candidate is identical to one of the reference translations. For this reason, it is not necessary to attain a score of 1. Because there are more opportunities to match, adding additional reference translations will increase the BLEU score.</p>
<p>In general:</p>
<ul>
<li>BLEU focuses on precision: how much the words (and/or n-grams) in the candidate model outputs appear in the human reference.</li>
<li><a href="../r/#recall-oriented-understudy-for-gisting-evaluation-rouge-score">ROUGE</a> focuses on recall: how much the words (and/or n-grams) in the human references appear in the candidate model outputs.</li>
</ul>
<p>These results are complementing, as is often the case in the precision-recall tradeoff.</p>
<iframe src="https://www.youtube.com/embed/M05L1DhFqcw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://medium.com/nlplanet/two-minutes-nlp-learn-the-bleu-metric-by-examples-df015ca73a86">https://medium.com/nlplanet/two-minutes-nlp-learn-the-bleu-metric-by-examples-df015ca73a86</a></li>
</ul>
<p>See also <a href="./">B</a>, [NLP Metrics]</p>
<h2 id="bill-gates-person">Bill Gates Person<a class="headerlink" href="#bill-gates-person" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/bHb_eG46v2c" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun">https://www.gatesnotes.com/The-Age-of-AI-Has-Begun</a></li>
</ul>
<h2 id="bin">Bin<a class="headerlink" href="#bin" title="Permanent link">#</a></h2>
<p>See <a href="./#bucket">Bucket</a></p>
<h2 id="binary-classification">Binary Classification<a class="headerlink" href="#binary-classification" title="Permanent link">#</a></h2>
<p>~ answer Yes or No, This or That, Boy or Girl</p>
<p><code>Answer a question with Yes or No with a confidence level</code>. Ex: is this shape a square? The simplest case of classification algorithm. In the case of the support-vector-machine, binary classification can be done with the creation of a hyperplane as a decision boundary in a real, transformed, or latent space.</p>
<p>See also <a href="./">B</a>, [Binary Cross-Entropy Loss Function], <a href="../c/#classification-task">Classification</a>, <a href="../m/#multi-class-classification">Multi-class Classification</a>, <a href="../s/#support-vector-machine-svm">Support Vector Machine</a></p>
<h2 id="binary-cross-entropy-bce-loss-function">Binary Cross-Entropy (BCE) Loss Function<a class="headerlink" href="#binary-cross-entropy-bce-loss-function" title="Permanent link">#</a></h2>
<p>If you are training a <a href="./#binary-classification">binary classifier</a>, a <a href="../m/#multi-label-classification">multi-label classification</a>, or a <a href="../r/#regression-task">regression</a>, chances are you are using binary cross-entropy / log loss as your <a href="../l/#loss-function">loss function</a>.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>cross-entropy loss = c = sum(0, n, Pi * log (1/Qi)
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a># And in the case of binary classification problem where we have only two classes, we name it as binary cross-entropy loss and above formula becomes:
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>binary cross-entropy loss = c = sum(0, 1, Pi * log (1/Qi) = Po * log(1/Qo) + (1-Po) * log(1/Q1)
</span></code></pre></div>
<iframe src="https://www.youtube.com/embed/DPSXVJF5jIs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/i78buAHKXpI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at :</p>
<ul>
<li><a href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a">https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../c/#cross-entropy-loss-function">Cross-Entropy Loss Function</a>, <a href="../e/#entropy">Entropy</a></p>
<h2 id="bing-search-engine">Bing Search Engine<a class="headerlink" href="#bing-search-engine" title="Permanent link">#</a></h2>
<p>Search engine developed by <a href="../m/#microsoft-company">Microsoft</a> that integrates with <a href="../c/#chatgpt-model">ChatGPT</a>[ChatGPT Model[</p>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="binomial-distribution">Binomial Distribution<a class="headerlink" href="#binomial-distribution" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/sVBOSwT5K8I" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, <a href="../d/#distribution">Distribution</a></p>
<h2 id="biological-neuron">Biological Neuron<a class="headerlink" href="#biological-neuron" title="Permanent link">#</a></h2>
<p>Biological neuron are much more powerful than a artificial neuron, aka perceptron.</p>
<iframe src="https://www.youtube.com/embed/hmtQPrH-gC4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">B</a>, <a href="../a/#artificial-neuron">Artificial Neuron</a>, <a href="./#brain">Brain</a>, <a href="../d/#dendrite">Dendrite</a>, <a href="../s/#synapse">Synapse</a></p>
<h2 id="blip-model">BLIP Model<a class="headerlink" href="#blip-model" title="Permanent link">#</a></h2>
<p>Create a a caption for an image using an encoder-decoder model (unlike the CLIP model, does not use the same embedding space?).</p>
<p>See also <a href="./">B</a>, <a href="../c/#contrastive-language-image-pre-training-clip-model">CLIP Model</a>, <a href="../i/#image-reconstruction">Image Reconstruction</a>, <a href="../m/#multimodal-translation">Multimodal Translation</a>, <a href="../t/#text-reconstruction">Text Reconstruction</a></p>
<h2 id="black-box-model">Black Box Model<a class="headerlink" href="#black-box-model" title="Permanent link">#</a></h2>
<p>A neural network is a black box model as even if you saw the weights you would have difficulties understanding how it comes to a decision. In fact it may come to the right answer using the wrong reasons. The opposite of a <a href="../w/#white-box-model">White Box Model</a> in relation to [Explainable AI]</p>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="block-sparse-attention">Block-Sparse Attention<a class="headerlink" href="#block-sparse-attention" title="Permanent link">#</a></h2>
<p>~ Computed attention is an [approximate attention]</p>
<p>See also <a href="./">B</a>, <a href="../f/#flashattention">FlashAttention</a></p>
<h2 id="bloomberggpt-model">BloombergGPT Model<a class="headerlink" href="#bloomberggpt-model" title="Permanent link">#</a></h2>
<p>Based on Bloom, but what makes it special is the data set it is trained on, public and private (FinPile)</p>
<iframe src="https://www.youtube.com/embed/FxMDrHnKWnk" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2303.17564" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.17564">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2303.17564">https://arxiv.org/abs/2303.17564</a></li>
<li>blog - <a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/">https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/</a></li>
<li>article(s)<ul>
<li><a href="https://openaimaster.com/how-to-use-bloomberg-gpt/">https://openaimaster.com/how-to-use-bloomberg-gpt/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">B</a>, <a href="../c/#chinchilla-scaling-law">Chinchilla Scaling Law</a></p>
<h2 id="boltzmann-machine">Boltzmann Machine<a class="headerlink" href="#boltzmann-machine" title="Permanent link">#</a></h2>
<p>~ developed in 1985, an improvement on <a href="../h/#hopfield-network">Hopfield networks</a> , associative memory network</p>
<p>~ can be generative by memorizing the distribution of the data</p>
<p>an unsupervised DL model in which every node is connected to every other node. That is, unlike the ANNs, CNNs, RNNs and SOMs, the Boltzmann Machines are undirected (or the connections are bidirectional). Boltzmann Machine is not a deterministic DL model but a stochastic or generative DL model. It is rather a representation of a certain system. There are two types of nodes in the Boltzmann Machine  Visible nodes  those nodes which we can and do measure, and the Hidden nodes  those nodes which we cannot or do not measure. Although the node types are different, the Boltzmann machine considers them as the same and everything works as one single system. The training data is fed into the Boltzmann Machine and the weights of the system are adjusted accordingly. Boltzmann machines help us understand abnormalities by learning about the working of the system in normal conditions.</p>
<p><img alt="" src="../img/b/boltzmann_machine.jpeg" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/_bqa_I5hNAo" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/types-of-boltzmann-machines/">https://www.geeksforgeeks.org/types-of-boltzmann-machines/</a></li>
</ul>
<p>See also <a href="./">B</a>, [Deep Belief Network], [Restricted Boltzmann Machine], <a href="../u/#unsupervised-deep-learning-model">Unsupervised Deep Learning Model</a>, <a href="../u/#unsupervised-learning">Unsupervised Learning</a></p>
<h2 id="boosting">Boosting<a class="headerlink" href="#boosting" title="Permanent link">#</a></h2>
<p>Boosting = <a href="./#bagging">Bagging</a>, but not with equal weights. Think of shareholder voting that is proportional to number of shares.</p>
<p>Sequentially combine weak predictors (such as <a href="../d/#decision-tree">decision trees</a>) to get a strong predictor! Start by training a random model, which is the first <a href="../w/#weak-learner">weak learner</a>. Evaluate it on the entire dataset. Shrink the points that have good predictions, and enlarge the points that have poor predictions. Train a second <a href="../w/#weak-learner">weak learner</a> on this modified dataset. We continue in this fashion until we build several models. The way to combine them into a <a href="../s/#strong-learner">strong learner</a> is the same way as with <a href="./#bagging">bagging</a>, namely, by voting or by averaging the predictions of the <a href="../w/#weak-learner">weak learner</a>. More specifically, if the learners are classifiers, the <a href="../s/#strong-learner">strong learner</a> predicts the most common class predicted by the <a href="../w/#weak-learner">weak learners</a> (thus the term voting), and if there are ties, by choosing randomly among them. If the learners are regressors, the strong learner predicts the average of the predictions given by the <a href="../w/#weak-learner">weak learners</a>.</p>
<p>Boosting is primarily used to reduce the <a href="./#bias">bias</a> and <a href="../v/#variance">variance</a> in a <a href="../s/#supervised-learning">supervised learning</a> technique. It refers to the family of an algorithm that converts <a href="../w/#weak-learner">weak learners</a> (base learner) to <a href="../s/#strong-learner">strong learners</a>. The <a href="../w/#weak-learner">weak learner</a> is the classifiers that are correct only up to a small extent with the actual classification, while the strong learners are the classifiers that are well correlated with the actual classification.</p>
<p>Few famous techniques of Boosting are:</p>
<ul>
<li><a href="../a/#adaptive-boosting-adaboost">AdaBoost</a></li>
<li><a href="../g/#gradient-boosting">Gradient boosting</a></li>
<li><a href="../e/#extreme-gradient-boosting-xgboost">Extreme Gradient Boosting (XGBoost)</a>.</li>
</ul>
<p>See also <a href="./">B</a>, <a href="./#boosting-step-size">Boosting Step Size</a></p>
<h2 id="boosting-step-size">Boosting Step Size<a class="headerlink" href="#boosting-step-size" title="Permanent link">#</a></h2>
<p>See also <a href="./">B</a>, <a href="./#boosting">Boosting</a>, <a href="../h/#hyperparameter">Hyperparameter</a></p>
<h2 id="bootstrap-sampling-method">Bootstrap Sampling Method<a class="headerlink" href="#bootstrap-sampling-method" title="Permanent link">#</a></h2>
<p>A large number of samples are drawn randomly with replacement from the original dataset, and the model is trained and tested on these samples. This method is used to estimate the variability of a model's performance and the uncertainty of its predictions. The main concept behind bootstrap sampling is train the same model multiple times on multiple samples taken with replacement from the target population. Bootstrapping is the most popular resampling method today. It uses sampling with replacement to estimate the sampling distribution for a desired estimator. The main purpose for this particular method is to evaluate the variance of an estimator. It does have many other applications, including:</p>
<ul>
<li>Estimating confidence intervals and standard errors for the estimator (e.g. the standard error for the mean),</li>
<li>Estimating precision for an estimator ,</li>
<li>Dealing with non-normally distributed data,</li>
<li>Calculating sample sizes for experiments.</li>
</ul>
<p>Bootstrapping has been shown to be an excellent method to estimate many distributions for statistics, sometimes giving better results than traditional normal approximation. It also works well with small samples. It doesnt perform very well when the model isnt smooth, is not a good choice for dependent data, missing data, censoring, or data with outliers.</p>
<p>Bootstrap + Aggregation = <a href="./#bagging">Bagging</a></p>
<p>More at:</p>
<ul>
<li><a href="https://www.datasciencecentral.com/resampling-methods-comparison/">https://www.datasciencecentral.com/resampling-methods-comparison/</a></li>
</ul>
<p>See also <a href="./">B</a>, <a href="../r/#resampling-method">Resampling Method</a></p>
<h2 id="boston-dynamics-company">Boston Dynamics Company<a class="headerlink" href="#boston-dynamics-company" title="Permanent link">#</a></h2>
<p>Boston Dynamics is an American engineering and robotics design <a href="../c/#company">company</a> founded in 1992 as a spin-off from the Massachusetts Institute of Technology. Headquartered in Waltham, Massachusetts, Boston Dynamics has been owned by the Hyundai Motor Group since December 2020, but having only completed the acquisition in June 2021.</p>
<p>Boston Dynamics develops of a series of dynamic highly-mobile robots, including BigDog, Spot, Atlas, and Handle. Since 2019, Spot has been made commercially available, making it the first commercially available robot from Boston Dynamics, while the company has stated its intent to commercialize other robots as well, including Handle.</p>
<p>Robots:</p>
<ul>
<li>[Atlas]</li>
<li><a href="../s/#spot-robot">Spot</a></li>
<li><a href="../s/#stretch-robot">Stretch</a></li>
</ul>
<iframe src="https://www.youtube.com/embed/L9U3B8wnM7w" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.bostondynamics.com/">https://www.bostondynamics.com/</a></li>
<li><a href="https://www.youtube.com/@BostonDynamics">https://www.youtube.com/@BostonDynamics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boston_Dynamics">https://en.wikipedia.org/wiki/Boston_Dynamics</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bounding-box">Bounding Box<a class="headerlink" href="#bounding-box" title="Permanent link">#</a></h2>
<p>See also <a href="./">B</a>, <a href="../o/#object-detection">Object Detection</a></p>
<h2 id="box-cox-transformation">Box Cox Transformation<a class="headerlink" href="#box-cox-transformation" title="Permanent link">#</a></h2>
<p>A <a href="../f/#feature-distribution-transformation">Feature Distribution Transformation</a></p>
<iframe src="https://www.youtube.com/embed/zYeTyEWt7Cw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at: </p>
<ul>
<li><a href="https://www.statisticshowto.com/probability-and-statistics/normal-distributions/box-cox-transformation/">https://www.statisticshowto.com/probability-and-statistics/normal-distributions/box-cox-transformation/</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="brain">Brain<a class="headerlink" href="#brain" title="Permanent link">#</a></h2>
<p>See also <a href="./">B</a>, <a href="./#biological-neuron">Biological Neuron</a></p>
<h2 id="brain-computer-interface-bci">Brain Computer Interface (BCI)<a class="headerlink" href="#brain-computer-interface-bci" title="Permanent link">#</a></h2>
<p>Connect your <a href="./#brain">brain</a> to a computer using a cable and by drilling a hole in your skull!</p>
<p>Used by <a href="../n/#neuralink-company">Neuralink</a></p>
<p>See also <a href="./">B</a>, <a href="../d/#deep-brain">Deep Brain</a>, ...</p>
<h2 id="bucket">Bucket<a class="headerlink" href="#bucket" title="Permanent link">#</a></h2>
<p>~ aka bin</p>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="bucketing">Bucketing<a class="headerlink" href="#bucketing" title="Permanent link">#</a></h2>
<p>~ aka binning</p>
<p>Converting a single <a href="../f/#feature">feature</a> into multiple binary features called [buckets] or bins, typically based on a value range. The chopped feature is typically a continuous feature.</p>
<p>For example, instead of representing temperature as a single continuous floating-point feature, you could chop ranges of temperatures into discrete buckets, such as:</p>
<ul>
<li>&lt;= 10 degrees Celsius would be the "cold" bucket.</li>
<li>11 - 24 degrees Celsius would be the "temperate" bucket.</li>
<li>&gt;= 25 degrees Celsius would be the "warm" bucket.</li>
</ul>
<p>The model will treat every value in the same bucket identically. For example, the values 13 and 22 are both in the temperate bucket, so the model treats the two values identically.</p>
<p>If you represent temperature as a continuous feature, then the model treats temperature as a single feature. If you represent temperature as three buckets, then the model treats each bucket as a separate feature. That is, a model can learn separate relationships of each bucket to the <a href="../l/#label">label</a>. For example, a <a href="../l/#linear-regression">linear regression</a> model can learn separate <a href="../w/#weight">weights</a> for each bucket.</p>
<p>Increasing the number of buckets makes your model more complicated by increasing the number of relationships that your model must learn. For example, the cold, temperate, and warm buckets are essentially three separate features for your model to train on. If you decide to add two more buckets--for example, freezing and hot--your model would now have to train on five separate features.</p>
<p>How do you know how many buckets to create, or what the ranges for each bucket should be? The answers typically require a fair amount of experimentation.</p>
<p>See also <a href="./">B</a>, <a href="../s/#synthetic-feature">Synthetic Feature</a></p>
<h2 id="buffered-online-learning">Buffered Online Learning<a class="headerlink" href="#buffered-online-learning" title="Permanent link">#</a></h2>
<p>Of the two types (online / offline), <a href="../o/#online-learning-algorithm">online learning algorithms</a> are more general in that you can easily construct an offline algorithm from a strictly online one plus a stored <a href="../d/#dataset">dataset</a>, but the opposite is not true for a strictly <a href="../o/#offline-learning-algorithm">offline learning algorithm</a>. However, this does not necessarily make them superior - often compromises are made in terms of sample efficiency, CPU cost or accuracy when using an online algorithm. Approaches such as <a href="../m/#mini-batch">mini-batches</a> in neural network training can be viewed as attempts to find a middle ground between online and offline algorithms.</p>
<p><a href="../e/#experience-replay">Experience replay</a>, a common RL technique, used in <a href="../d/#deep-q-network-dqn">Deep Q-Networks</a> amongst others, is another in-between approach. Although you could store all the experience necessary to fully train an agent in theory, typically you store a rolling history and sample from it. It's possible to argue semantics about this, but I view the approach as being a kind of "buffered online", as it requires low-level components that can work online (e.g. neural networks for <a href="../d/#deep-q-network-dqn">DQN</a>).</p>
<p>More at:</p>
<ul>
<li><a href="https://ai.stackexchange.com/questions/10474/what-is-the-relation-between-online-or-offline-learning-and-on-policy-or-off">https://ai.stackexchange.com/questions/10474/what-is-the-relation-between-online-or-offline-learning-and-on-policy-or-off</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>
<h2 id="byte-pair-encoding-bpe-tokenization">Byte-Pair Encoding (BPE) Tokenization<a class="headerlink" href="#byte-pair-encoding-bpe-tokenization" title="Permanent link">#</a></h2>
<p>~ the <a href="../t/#tokenization">tokenization</a> algorithm used by <a href="../o/#openai-company">OpenAI</a>. You provide a training corpus and a vocabulary size. The algorithm will then find the optimum tokens.</p>
<p><img alt="" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Great tokenizer but heavy biased on English and space separated token (beware German, Chinese, etc.!) --&gt; <a href="../r/#receptance-weighted-key-value-rwkv-world-tokenizer">RWKV World Tokenizer</a></p>
<p>Byte-Pair Encoding (BPE) was initially developed as an algorithm to compress texts, and then used by <a href="../o/#openai-company">OpenAI</a> for <a href="../t/#tokenization">tokenization</a> when pretraining the <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT model</a>. Its used by a lot of <a href="../t/#transformer-architecture">Transformer</a> models, including GPT, [GPT-2], RoBERTa, BART, and DeBERTa.</p>
<iframe src="https://www.youtube.com/embed/HEikzVL-lZU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>Hugging Face course - <a href="https://huggingface.co/learn/nlp-course/chapter6/5">https://huggingface.co/learn/nlp-course/chapter6/5</a></li>
</ul>
<p>See also <a href="./">B</a>, ...</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../a/" class="md-footer__link md-footer__link--prev" aria-label="Previous: A">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                A
              </div>
            </div>
          </a>
        
        
          
          <a href="../c/" class="md-footer__link md-footer__link--next" aria-label="Next: C">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                C
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>