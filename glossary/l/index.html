
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/l/">
      
      
        <link rel="prev" href="../k/">
      
      
        <link rel="next" href="../m/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>L - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="L - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/l.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/l/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="L - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/l.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#l" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              L
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../g/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    L
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#l1-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#l2-loss" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#l2-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#label" class="md-nav__link">
    <span class="md-ellipsis">
      Label
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labeling-function" class="md-nav__link">
    <span class="md-ellipsis">
      Labeling Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labeling-service" class="md-nav__link">
    <span class="md-ellipsis">
      Labeling Service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labor-market-impact" class="md-nav__link">
    <span class="md-ellipsis">
      Labor Market Impact
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-expression-language-lcel" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Expression Language (LCEL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-hub" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Hub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langflow-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangFlow Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langgraph-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langgraph-studio" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph Studio
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langserve-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangServe Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langsmith-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangSmith Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Language AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-model" class="md-nav__link">
    <span class="md-ellipsis">
      Language Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-model-for-discussion-applications-lamda-model" class="md-nav__link">
    <span class="md-ellipsis">
      Language Model for Discussion Applications (LaMDA) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Language Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      Language Parsing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-processing-unit-lpu" class="md-nav__link">
    <span class="md-ellipsis">
      Language Processing Unit (LPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-and-vision-assistant-llava-model" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language and Vision Assistant (LLaVa) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-model-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Model (LLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-as-a-judge" class="md-nav__link">
    <span class="md-ellipsis">
      LLM As A Judge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-model-meta-ai-llama-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Model Meta AI (LLaMA) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-operating-system-llm-os" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Operating System (LLM OS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llmgraphtransformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      LLMGraphTransformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-operations-llmops" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Operations (LLMOps)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-performance-llmperf-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Performance (LLMPerf) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-pricing" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Pricing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-self-correction-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Self-Correction Reasoning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-scale-artificial-intelligence-open-network-laion-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Large-Scale Artificial Intelligence Open Network (LAION) Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Lasso Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso-regression-penalty" class="md-nav__link">
    <span class="md-ellipsis">
      Lasso Regression Penalty
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-diffusion-model-ldm" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Diffusion Model (LDM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-dirichlet-allocation-lda" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Dirichlet Allocation (LDA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-perturbation" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Perturbation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space-compression" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space Compression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space Visualization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-variable" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-variable-model" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Variable Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layer" class="md-nav__link">
    <span class="md-ellipsis">
      Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leakyrelu-lrelu-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      LeakyReLU (LReLU) Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-method" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-process" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Process
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Strategy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-vector-quantization-lvq-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Vector Quantization (LVQ) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-velocity" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Velocity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leave-one-out-cross-validation-loocv" class="md-nav__link">
    <span class="md-ellipsis">
      Leave-One-Out Cross-Validation (LOOCV)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#legendre-memory-unit-lmu" class="md-nav__link">
    <span class="md-ellipsis">
      Legendre Memory Unit (LMU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leopold-aschenbrenner-person" class="md-nav__link">
    <span class="md-ellipsis">
      Leopold Aschenbrenner Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lexical-search" class="md-nav__link">
    <span class="md-ellipsis">
      Lexical Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lidar" class="md-nav__link">
    <span class="md-ellipsis">
      LIDAR
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#light-gradient-boosting-machine-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      Light Gradient Boosting Machine (LightGBM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      Likelihood
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-algebra" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Algebra
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Autoencoder
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-discriminant-analysis-lda" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Discriminant Analysis (LDA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-temporal-logic" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Temporal Logic
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#link-prediction" class="md-nav__link">
    <span class="md-ellipsis">
      Link Prediction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linux-foundation-ai-and-data-lfaidata" class="md-nav__link">
    <span class="md-ellipsis">
      Linux Foundation AI And Data (LFAI&amp;Data)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#liquid-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Liquid AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#liquid-neural-network-lnn" class="md-nav__link">
    <span class="md-ellipsis">
      Liquid Neural Network (LNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#livebench-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      LiveBench Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-guard" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMa Guard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-adapter-model" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMA-Adapter Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llamaindex-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Llamaindex Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm-studio-application" class="md-nav__link">
    <span class="md-ellipsis">
      LM Studio Application
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lmsys-elo-rating-system" class="md-nav__link">
    <span class="md-ellipsis">
      LMSys Elo Rating System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-outlier-factor-lof" class="md-nav__link">
    <span class="md-ellipsis">
      Local Outlier Factor (LOF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-sensitive-hashing-lsh" class="md-nav__link">
    <span class="md-ellipsis">
      Local Sensitive Hashing (LSH)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Local Sensitive Hashing (LSH)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Log Loss Function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#log-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      Log Transformation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logical-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Logical Reasoning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression-logreg" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression (LogReg)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logit" class="md-nav__link">
    <span class="md-ellipsis">
      Logit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm-cell" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM) Cell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm-network" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM) Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#longformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Longformer Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#longformer-encoder-decoder-led" class="md-nav__link">
    <span class="md-ellipsis">
      Longformer-Encoder-Decoder (LED)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#look-ahead-planning" class="md-nav__link">
    <span class="md-ellipsis">
      Look-Ahead Planning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lora-exchange-lorax-serving" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA Exchange (LoRAX) Serving
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-graph" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-rank-adaptation-lora-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Rank Adaptation (LoRA) Fine-Tuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-rank-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Rank Approximation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwig-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Ludwig Framework
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../v/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#l1-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#l2-loss" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#l2-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#label" class="md-nav__link">
    <span class="md-ellipsis">
      Label
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labeling-function" class="md-nav__link">
    <span class="md-ellipsis">
      Labeling Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labeling-service" class="md-nav__link">
    <span class="md-ellipsis">
      Labeling Service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#labor-market-impact" class="md-nav__link">
    <span class="md-ellipsis">
      Labor Market Impact
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-expression-language-lcel" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Expression Language (LCEL)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-hub" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Hub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langflow-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangFlow Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langgraph-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langgraph-studio" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph Studio
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langserve-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangServe Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langsmith-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      LangSmith Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Language AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-model" class="md-nav__link">
    <span class="md-ellipsis">
      Language Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-model-for-discussion-applications-lamda-model" class="md-nav__link">
    <span class="md-ellipsis">
      Language Model for Discussion Applications (LaMDA) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      Language Modeling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      Language Parsing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#language-processing-unit-lpu" class="md-nav__link">
    <span class="md-ellipsis">
      Language Processing Unit (LPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-and-vision-assistant-llava-model" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language and Vision Assistant (LLaVa) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-model-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Model (LLM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-as-a-judge" class="md-nav__link">
    <span class="md-ellipsis">
      LLM As A Judge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-model-meta-ai-llama-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Model Meta AI (LLaMA) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-operating-system-llm-os" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Operating System (LLM OS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llmgraphtransformer-model" class="md-nav__link">
    <span class="md-ellipsis">
      LLMGraphTransformer Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-operations-llmops" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Operations (LLMOps)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-performance-llmperf-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Performance (LLMPerf) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-pricing" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Pricing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-self-correction-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Self-Correction Reasoning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-scale-artificial-intelligence-open-network-laion-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Large-Scale Artificial Intelligence Open Network (LAION) Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Lasso Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso-regression-penalty" class="md-nav__link">
    <span class="md-ellipsis">
      Lasso Regression Penalty
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-diffusion-model-ldm" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Diffusion Model (LDM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-dirichlet-allocation-lda" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Dirichlet Allocation (LDA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-perturbation" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Perturbation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space-compression" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space Compression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-space-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Space Visualization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-variable" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Variable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-variable-model" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Variable Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latent-vector" class="md-nav__link">
    <span class="md-ellipsis">
      Latent Vector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layer" class="md-nav__link">
    <span class="md-ellipsis">
      Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leakyrelu-lrelu-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      LeakyReLU (LReLU) Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-bias" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Bias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-method" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Method
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-process" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Process
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Strategy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-vector-quantization-lvq-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Vector Quantization (LVQ) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-velocity" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Velocity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leave-one-out-cross-validation-loocv" class="md-nav__link">
    <span class="md-ellipsis">
      Leave-One-Out Cross-Validation (LOOCV)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#legendre-memory-unit-lmu" class="md-nav__link">
    <span class="md-ellipsis">
      Legendre Memory Unit (LMU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#leopold-aschenbrenner-person" class="md-nav__link">
    <span class="md-ellipsis">
      Leopold Aschenbrenner Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lexical-search" class="md-nav__link">
    <span class="md-ellipsis">
      Lexical Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lidar" class="md-nav__link">
    <span class="md-ellipsis">
      LIDAR
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#light-gradient-boosting-machine-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      Light Gradient Boosting Machine (LightGBM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      Likelihood
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-algebra" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Algebra
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Autoencoder
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-discriminant-analysis-lda" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Discriminant Analysis (LDA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-temporal-logic" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Temporal Logic
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#link-prediction" class="md-nav__link">
    <span class="md-ellipsis">
      Link Prediction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linux-foundation-ai-and-data-lfaidata" class="md-nav__link">
    <span class="md-ellipsis">
      Linux Foundation AI And Data (LFAI&amp;Data)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#liquid-ai-company" class="md-nav__link">
    <span class="md-ellipsis">
      Liquid AI Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#liquid-neural-network-lnn" class="md-nav__link">
    <span class="md-ellipsis">
      Liquid Neural Network (LNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#livebench-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      LiveBench Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-guard" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMa Guard
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-adapter-model" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMA-Adapter Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llamaindex-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Llamaindex Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm-studio-application" class="md-nav__link">
    <span class="md-ellipsis">
      LM Studio Application
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lmsys-elo-rating-system" class="md-nav__link">
    <span class="md-ellipsis">
      LMSys Elo Rating System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-outlier-factor-lof" class="md-nav__link">
    <span class="md-ellipsis">
      Local Outlier Factor (LOF)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#local-sensitive-hashing-lsh" class="md-nav__link">
    <span class="md-ellipsis">
      Local Sensitive Hashing (LSH)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Local Sensitive Hashing (LSH)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log-loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Log Loss Function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#log-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      Log Transformation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logical-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Logical Reasoning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression-logreg" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression (LogReg)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logit" class="md-nav__link">
    <span class="md-ellipsis">
      Logit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm-cell" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM) Cell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#long-short-term-memory-lstm-network" class="md-nav__link">
    <span class="md-ellipsis">
      Long Short-Term Memory (LSTM) Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#longformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Longformer Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#longformer-encoder-decoder-led" class="md-nav__link">
    <span class="md-ellipsis">
      Longformer-Encoder-Decoder (LED)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#look-ahead-planning" class="md-nav__link">
    <span class="md-ellipsis">
      Look-Ahead Planning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lora-exchange-lorax-serving" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA Exchange (LoRAX) Serving
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-graph" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-rank-adaptation-lora-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Rank Adaptation (LoRA) Fine-Tuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-rank-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Rank Approximation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwig-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Ludwig Framework
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="l">L<a class="headerlink" href="#l" title="Permanent link">#</a></h1>
<h2 id="l1-regularization">L1 Regularization<a class="headerlink" href="#l1-regularization" title="Permanent link">#</a></h2>
<p>A type of <a href="../r/#regularization">regularization</a> that penalizes <a href="../w/#weight">weights</a> in proportion to the sum of the absolute value of the weights. L1 regularization helps drive the weights of irrelevant or barely relevant <a href="../f/#feature">features</a> to exactly 0. A <a href="../f/#feature">feature</a> with a weight of 0 is effectively removed from the model.</p>
<p>Contrast with <a href="./#l2-regularization">L2 regularization</a>.</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="l2-loss">L2 Loss<a class="headerlink" href="#l2-loss" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="l2-regularization">L2 Regularization<a class="headerlink" href="#l2-regularization" title="Permanent link">#</a></h2>
<p>A type of <a href="../r/#regularization">regularization</a> that penalizes weights in proportion to the sum of the squares of the <a href="../w/#weight">weights</a>. L2 regularization helps drive <a href="../o/#outlier">outlier</a> weights (those with high positive or low negative values) closer to 0 but not quite to 0. Features with values very close to 0 remain in the model but don't influence the model's <a href="../p/#prediction">prediction</a> very much.</p>
<p>L2 regularization always improves generalization in linear models.</p>
<p>Contrast with <a href="./#l1-regularization">L1 regularization</a>.</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="label">Label<a class="headerlink" href="#label" title="Permanent link">#</a></h2>
<p>~ think of your label as your model teacher!</p>
<p>~ the final prediction or decision the AI system makes</p>
<p>Name of a prediction in a supervised models. Correspond to a target attribute in unsupervised learning. Example of label: the agent-skill needed to result the customer's call.</p>
<p>In [supervised machine learning], the "answer" or "result" portion of an <a href="../e/#example">example</a>.</p>
<p>Each labeled example consists of one or more <a href="../f/#feature">features</a> and a label. For instance, in a spam detection dataset, the label would probably be either "spam" or "not spam." In a rainfall dataset, the label might be the amount of rain that fell during a certain period.</p>
<p>See also <a href="./">L</a>, <a href="../d/#data-point">Data Point</a>, <a href="./#labeling-function">Labeling Function</a>, <a href="../s/#supervised-learning">Supervised Learning</a>, <a href="../t/#target-attribute">Target Attribute</a></p>
<h2 id="labeling-function">Labeling Function<a class="headerlink" href="#labeling-function" title="Permanent link">#</a></h2>
<p>Use one or more function to label a sample. If you have more than one labeling function, use the majority rule, i.e. label the sample with the sample that has the maximum probability. <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> A label is an enum, not a probability. Used by snorkel.</p>
<p>See also <a href="./">L</a>, <a href="./#label">Label</a>, <a href="../s/#snorkel-program">Snorkel Program</a></p>
<h2 id="labeling-service">Labeling Service<a class="headerlink" href="#labeling-service" title="Permanent link">#</a></h2>
<p>Mechanical turk, crowd flower, instaML LOOP. Do you have the proper label? Have several people label the same image/entry and used the Dawid-Skene or majority vote algorithm!</p>
<p>See also <a href="./">L</a>, <a href="../d/#dawid-skene-algorithm">Dawid-Skene Algorithm</a>, <a href="../m/#majority-vote-algorithm">Majority Vote Algorithm</a>, [Unlabelled Data Algorithm]</p>
<h2 id="labor-market-impact">Labor Market Impact<a class="headerlink" href="#labor-market-impact" title="Permanent link">#</a></h2>
<p>We investigate the potential implications of <a href="./#large-language-model-llm">large language models (LLMs)</a>, such as <a href="../g/#generative-pre-trained-transformer-gpt-model-family">Generative Pre-trained Transformers (GPTs)</a>, on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. </p>
<p><strong>Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted</strong>.</p>
<p>We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.</p>
<iframe src="https://www.youtube.com/embed/ooqYC781HGE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2303.10130" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.10130">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>2024/03/04 - GenAI and NYC - <a href="https://www.mckinsey.com/industries/public-sector/our-insights/generative-ai-and-the-future-of-new-york">https://www.mckinsey.com/industries/public-sector/our-insights/generative-ai-and-the-future-of-new-york</a></li>
<li>2023/09/05 - <a href="https://www.cnn.com/2023/09/05/opinions/artificial-intelligence-jobs-labor-market">https://www.cnn.com/2023/09/05/opinions/artificial-intelligence-jobs-labor-market</a></li>
<li>2023/07/26 - GenAI and future of work - <a href="https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america">https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america</a></li>
<li>2023/06/21 - productivity frontier - <a href="https://www.mckinsey.com/featured-insights/mckinsey-live/webinars/the-economic-potential-of-generative-ai-the-next-productivity-frontier">https://www.mckinsey.com/featured-insights/mckinsey-live/webinars/the-economic-potential-of-generative-ai-the-next-productivity-frontier</a></li>
<li>2023/03/17 - Early look at impact - <a href="https://openai.com/research/gpts-are-gpts">https://openai.com/research/gpts-are-gpts</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langchain-expression-language-lcel">LangChain Expression Language (LCEL)<a class="headerlink" href="#langchain-expression-language-lcel" title="Permanent link">#</a></h2>
<p>How chains are built in <a href="./#langchain-python-module">LangChain</a>. DEsigned to build sequence of calls (to LLMs or any other component)</p>
<p>LCEL is a declarative way to compose chains of components. What does that mean? Means its an easy way to put useful building blocks together. Here's quick summary of the LangChain Expression Language (LCEL) page: - LCEL Basics: Simplifies building complex chains from basic components using a unified interface and composition primitives. - Unified Interface: Every LCEL object implements the Runnable interface, supporting common invocation methods like invoke, batch, stream, ainvoke, and more. - Composition Primitives: LCEL provides tools for composing chains, parallelizing components, adding fallbacks, and dynamically configuring internal chain elements. - Model Flexibility: LCEL allows for easy switching between different models and providers (like OpenAI or Anthropic), and runtime configurability of chat models or LLMs. - Advanced Features: LCEL features things like logging intermediate results with LangSmith integration and adding fallback logic for enhanced reliability.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>chain = prompt | model | output_parser
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>stream = stream back chuncks of the response
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>invoke = call the chain on an input
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>batch = call the chain on a list of inputs
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>runnable_protocol = standard interface to facilitate defining custom chains
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>input_schema = description of the inputs accepted by a Runnable
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>output_schema = description of the output produced by a Runnable
</span></code></pre></div>
<p>More at:</p>
<ul>
<li><a href="https://python.langchain.com/docs/expression_language/">https://python.langchain.com/docs/expression_language/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langchain-hub">LangChain Hub<a class="headerlink" href="#langchain-hub" title="Permanent link">#</a></h2>
<p>Taking inspiration from Hugging Face Hub, LangChainHub is collection of all artifacts useful for working with LangChain primitives such as prompts, chains and agents. The goal of this repository is to be a central resource for sharing and discovering high quality prompts, chains and agents that combine together to form complex LLM applications.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain</span><span class="w"> </span><span class="kn">import</span> <span class="n">hub</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">obj</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s2">&quot;homanp/superagent&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>More at;</p>
<ul>
<li>site - <a href="https://smith.langchain.com/hub">https://smith.langchain.com/hub</a></li>
<li>alternatives<ul>
<li><a href="https://docs.pezzo.ai/features/langchain">https://docs.pezzo.ai/features/langchain</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langchain-python-module">LangChain Python Module<a class="headerlink" href="#langchain-python-module" title="Permanent link">#</a></h2>
<p>~ an alternative to <a href="./#llamaindex-python-module">Llamaindex</a></p>
<p>LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also:</p>
<ul>
<li>Be data-aware: connect a language model to other sources of data</li>
<li>Be agentic: allow a language model to interact with its environment</li>
</ul>
<p>The LangChain framework is designed with the above principles in mind.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># Proprietary LLM from e.g. OpenAI</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="c1"># pip install openai</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.llms</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="c1"># Alternatively, open-source LLM hosted on Hugging Face</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># pip install huggingface_hub</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain</span><span class="w"> </span><span class="kn">import</span> <span class="n">HuggingFaceHub</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="n">llm</span> <span class="o">=</span> <span class="n">HuggingFaceHub</span><span class="p">(</span><span class="n">repo_id</span> <span class="o">=</span> <span class="s2">&quot;google/flan-t5-xl&quot;</span><span class="p">)</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="c1"># The LLM takes a prompt as an input and outputs a completion</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Alice has a parrot. What animal is Alice&#39;s pet?&quot;</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="n">completion</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="" src="../img/l/langchain_python_module_value_proposition.png" width="100%" /></p>
<p><img alt="" src="../img/l/langchain_python_module_components.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/nE2skSRWTTs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>announcement - <a href="https://www.pinecone.io/learn/langchain-intro/">https://www.pinecone.io/learn/langchain-intro/</a></li>
<li>docs - <a href="https://python.langchain.com/en/latest/index.html">https://python.langchain.com/en/latest/index.html</a></li>
<li>JS docs - <a href="https://js.langchain.com/docs/">https://js.langchain.com/docs/</a></li>
<li>tutorials</li>
<li>book - <a href="https://www.pinecone.io/learn/langchain/">https://www.pinecone.io/learn/langchain/</a></li>
<li>tuts - <a href="https://www.pinecone.io/learn/series/langchain/">https://www.pinecone.io/learn/series/langchain/</a></li>
<li>notebooks - <a href="https://github.com/pinecone-io/examples/tree/master/generation/langchain/handbook">https://github.com/pinecone-io/examples/tree/master/generation/langchain/handbook</a></li>
<li>articles</li>
<li><a href="https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c">https://towardsdatascience.com/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c</a></li>
<li>colabs</li>
<li>intro - <a href="https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/00-langchain-intro.ipynb">https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/00-langchain-intro.ipynb</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="./#langflow-python-module">LangFlow Python Module</a>, <a href="../v/#vector-database">Vector Database</a></p>
<h2 id="langflow-python-module">LangFlow Python Module<a class="headerlink" href="#langflow-python-module" title="Permanent link">#</a></h2>
<p>~ used to build no-code LangChain applications</p>
<p>LangFlow is an easy way to prototype <a href="./#langchain-python-module">LangChain</a> flows. The drag-and-drop feature allows quick and effortless experimentation, while the built-in chat interface facilitates real-time interaction. It provides options to edit prompt parameters, create chains and agents, track thought processes, and export flows.</p>
<iframe src="https://www.youtube.com/embed/sC9SV06gsDM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/-D1EIbKVlz8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>Alternatives</p>
<ul>
<li>Flowise - JS based</li>
</ul>
<p>More at:</p>
<ul>
<li>docs - <a href="https://docs.langflow.org/">https://docs.langflow.org/</a></li>
<li>huggin face space - <a href="https://huggingface.co/spaces/Logspace/Langflow">https://huggingface.co/spaces/Logspace/Langflow</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langgraph-python-module">LangGraph Python Module<a class="headerlink" href="#langgraph-python-module" title="Permanent link">#</a></h2>
<p>A state machine way to run agent with <a href="./#langchain-python-module">LangChain</a></p>
<p>To build custom agents and more than just simple chains</p>
<ul>
<li>state graph</li>
<li>nodes = chains or runnables/tools</li>
<li>edges = wire everything together<ul>
<li>conditional edges = <a href="./#large-language-model-llm">LLM</a> decides which node to go to next (tools)</li>
</ul>
</li>
<li>compile the graph so you can then run the graph!</li>
<li>&lt;!&gt; With memory, you can restart a graph from a particular state (instead of from the start)</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a> Invoke = Get the response from the LLM all at once
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>  * You cn also invoke a graph!!! where you pass parameters to a GraphState
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a> Stream = Get the response from the LLM in a streaming fashion (display or process as you receive characters)
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>  * 2 modes = value and updates
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    * value = full list every time
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    * update = only get the updates
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a> GraphState = Key value store
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>  * an object with attributes in python
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a> Node = Take a GraphState as input
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>  * Implemented as a python function
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>  * An execution in python
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>  * Get inputs from the state
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>  * Write outputs to the state or exteranl call (simple print)
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>  * can update the state (unlike edges)
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>  * Examples:
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>    * Generate a response node
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>    * Use external tools such as accesssing an external database
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>    * Hallucination checker
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a> Edge =
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>  * can be passed a state (which is immutable at the edge level?)
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a> GraphBuilder = The object used to build the execution graph
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>  * Add node
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>  * add edge (start and end node + link added nodes)
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>  * add conditional edge (if true, do that , otherwise does this other thing)
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>  * Not sure you can add nodes to existing graphs
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a> BinaryScore = output &quot;yes&quot; or &quot;no&quot; equivalent for branching conditions?
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a> Structured Output = formatted output
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a> Schema Override = reformat the output coming from the LangChain library or LLM (include input, output, document, number of iteration, etc)
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a> Human in the loop garantee &lt;-- a person must sign-off on an given action before execution
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a> Parallelisation = parallel execution
</span><span id="__span-3-41"><a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>
</span><span id="__span-3-42"><a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a> CustomState reducer = provide a function on how to update a state (maybe by adding the new value to a list instead of overriding a parameter&#39;s value)
</span><span id="__span-3-43"><a id="__codelineno-3-43" name="__codelineno-3-43" href="#__codelineno-3-43"></a>  * Used to handle state updates
</span><span id="__span-3-44"><a id="__codelineno-3-44" name="__codelineno-3-44" href="#__codelineno-3-44"></a>  * Frequently used in parallelization
</span><span id="__span-3-45"><a id="__codelineno-3-45" name="__codelineno-3-45" href="#__codelineno-3-45"></a>
</span><span id="__span-3-46"><a id="__codelineno-3-46" name="__codelineno-3-46" href="#__codelineno-3-46"></a> Agent vs Subagent = Top agent is router and subagent is responsible for execution and report to top agent at the end
</span><span id="__span-3-47"><a id="__codelineno-3-47" name="__codelineno-3-47" href="#__codelineno-3-47"></a>
</span><span id="__span-3-48"><a id="__codelineno-3-48" name="__codelineno-3-48" href="#__codelineno-3-48"></a> Graph Execution Pause = when a node fails
</span><span id="__span-3-49"><a id="__codelineno-3-49" name="__codelineno-3-49" href="#__codelineno-3-49"></a>
</span><span id="__span-3-50"><a id="__codelineno-3-50" name="__codelineno-3-50" href="#__codelineno-3-50"></a> Memory = used for multi-turn conversation (entire set of messages instead of just the last one)
</span><span id="__span-3-51"><a id="__codelineno-3-51" name="__codelineno-3-51" href="#__codelineno-3-51"></a>  * Can be done in in-memory, or externally with SQLite PostgreSQL, and other connectors to other databases
</span><span id="__span-3-52"><a id="__codelineno-3-52" name="__codelineno-3-52" href="#__codelineno-3-52"></a>
</span><span id="__span-3-53"><a id="__codelineno-3-53" name="__codelineno-3-53" href="#__codelineno-3-53"></a> Thread = how we separate users who are using the same application
</span><span id="__span-3-54"><a id="__codelineno-3-54" name="__codelineno-3-54" href="#__codelineno-3-54"></a>  * are identified with a Thread ID
</span><span id="__span-3-55"><a id="__codelineno-3-55" name="__codelineno-3-55" href="#__codelineno-3-55"></a>  * Used to find the proper memory in the memory store
</span><span id="__span-3-56"><a id="__codelineno-3-56" name="__codelineno-3-56" href="#__codelineno-3-56"></a>  * Id thread ID does not exist, Cstart with a new
</span><span id="__span-3-57"><a id="__codelineno-3-57" name="__codelineno-3-57" href="#__codelineno-3-57"></a>
</span><span id="__span-3-58"><a id="__codelineno-3-58" name="__codelineno-3-58" href="#__codelineno-3-58"></a> Long Term memory store = what is learned from the user and is available in every threads
</span><span id="__span-3-59"><a id="__codelineno-3-59" name="__codelineno-3-59" href="#__codelineno-3-59"></a>  * Used to profile users
</span></code></pre></div>
<iframe src="https://www.youtube.com/embed/PqS1kib7RTw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>docs - <a href="https://python.langchain.com/docs/langgraph">https://python.langchain.com/docs/langgraph</a></li>
<li>tutorials - <a href="https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238107-course-overview">https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238107-course-overview</a></li>
<li>articles<ul>
<li>CRAG - <a href="https://www.datacamp.com/tutorial/corrective-rag-crag">https://www.datacamp.com/tutorial/corrective-rag-crag</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langgraph-studio">LangGraph Studio<a class="headerlink" href="#langgraph-studio" title="Permanent link">#</a></h2>
<p>A visual debugger for <a href="./#langgraph-python-module">LangGraph</a> ==&gt; nicer UI to <a href="./#langsmith-python-module">LangSmith</a></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langserve-python-module">LangServe Python Module<a class="headerlink" href="#langserve-python-module" title="Permanent link">#</a></h2>
<p>For one-click deployments of LangChain applications</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="langsmith-python-module">LangSmith Python Module<a class="headerlink" href="#langsmith-python-module" title="Permanent link">#</a></h2>
<p>Observability stack from LangChain </p>
<p>3 areas:</p>
<ul>
<li>Tracing (input, state, retrieved documents, latency, final output) + tokens per LLM call + request costs</li>
<li>Prompt Engineering</li>
<li>...</li>
</ul>
<p><img alt="" src="../img/l/langsmith.png" width="100%" /></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="language-ai">Language AI<a class="headerlink" href="#language-ai" title="Permanent link">#</a></h2>
<p>See <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a></p>
<h2 id="language-model">Language Model<a class="headerlink" href="#language-model" title="Permanent link">#</a></h2>
<p>See <a href="./#language-modeling">Language Modeling</a></p>
<h2 id="language-model-for-discussion-applications-lamda-model">Language Model for Discussion Applications (LaMDA) Model<a class="headerlink" href="#language-model-for-discussion-applications-lamda-model" title="Permanent link">#</a></h2>
<p>Built by <a href="../g/#google-company">Google</a></p>
<p>Beware, cannot use GPU for inference. ??? &lt;== ????</p>
<iframe src="https://www.youtube.com/embed/7BvbgUNT2gI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/7BvbgUNT2gI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>blog - <a href="https://blog.google/technology/ai/lamda/">https://blog.google/technology/ai/lamda/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="language-modeling">Language Modeling<a class="headerlink" href="#language-modeling" title="Permanent link">#</a></h2>
<p>Language modeling is the task of assigning a probability to a sequence of words in a text in a specific language. Simple language models can look at a word and predict the next word (or words) most likely to follow it, based on statistical analysis of existing text sequences. To create a language model that successfully predicts word sequences, you need to train it on large sets of data. Language models are a key component in natural language processing applications. You can think of them as statistical prediction machines, where you give text as input and get a prediction as the output. You’re probably familiar with this from the auto-complete feature on your smartphone. For instance, if you type “good,” auto-complete might suggest “morning” or “luck.”</p>
<p>See also <a href="./">L</a>, <a href="./#language-model">Language Model</a>, <a href="./#large-language-model-llm">Large Language Model</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a>, [Small Language Model]</p>
<h2 id="language-parsing">Language Parsing<a class="headerlink" href="#language-parsing" title="Permanent link">#</a></h2>
<p>~ figuring out which group of words go together (as “phrases”) and which words are the subject or object of a verb. The NLP parser separates a series of text into smaller pieces based on the grammar rules. If a sentence that cannot be parsed may have grammatical errors.</p>
<p>See also <a href="./">L</a>, <a href="../b/#benchmark">Benchmark</a></p>
<h2 id="language-processing-unit-lpu">Language Processing Unit (LPU)<a class="headerlink" href="#language-processing-unit-lpu" title="Permanent link">#</a></h2>
<p>Developed by the founder of <a href="../g/#groq-company">Groq</a> to accelerate the token output of <a href="./#large-language-model-llm">LLM</a></p>
<p>Remember that game of Go in 2016 when <a href="../a/#alphago-model">AlphaGo</a> played against the world champion Lee Sedol and won? Well, about a month before the competition, there was a test game which AlphaGo lost. The researchers from <a href="../d/#deepmind-company">DeepMind</a> ported AlphaGo to <a href="../t/#tensor-processing-unit-tpu">Tensor Processing Unit (TPU)</a> and then the computer program was able to win by a wide margin.</p>
<p>The realization that computational power was a bottleneck for AI's potential led to the inception of Groq and the creation of the LPU. This realization came to Jonathan Ross who initially began what became TPU project in <a href="../g/#google-company">Google</a>. He started Groq in 2016.</p>
<p>The LPU is a special kind of computer brain designed to handle language tasks very quickly. Unlike other computer chips that do many things at once (parallel processing), the LPU works on tasks one after the other (sequential processing), which is perfect for understanding and generating language. Imagine it like a relay race where each runner (chip) passes the baton (data) to the next, making everything run super fast. The LPU is designed to overcome the two LLM bottlenecks: compute density and memory bandwidth.</p>
<p>Groq took a novel approach right from the start, focusing on software and compiler development before even thinking about the hardware. They made sure the software could guide how the chips talk to each other, ensuring they work together seamlessly like a team in a factory. This makes the LPU really good at processing language efficiently and at high speed, ideal for AI tasks that involve understanding or creating text.</p>
<p>This led to a highly optimized system that not only runs circles around traditional setups in terms of speed but does so with greater cost efficiency and lower energy consumption. This is big news for industries like finance, government, and tech, where quick and accurate data processing is key.</p>
<p>Now, don't go tossing out your <a href="../g/#graphical-processing-unit-gpu">GPUs</a> just yet! While the LPU is a beast when it comes to inference, making light work of applying trained models to new data, GPUs still reign supreme in the training arena. The LPU and GPU might become the dynamic duo of AI hardware, each excelling in their respective roles.</p>
<p>To better understand architecture, Groq offers two papers: from 2020 (Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning Workloads) and 2022 (A So ware-defined Tensor Streaming Multiprocessor for Large-scale Machine Learning). The term “LPU” must be a recent addition to Groq’s narrative, since it’s never mentioned in the papers.</p>
<p>More at:</p>
<ul>
<li><a href="https://wow.groq.com/groq-isca-paper-2020/">https://wow.groq.com/groq-isca-paper-2020/</a></li>
<li><a href="https://wow.groq.com/isca-2022-paper/">https://wow.groq.com/isca-2022-paper/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="large-language-and-vision-assistant-llava-model">Large Language and Vision Assistant (LLaVa) Model<a class="headerlink" href="#large-language-and-vision-assistant-llava-model" title="Permanent link">#</a></h2>
<p>An extension to the <a href="./#large-language-model-meta-ai-llama-model-family">LLaMA Model</a> to allow it to be multimodal or see.</p>
<p>Lava is a recently released multimodal model called Large Language and Vision Assistant. It can run multimodal tasks across both image and text inputs. Lava has shown promising performance in understanding and reasoning about images, generating HTML websites from wireframe sketches, and generating stories based on complex images. Its ability to process both visual and textual information sets it apart from traditional language models.</p>
<iframe src="https://www.youtube.com/embed/RxBSmbdJ1I8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>demo - <a href="https://llava.hliu.cc/">https://llava.hliu.cc/</a></li>
<li>code - <a href="https://github.com/haotian-liu/LLaVA">https://github.com/haotian-liu/LLaVA</a></li>
<li>project site - <a href="https://llava-vl.github.io/">https://llava-vl.github.io/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="large-language-model-llm">Large Language Model (LLM)<a class="headerlink" href="#large-language-model-llm" title="Permanent link">#</a></h2>
<p>Large Language Models are <a href="./#language-model">Language Model</a> with not millions, but billions of parameters/weights. The term "large" in LLM refers to the fact that these models are designed to handle large amounts of data, both in terms of the size of the text corpus used to train them and in terms of the amount of text they can generate or process at once.</p>
<p>In 2023, aftr the release of <a href="../c/#chatgpt-model">ChatGPT</a>, LLMs started having a huge <a href="./#labor-market-impact">impact on the labor force</a></p>
<p>These models typically utilize deep learning techniques and are trained on massive amounts of text data, such as books, articles, and web pages, in order to learn the patterns and structure of language.</p>
<p>Examples of Large Language Models include
  * <a href="../g/#generative-pre-trained-transformer-gpt-model-family">GPT-3</a>, [GPT-2]
  * <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT</a>
  * and [T5], among others.</p>
<p>These models have been used for a variety of tasks, such as <a href="../m/#machine-translation">language translation</a>, text generation, <a href="../q/#question-answering-qa">question answering</a>, and <a href="../s/#sentiment-analysis">sentiment analysis</a>, and have demonstrated impressive performance on many <a href="../b/#benchmark">benchmarks</a> in [natural language understanding] and generation.</p>
<p><img alt="" src="../img/l/large_language_model_history.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/StLtMcsbQes" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2303.18223" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.18223">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2303.18223">https://arxiv.org/abs/2303.18223</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="./#language-modeling">Language Modeling</a>, <a href="../m/#model-compression">Model Compression</a>, [Model Context Protocol], <a href="../n/#neural-scaling-law">Neural Scaling Law</a>, <a href="../s/#steerability">Steerability</a></p>
<h2 id="llm-as-a-judge">LLM As A Judge<a class="headerlink" href="#llm-as-a-judge" title="Permanent link">#</a></h2>
<p>Use a language model to compare 2 other <a href="./#large-language-model-llm">LLMs</a>. This approach is used in the <a href="../m/#multi-turn-question-set-benchmark-mt-bench">MT-Bench</a> to model human preference.</p>
<p><img alt="" src="../img/l/large_language_model_as_a_judge.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>code - <a href="https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge">https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge</a></li>
<li>articles<ul>
<li><a href="https://www.galileo.ai/blog/best-practices-for-creating-your-llm-as-a-judge">https://www.galileo.ai/blog/best-practices-for-creating-your-llm-as-a-judge</a></li>
<li><a href="https://www.galileo.ai/blog/tricks-to-improve-llm-as-a-judge">https://www.galileo.ai/blog/tricks-to-improve-llm-as-a-judge</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="large-language-model-meta-ai-llama-model-family">Large Language Model Meta AI (LLaMA) Model Family<a class="headerlink" href="#large-language-model-meta-ai-llama-model-family" title="Permanent link">#</a></h2>
<p>Using the scaling method described in <a href="../c/#chinchilla-model">Chinchilla</a>
 65 Billion parameters.</p>
<p>The model family includes:
  * LLaMA 1 (February 2023)
    * Came in four sizes: 7B, 13B, 33B, and 65B parameters.
    * Designed to be more efficient than GPT-3, using fewer resources while achieving strong performance.
    * Not publicly available as an API but accessible to researchers.
  * LLaMA 2 (July 2023)
    * Released as an open-source model, unlike LLaMA 1.
    * Included three sizes: 7B, 13B, and 70B parameters.
    * More training data and fine-tuning improvements over LLaMA 1.
    * Came with LLaMA 2-Chat, optimized for conversational tasks.
  * LLaMA 3 (Expected in 2024)
    * Meta has announced that LLaMA 3 will be released in 2024.
    * Expected to include larger models (possibly over 100B parameters).
    * Improved fine-tuning for safety, instruction-following, and efficiency.</p>
<iframe src="https://www.youtube.com/embed/E5OnoYF2oAk" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2302.13971" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2302.13971">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>LLaMa 3</li>
<li>LLaMa 2 <ul>
<li>UI - <a href="https://labs.perplexity.ai/">https://labs.perplexity.ai/</a></li>
<li>download - <a href="https://ollama.ai/">https://ollama.ai/</a></li>
</ul>
</li>
<li>LLaMa 1<ul>
<li>announcement - <a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">https://ai.facebook.com/blog/large-language-model-llama-meta-ai/</a></li>
<li>paper <a href="https://arxiv.org/abs/2302.13971">https://arxiv.org/abs/2302.13971</a></li>
<li>model card - <a href="https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md">https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md</a></li>
<li>model leak - <a href="https://www.vice.com/en/article/xgwqgw/facebooks-powerful-large-language-model-leaks-online-4chan-llama">https://www.vice.com/en/article/xgwqgw/facebooks-powerful-large-language-model-leaks-online-4chan-llama</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/LLaMA">https://en.wikipedia.org/wiki/LLaMA</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llm-operating-system-llm-os">LLM Operating System (LLM OS)<a class="headerlink" href="#llm-operating-system-llm-os" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li>articles<ul>
<li><a href="https://medium.com/@ronaldmannak/goodbye-windows-hello-llms-the-future-of-operating-systems-7ba61ea03e8d">https://medium.com/@ronaldmannak/goodbye-windows-hello-llms-the-future-of-operating-systems-7ba61ea03e8d</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, <a href="../m/#memgpt-model">MemGPT Model</a></p>
<h2 id="llmgraphtransformer-model">LLMGraphTransformer Model<a class="headerlink" href="#llmgraphtransformer-model" title="Permanent link">#</a></h2>
<p>~ Utility used to turn documents into a graph by using an <a href="./#large-language-model-llm">LLM</a> for [Name-Entity Recognition] and relationship extraction</p>
<p>More at:</p>
<ul>
<li>docs - <a href="https://python.langchain.com/v0.2/api_reference/experimental/graph_transformers/langchain_experimental.graph_transformers.llm.LLMGraphTransformer.html">https://python.langchain.com/v0.2/api_reference/experimental/graph_transformers/langchain_experimental.graph_transformers.llm.LLMGraphTransformer.html</a></li>
<li>articles<ul>
<li><a href="https://towardsdatascience.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59">https://towardsdatascience.com/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59</a></li>
<li>code - <a href="https://colab.research.google.com/github/tomasonjo/blogs/blob/master/llm/llm_graph_transformer_in_depth.ipynb">https://colab.research.google.com/github/tomasonjo/blogs/blob/master/llm/llm_graph_transformer_in_depth.ipynb</a></li>
</ul>
</li>
</ul>
<p>See also <a href="../t/">T</a>, <a href="../g/#graphrag-system">GraphRAG System</a></p>
<h2 id="llm-operations-llmops">LLM Operations (LLMOps)<a class="headerlink" href="#llm-operations-llmops" title="Permanent link">#</a></h2>
<ul>
<li>where you validate improvements over baseline</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llm-performance-llmperf-benchmark">LLM Performance (LLMPerf) Benchmark<a class="headerlink" href="#llm-performance-llmperf-benchmark" title="Permanent link">#</a></h2>
<p>Utilizing the LLMPerf, we have benchmarked a selection of LLM inference providers. Our analysis focuses on evaluating their performance, reliability, and efficiency under the following key metrics:</p>
<ul>
<li>Output tokens throughput, which represents the average number of output tokens returned per second. This metric is important for applications that require high throughput, such as summarization and translation, and easy to compare across different models and providers.</li>
<li>Time to first token (TTFT), which represents the duration of time that LLM returns the first token. TTFT is especially important for streaming applications, such as chatbots.</li>
</ul>
<p>The LLMPerf Leaderboard displays results in a clear, transparent manner. Our aim is to provide users and developers with vital insights into the capabilities and limitations of each provider, informing decisions for future integrations and deployments.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="w">   </span>python<span class="w"> </span>token_benchmark_ray.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">    </span>--model<span class="w"> </span>&lt;MODEL_NAME&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">    </span>--mean-input-tokens<span class="w"> </span><span class="m">550</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">    </span>--stddev-input-tokens<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="w">    </span>--mean-output-tokens<span class="w"> </span><span class="m">150</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="w">    </span>--stddev-output-tokens<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="w">    </span>--max-num-completed-requests<span class="w"> </span><span class="m">150</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="w">    </span>--num-concurrent-requests<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="w">    </span>--llm-api<span class="w"> </span>&lt;litellm/openai&gt;<span class="w"> </span>
</span></code></pre></div>
<p><img alt="" src="../img/l/large_language_model_performance.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>leaderboard - <a href="https://github.com/ray-project/llmperf-leaderboard">https://github.com/ray-project/llmperf-leaderboard</a></li>
<li>tool - <a href="https://github.com/ray-project/llmperf">https://github.com/ray-project/llmperf</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llm-pricing">LLM Pricing<a class="headerlink" href="#llm-pricing" title="Permanent link">#</a></h2>
<p>For each provider</p>
<ul>
<li>For each model<ul>
<li>Input cost for 1 million token</li>
<li>Output cost for 1 million token</li>
<li>[Tokenizer tax ] - Word to token ratio for submitted-input and generated-output text</li>
<li>[Prompt Tuning] - To get the desired output, the prompt needs to be wrapped with additional content (<a href="../s/#system-prompt">system prompt</a>, <a href="../f/#few-shot-prompting">few-shot prompting</a>, and etc.)</li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llm-self-correction-reasoning">LLM Self-Correction Reasoning<a class="headerlink" href="#llm-self-correction-reasoning" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/l/large_language_model_self_correction_reasoning.png" width="100%" /></p>
<object data="https://arxiv.org/pdf/2308.03188" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2308.03188">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2308.03188">https://arxiv.org/abs/2308.03188</a></li>
<li>github - <a href="https://github.com/teacherpeterpan/self-correction-llm-papers">https://github.com/teacherpeterpan/self-correction-llm-papers</a></li>
<li><a href="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/">https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/</a></li>
</ul>
<p>See also <a href="./">L</a>, ....</p>
<h2 id="large-scale-artificial-intelligence-open-network-laion-dataset">Large-Scale Artificial Intelligence Open Network (LAION) Dataset<a class="headerlink" href="#large-scale-artificial-intelligence-open-network-laion-dataset" title="Permanent link">#</a></h2>
<p>~ datasets used to build CLIP models and <a href="../o/#openclip-model">openclip</a></p>
<p>Open datasets released by the LAION Nonprofit organization</p>
<ul>
<li>LAION-400M - 400M English (image, text) pairs (2021)</li>
<li>LAION-5B - 5,85 billion CLIP-filtered image-text pairs (2022)</li>
<li>LAION-Aesthetics - several collections of subsets from LAION 5B with high visual quality</li>
</ul>
<p>More at:</p>
<ul>
<li>site - <a href="https://laion.ai/">https://laion.ai/</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/LAION">https://en.wikipedia.org/wiki/LAION</a> </li>
<li>articles<ul>
<li><a href="https://venturebeat.com/ai/a-free-ai-image-dataset-removed-for-child-sex-abuse-images-has-come-under-fire-before/">https://venturebeat.com/ai/a-free-ai-image-dataset-removed-for-child-sex-abuse-images-has-come-under-fire-before/</a></li>
</ul>
</li>
<li>sites<ul>
<li>400M - <a href="https://laion.ai/blog/laion-400-open-dataset/">https://laion.ai/blog/laion-400-open-dataset/</a></li>
<li>5B - <a href="https://laion.ai/blog/laion-5b/">https://laion.ai/blog/laion-5b/</a></li>
<li>aesthetics - <a href="https://laion.ai/blog/laion-aesthetics/">https://laion.ai/blog/laion-aesthetics/</a></li>
</ul>
</li>
<li>papers <ul>
<li>400M - <a href="https://arxiv.org/abs/2111.02114">https://arxiv.org/abs/2111.02114</a></li>
<li>5B - <a href="https://arxiv.org/abs/2210.08402">https://arxiv.org/abs/2210.08402</a></li>
</ul>
</li>
<li>tools<ul>
<li>source - <a href="https://github.com/LAION-AI/laion-datasets/tree/main">https://github.com/LAION-AI/laion-datasets/tree/main</a></li>
<li>brosing - <a href="https://rom1504.github.io/clip-retrieval/">https://rom1504.github.io/clip-retrieval/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="lasso-regression">Lasso Regression<a class="headerlink" href="#lasso-regression" title="Permanent link">#</a></h2>
<p>~ aka <a href="./#l1-regularization">L1 Regularization</a>. Instead of a <a href="./#linear-regression">linear regression</a> use this regression?</p>
<p>In lasso regression, weights can go to zero (not just close to 0 as in the <a href="../r/#ridge-regression">ridge regression</a>) and result in <a href="../f/#feature-selection">feature selection</a> !</p>
<p>Lasso regression is better than the <a href="../r/#ridge-regression">ridge regression</a> with models that contain a lot of useless variables.</p>
<iframe src="https://www.youtube.com/embed/VqKq78PVO9g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/NGf0voTMlcs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/Xm2C_gTAl8c" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/">https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="lasso-regression-penalty">Lasso Regression Penalty<a class="headerlink" href="#lasso-regression-penalty" title="Permanent link">#</a></h2>
<p>In a <a href="./#lasso-regression">lasso regression</a>, The term/bias added to the loss function to lower the <a href="../v/#variance">variance</a> (improve the prediction) due to the small number of samples in the training set.</p>
<p><img alt="" src="../img/l/lasso_regression_penalty.png" width="100%" /></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="latent-diffusion-model-ldm">Latent Diffusion Model (LDM)<a class="headerlink" href="#latent-diffusion-model-ldm" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/l/latent_diffusion_model.png" width="100%" /></p>
<p>The overall model will look like this:</p>
<ul>
<li>you will have your initial image here X, and encode it into an information-dense space called the latent space, Z. This is very similar to a GAN where you will use an encoder model to take the image and extract the most relevant information about it in a sub-space, which you can see as a downsampling task. Reducing its size while keeping as much information as possible.</li>
<li>You are now in the latent space with your condensed input. You then do the same thing with your conditioning inputs, either text, images, or anything else,</li>
<li>and merge them with your current image representation. WE condition LDMs either via concatenation or by a more general cross-attention mechanism. This attention mechanism will learn the best way to combine the input and conditioning inputs in this latent space. Adding attention, a transformer feature, to diffusion models. These merged inputs are now your initial noise for the diffusion process. Then, you have the same diffusion model I covered in my Imagen video but still in this sub-space.</li>
<li>Finally, you reconstruct the image using a decoder which you can see as the reverse step of your initial encoder. Taking this modified and de-noised input in the latent space to construct a final high-resolution image, basically upsampling your result.
 And voilà! This is how you can use diffusion models for a wide variety of tasks like super-resolution, inpainting, and even text-to-image with the recent stable diffusion open-sourced model through the conditioning process while being much more efficient and allowing you to run them on your GPUs instead of requiring hundreds of them. </li>
</ul>
<object data="https://arxiv.org/pdf/2112.10752" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2112.10752">Download PDF</a>.
    </p>
</object>

<iframe src="https://www.youtube.com/embed/RGBNdD3Wn-g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2112.10752">https://arxiv.org/abs/2112.10752</a></li>
<li><a href="https://pub.towardsai.net/latent-diffusion-models-the-architecture-behind-stable-diffusion-434ba7d91108">https://pub.towardsai.net/latent-diffusion-models-the-architecture-behind-stable-diffusion-434ba7d91108</a></li>
<li><a href="https://www.louisbouchard.ai/latent-diffusion-models/">https://www.louisbouchard.ai/latent-diffusion-models/</a></li>
<li><a href="https://github.com/CompVis/latent-diffusion">code - https://github.com/CompVis/latent-diffusion</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../c/#conditioning">Conditioning</a>, <a href="../c/#cross-attention">Cross-Attention</a>, <a href="../d/#diffusion-model-dm">Diffusion Model</a>, <a href="../d/#diffusion-process">Diffusion Process</a>, <a href="../i/#image-decoder">Image Decoder</a>, <a href="../i/#image-encoder">Image Encoder</a>, <a href="./#latent-space">Latent Space</a>, <a href="../p/#pixel-space">Pixel Space</a>, <a href="../u/#u-net-architecture">U-Net Architecture</a></p>
<h2 id="latent-dirichlet-allocation-lda">Latent Dirichlet Allocation (LDA)<a class="headerlink" href="#latent-dirichlet-allocation-lda" title="Permanent link">#</a></h2>
<p>Used as a topic modeling technique that is it can classify text in a document to a particular topic. It uses Dirichlet distribution to find topics for each document model and words for each topic model. Johann Peter Gustav Lejeune Dirichlet was a German mathematician in the 1800s who contributed widely to the field of modern mathematics. There is a probability distribution named after him ‘Dirichlet Distribution’ which is the basis of Latent Dirichlet Allocation (--LDA--).</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="latent-perturbation">Latent Perturbation<a class="headerlink" href="#latent-perturbation" title="Permanent link">#</a></h2>
<p>Used to find out what the latent variable are/mean in a latent variable model. <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> The model learns by itself that those are important variables based on the provided training sample. <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> The loss function defines what is learned and HOW it learns it! Latent perturbation is useful to see how entangled or disentangled latent variables are.</p>
<p>See also <a href="./">L</a>, <a href="../d/#disentangled-variational-autoencoder">Disentangled Variational Autoencoder</a>, <a href="./#latent-variable">Latent Variable</a>, <a href="./#latent-variable-model">Latent Variable Model</a></p>
<h2 id="latent-space">Latent Space<a class="headerlink" href="#latent-space" title="Permanent link">#</a></h2>
<p><mark>A compressed/downsampled space that contains as much information as possible space</mark>. </p>
<p>Formally, a latent space is defined as an abstract multi-dimensional space that encodes a meaningful internal representation of externally observed events. Samples that are similar in the external world are positioned close to each other in the latent space. To better understand the concept, let’s think about how humans perceive the world. We are able to understand a broad range of topics by encoding each observed event in a compressed representation in our brain. For example, we don’t keep in mind every detail of the appearance of a dog to be able to recognize a dog in the street. As we can see in the illustration below, we keep an internal representation of the general appearance of a dog:</p>
<p><img alt="" src="../img/l/latent_space_in_mind.png" width="100%" /></p>
<p>In a similar way, the latent space tries to provide a compressed understanding of the world to a computer through a spatial representation.
 Deep learning has revolutionized many aspects of our life with applications ranging from self-driving cars to predicting serious diseases. Its main goal is to transform the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. So, we realize that deep learning and latent space are strongly related concepts since the internal representations of the former constitute the latter. As we can see below, a deep learning model takes as input raw data and outputs discriminative features that lie in a low-dimensional space referred to as latent space. These features are then used to solve various tasks like classification, regression, or reconstruction:</p>
<p><img alt="" src="../img/l/latent_space.png" width="100%" /></p>
<p>To better understand the importance of latent space in deep learning, we should think of the following question: Why do we have to encode the raw data in a low-dimensional l atent space before classification, regression, or reconstruction?
 The answer is data compression. Specifically, in cases where our input data are high-dimensional, it is impossible to learn important information directly from the raw data. </p>
<p>More at:</p>
<ul>
<li><a href="https://ai.stackexchange.com/questions/11285/what-is-the-difference-between-latent-and-embedding-spaces">https://ai.stackexchange.com/questions/11285/what-is-the-difference-between-latent-and-embedding-spaces</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a>, <a href="../e/#encoder">Encoder</a>]<a href="./#latent-variable">Latent Variable</a>, <a href="./#latent-variable-model">Latent Variable Model</a>, <a href="./#latent-vector">Latent Vector</a>, <a href="../p/#pixel-space">Pixel Space</a>, <a href="../r/#representation-space">Representation Space</a>, <a href="../s/#semantic-space">Semantic Space</a>, <a href="../w/#word-embedding-space">Word Embedding Space</a></p>
<h2 id="latent-space-compression">Latent Space Compression<a class="headerlink" href="#latent-space-compression" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/NqmMnjJ6GEg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, <a href="../e/#encoder">Encoder</a>, <a href="./#latent-space">Latent Space</a></p>
<h2 id="latent-space-visualization">Latent Space Visualization<a class="headerlink" href="#latent-space-visualization" title="Permanent link">#</a></h2>
<p>Project a <a href="./#latent-space">latent space</a> or multi-dimensional space on 2D space</p>
<ul>
<li><a href="../p/#principal-component-analysis-pca">Principal Component Analysis (PCA)</a></li>
<li><a href="../t/#t-distributed-stochastic-neighbor-embedding-t-sne-algorithm">t-SNE</a></li>
<li><a href="../u/#uniform-manifold-approximation-and-projection-umap-algorithm">UMAP</a></li>
</ul>
<iframe src="https://www.youtube.com/embed/o_cAOa5fMhE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="latent-variable">Latent Variable<a class="headerlink" href="#latent-variable" title="Permanent link">#</a></h2>
<p>Myth of the cave = where observation are only a projection of other objects. Latent variables are not directly observable, but are the true explanatory factors (that are casting the shadows that we see !)</p>
<p><img alt="" src="../img/l/latent_variable.png" width="100%" /></p>
<p>See also <a href="./">L</a>, <a href="./#latent-space">Latent Space</a>, <a href="./#latent-variable-model">Latent Variable Model</a></p>
<h2 id="latent-variable-model">Latent Variable Model<a class="headerlink" href="#latent-variable-model" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, <a href="../a/#autoencoder">Autoencoder</a>, [Generative Adversarial Network], <a href="./#latent-space">Latent Space</a>, <a href="./#latent-variable">Latent Variable</a>, <a href="../v/#variational-autoencoder-vae">Variational Autoencoder</a></p>
<h2 id="latent-vector">Latent Vector<a class="headerlink" href="#latent-vector" title="Permanent link">#</a></h2>
<p>The input of a GAN acts as a latent vector since it encodes the output image \mathbf{G(z)} in a low-dimensional vector \mathbf{z}. To verify this, we can see how interpolation works in the latent space since we can handle specific attributes of the image by linearly modifying the latent vector. In the image below, we can see how we can handle the pose of a face by changing the latent vector of the GAN that generates it: </p>
<p><img alt="" src="../img/l/latent_vector.png" width="100%" /></p>
<p>See also <a href="./">L</a>, <a href="./#latent-space">Latent Space</a></p>
<h2 id="layer">Layer<a class="headerlink" href="#layer" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, <a href="../h/#hidden-layer">Hidden Layer</a>, <a href="../i/#input-layer">Input Layer</a>, <a href="../o/#output-layer">Output Layer</a></p>
<h2 id="leakyrelu-lrelu-activation-function">LeakyReLU (LReLU) Activation Function<a class="headerlink" href="#leakyrelu-lrelu-activation-function" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, <a href="../r/#rectified-linear-unit-relu-activation-function">ReLU Activation Function</a>, <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="learning-bias">Learning Bias<a class="headerlink" href="#learning-bias" title="Permanent link">#</a></h2>
<p>See <a href="../i/#inductive-bias">Inductive Bias</a></p>
<h2 id="learning-method">Learning Method<a class="headerlink" href="#learning-method" title="Permanent link">#</a></h2>
<p>All of those are or should be machine learning algorithm type! Here is a non-exhaustive list:</p>
<ul>
<li>experience - learn from the past/data</li>
<li><a href="../u/#unsupervised-learning">unsupervised learning</a> - try, fail, learn from failures ? Takes a long time / many iteration!<ul>
<li><a href="../a/#association-rule-learning">association rule learning</a> -</li>
</ul>
</li>
<li>[imitation learning] - clone behavior of experts &lt;== good to get started, but do you understand?</li>
<li><a href="../s/#supervised-learning">supervised learning</a> - with a teacher</li>
<li><a href="../r/#reinforcement-learning-rl">reinforcement learning</a> - reward-and-policy-based learning</li>
<li>[task-based learning] - focus on goal, use all of your skills to complete it and develop new ones (be motivated to find new skills)</li>
<li><a href="../f/#feedback-based-learning">feedback-based learning</a> - get feedback from the crowd (experts and non-experts), select the feedback you want -- always try your best --&gt; develop a persona</li>
<li><a href="../t/#transfer-learning">transfer learning</a> - priors + I learned that concept before, no need to relearn</li>
<li><a href="../w/#weak-supervised-learning">weak-supervised learning</a> - augment the data (i.e. create data!) which has been labeled (supervised)</li>
<li><a href="../s/#semi-supervised-learning">semi-supervised learning</a> - label existing data based on data that has been labeled</li>
<li><a href="../s/#self-supervised-learning-ssl">self-supervised learning</a> - acquire knowledge and skills through experiences and interactions without external feedback or instruction</li>
<li><a href="../c/#contrastive-learning">contrastive learning</a> - learning based on similarities and differences</li>
<li><a href="../a/#adaptive-learning">adaptive learning</a> - learning adapted to the learner's level and what has not yet been understood</li>
<li><a href="../c/#curriculum-learning">curriculum learning</a> - learning from simple to complex in order to learn faster and more efficiently.</li>
<li><a href="../f/#federated-learning">federated learning</a> - </li>
</ul>
<p>Drive to learn</p>
<ul>
<li><a href="../p/#purpose-learning">Purpose Learning</a> ~ human <a href="./#loss-function">Loss function</a> ?</li>
</ul>
<p>See also <a href="./">L</a>, <a href="../m/#machine-learning-type">Machine Learning Type</a></p>
<h2 id="learning-process">Learning Process<a class="headerlink" href="#learning-process" title="Permanent link">#</a></h2>
<ul>
<li>Changing weights in an ANN using backpropagation</li>
</ul>
<p>See also <a href="./">L</a>, <a href="../b/#backpropagation">Backpropagation</a></p>
<h2 id="learning-rate">Learning Rate<a class="headerlink" href="#learning-rate" title="Permanent link">#</a></h2>
<p>~ controls how rapidly the model learns/changes</p>
<div class="admonition note">
<p class="admonition-title">Often symbolized by 'alpha'</p>
</div>
<p>The learning rate <code>controls how rapidly the weights and biases of each network are updated during training</code>. A higher learning rate might allow the network to explore a wider set of model weights, but might pass over more optimal weights. Iterative learning: (1) observe difference between predicted answer, and correct answer. (2) Adjust the model a 'small amount' (at each pass /epoch) to make the prediction closer to the correct answer. Size of update at each iteration. Relative weight of new iteration vs old iterations?</p>
<p>The learning rate is impacted differently function of the ML algorithm in use</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>new_value = expected_value + alpha * ( observed_error )
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>          = expected_value + alpha * ( observed_value - expected_value)
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>          = (1 - alpha) * expected_value + alpha * observed_value
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>with alpha = learning_rate
</span></code></pre></div>
<p>In <a href="../r/#reinforcement-learning-rl">reinforcement learning</a>, more specifically in Q-learning, the learning rate is used as follow:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a># Q-Learning
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>Q_new = (1 - alpha) * Q_old + alpha * Q_learned
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a># From state, go to next_state
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a># Q_old = value in the Q-table for the state-action pair
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a># Q_learned = computed value in the Q-table for the state-action pair given the latest action
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>            = R_t+1 + gamma * optimized_Q_value(next_state)               &lt;== next state is known &amp; next-state Q-values are known
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>            = R_t+1 + gamma * max( Q_current(next_state, action_i) )
</span></code></pre></div>
<div class="admonition note">
<ul>
<li>the learning rate, alpha, is between 0 and 1</li>
<li>if alpha = 1  ==&gt; immediately forget the past!</li>
<li>if alpha = 0  ==&gt; oblivious to observation = no change!</li>
<li>A starting value can be between 0.01 and 0.1 which implies that updates with be between 1% and 10% of the observed error.</li>
</ul>
</div>
<p>See also <a href="./">L</a>, [Gradient Descent Algorithm], <a href="../h/#hyperparameter">Hyperparameter</a>, <a href="./#loss-function">Loss Function</a>, <a href="../p/#prior">Prior</a>, <a href="../t/#transfer-learning">Transfer Learning</a></p>
<h2 id="learning-strategy">Learning Strategy<a class="headerlink" href="#learning-strategy" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, <a href="./#learning-method">Learning Method</a>, <a href="./#learning-rate">Learning Rate</a>, <a href="./#learning-velocity">Learning Velocity</a></p>
<h2 id="learning-vector-quantization-lvq-algorithm">Learning Vector Quantization (LVQ) Algorithm<a class="headerlink" href="#learning-vector-quantization-lvq-algorithm" title="Permanent link">#</a></h2>
<p>Clustering algorithm used in <a href="../u/#unsupervised-learning">unsupervised learning</a>.</p>
<iframe src="https://www.youtube.com/embed/iq8aFkZo67o" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="learning-velocity">Learning Velocity<a class="headerlink" href="#learning-velocity" title="Permanent link">#</a></h2>
<p>How fast you learn to execute a task.</p>
<p>See also <a href="./">L</a>, <a href="./#learning-rate">Learning Rate</a>, [Sample Strategy], <a href="../s/#sample-efficiency">Sample Efficiency</a></p>
<h2 id="leave-one-out-cross-validation-loocv">Leave-One-Out Cross-Validation (LOOCV)<a class="headerlink" href="#leave-one-out-cross-validation-loocv" title="Permanent link">#</a></h2>
<p>A special case of [k-fold cross-validation] is the Leave-one-out cross-validation (LOOCV) method in which we set k=n (number of observations in the dataset). Only one training sample is used for testing during each iteration. This method is very useful when working with very small datasets.</p>
<p>More at:</p>
<ul>
<li><a href="https://machinelearningmastery.com/k-fold-cross-validation/">https://machinelearningmastery.com/k-fold-cross-validation/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="legendre-memory-unit-lmu">Legendre Memory Unit (LMU)<a class="headerlink" href="#legendre-memory-unit-lmu" title="Permanent link">#</a></h2>
<p>~ a memory unit in <a href="../r/#recurrent-neural-network-rnn">RNNs</a> ?</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="leopold-aschenbrenner-person">Leopold Aschenbrenner Person<a class="headerlink" href="#leopold-aschenbrenner-person" title="Permanent link">#</a></h2>
<p>Wrote an essay called situational awareness which compare the future of AI to the Manhattan project and competition with China</p>
<iframe src="https://www.youtube.com/embed/zdbVtZIn9IM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/xm1B3Y3ypoE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://situational-awareness.ai/">https://situational-awareness.ai/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="lexical-search">Lexical Search<a class="headerlink" href="#lexical-search" title="Permanent link">#</a></h2>
<p>Word matching. Keyword search or exact phrase.</p>
<p>Algorithms:</p>
<ul>
<li>Rabin-Karp</li>
<li>Bayer-Moore</li>
<li>Knuth-Morris-Pratt</li>
</ul>
<p><img alt="" src="../img/l/lexical_search_problem.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/au59-CEPegg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, <a href="../s/#semantic-search">Semantic Search</a></p>
<h2 id="lidar">LIDAR<a class="headerlink" href="#lidar" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, <a href="../a/#autonomous-vehicle">Autonomous Vehicle</a></p>
<h2 id="light-gradient-boosting-machine-lightgbm">Light Gradient Boosting Machine (LightGBM)<a class="headerlink" href="#light-gradient-boosting-machine-lightgbm" title="Permanent link">#</a></h2>
<p>An <a href="../e/#ensemble-method">ensemble method</a>.</p>
<p>LightGBM, short for light gradient-boosting machine, is a free and open-source distributed gradient-boosting framework for machine learning, originally developed by Microsoft. It is based on <a href="../d/#decision-tree">Decision tree algorithms</a> and used for ranking, <a href="../c/#classification-task">classification</a> and other machine learning tasks. The development focus is on performance and scalability.</p>
<object data="https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf">Download PDF</a>.
    </p>
</object>

<iframe src="https://www.youtube.com/embed/R5FB1ZUejXM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>docs - <a href="https://lightgbm.readthedocs.io/en/latest/index.html">https://lightgbm.readthedocs.io/en/latest/index.html</a></li>
<li>code - <a href="https://github.com/microsoft/LightGBM">https://github.com/microsoft/LightGBM</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/LightGBM">https://en.wikipedia.org/wiki/LightGBM</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="likelihood">Likelihood<a class="headerlink" href="#likelihood" title="Permanent link">#</a></h2>
<p>Another word for a probability in a discrete space/word/exercise</p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="linear-activation-function">Linear Activation Function<a class="headerlink" href="#linear-activation-function" title="Permanent link">#</a></h2>
<p>It is a simple straight-line <a href="../a/#activation-function">activation function</a> which is directly proportional to the input i.e. the weighted sum of neurons. It has the equation:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>f(x) = kx
</span></code></pre></div>
<p>where k is a constant.</p>
<p><img alt="" src="../img/l/linear_activation_function.png" width="100%" /></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="linear-algebra">Linear Algebra<a class="headerlink" href="#linear-algebra" title="Permanent link">#</a></h2>
<p>Math where you do NOT have square, cubes, etc.</p>
<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Linear_algebra">https://en.wikipedia.org/wiki/Linear_algebra</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="linear-autoencoder">Linear Autoencoder<a class="headerlink" href="#linear-autoencoder" title="Permanent link">#</a></h2>
<p>Let’s first suppose that both our encoder and decoder architectures have only one layer without non-linearity (linear autoencoder). Such encoder and decoder are then simple linear transformations that can be expressed as matrices. In such situation, we can see a clear link with PCA in the sense that, just like PCA does, we are looking for the best linear subspace (hidden state?) to project data on with as few information loss as possible when doing so. Encoding and decoding matrices obtained with PCA define naturally one of the solutions we would be satisfied to reach by gradient descent, but we should outline that this is not the only one.</p>
<p>See also <a href="./">L</a>, <a href="../a/#autoencoder">Autoencoder</a>, <a href="../p/#principal-component-analysis-pca">Principal Component Analysis</a></p>
<h2 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)<a class="headerlink" href="#linear-discriminant-analysis-lda" title="Permanent link">#</a></h2>
<p>Linear Discriminant Analysis(or LDA for short) was proposed by Ronald Fisher which is a Supervised Learning algorithm. It means that you must use both features and labels of data to reduce dimension while [Principal Component Analysis (PCA)<a href="../p/#principal-component-analysis-pca">PCA</a> only uses features. Another key point : the purpose of LDA is to find a new space in which reduced-dimension dataset is good for classification task. To meet this goal, LDA uses 2 metrics: Within-class variance and Between-class variance. The core idea is quite straightforward: finding vectors w which maximize the distance between mean vectors of 2 classes and minimize the variance within each class. A little bit explanation: within-class variance stands for scatter. The smaller this quantity, the lower data points scatter and vice versa. We want to classify classes, of course we have to maximize the distance between each class, that's why maximizing distance between mean vectors. However, we also need to take into account the scatter of data.The greater the within-class variance, the more data points of 2 classes overlap and it culminates in bad result for classification. Now you know why we need to minimize the scatter.</p>
<p>More at:</p>
<ul>
<li>PCA vs LDA - <a href="https://iq.opengenus.org/pca-vs-lda/">https://iq.opengenus.org/pca-vs-lda/</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../d/#dimensionality-reduction">Dimensionality Reduction</a>, <a href="../r/#retrieval-based-model">Retrieval Model</a></p>
<h2 id="linear-programming">Linear Programming<a class="headerlink" href="#linear-programming" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/Bzzqx1F23a8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, <a href="../o/#objective-function">Objective Function</a></p>
<h2 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">#</a></h2>
<p>Find an equation. Best fit. Ex: <a href="https://www.desmos.com/calculator/fmhotfn3qm">https://www.desmos.com/calculator/fmhotfn3qm</a>.</p>
<p>Not how long it will take for my car to stop given my speed (linear regression), but whether I am going to hit the tree or not (logistic regression).</p>
<p><img alt="" src="../img/l/linear_regression.png" width="100%" /></p>
<p>Sample code:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">linear_model</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="n">regr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="nb">print</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">)</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="nb">print</span> <span class="n">regr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></code></pre></div>
<p>More at :</p>
<ul>
<li>simulation <a href="https://setosa.io/ev/ordinary-least-squares-regression/">https://setosa.io/ev/ordinary-least-squares-regression/</a></li>
<li>introduction - <a href="https://towardsdatascience.com/linear-regression-the-actually-complete-introduction-67152323fcf2">https://towardsdatascience.com/linear-regression-the-actually-complete-introduction-67152323fcf2</a></li>
<li>code - <a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html">https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../c/#classification-task">Classification</a>, <a href="../m/#multiple-linear-regression">Multiple Linear Regression</a>, <a href="../n/#non-linear-regression">Non-Linear Regression</a>, <a href="../p/#prediction-error">Prediction Error</a>, <a href="../r/#regression-task">Regression</a></p>
<h2 id="linear-temporal-logic">Linear Temporal Logic<a class="headerlink" href="#linear-temporal-logic" title="Permanent link">#</a></h2>
<p>Temporal logic is a subfield of mathematical logic that deals with reasoning about time and the temporal relationships between events. In artificial intelligence, temporal logic is used as a formal language to describe and reason about the temporal behavior of systems and processes.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/aritificial-intelligence-temporal-logic/">https://www.geeksforgeeks.org/aritificial-intelligence-temporal-logic/</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/Linear_temporal_logic">https://en.wikipedia.org/wiki/Linear_temporal_logic</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="link-prediction">Link Prediction<a class="headerlink" href="#link-prediction" title="Permanent link">#</a></h2>
<p>There are many ways to solve problems in <a href="../r/#recommendation-engine">recommendation engines</a>. These solutions range from algorithmic approaches, link prediction algorithms, embedding based solutions, etc. Link prediction is also referred to as graph completion, a common problem in graph theory. In the simplest form, given a network, you want to know if there should be an edge between a pair of nodes. This definition changes slightly depending on the type of network you’re working with. A directed / multi graph can have slightly different interpretations but the fundamental concept of identifying missing edges in a network remains.</p>
<p><img alt="" src="../img/l/link_prediction.webp" width="100%" /></p>
<p>Problems in link prediction are also quite common when dealing with temporal networks (networks which change over time). Given a network G at time step t, you would want to predict the edges of the graph G at time step t+1.</p>
<iframe src="https://www.youtube.com/embed/kq_b0QmxFCI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/link-prediction-recommendation-engines-with-node2vec-c97c429351a8">https://towardsdatascience.com/link-prediction-recommendation-engines-with-node2vec-c97c429351a8</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="linux-foundation-ai-and-data-lfaidata">Linux Foundation AI And Data (LFAI&amp;Data)<a class="headerlink" href="#linux-foundation-ai-and-data-lfaidata" title="Permanent link">#</a></h2>
<p>The mission of LF AI &amp; Data is to build and support an open artificial intelligence (AI) and data community, and drive open source innovation in the AI and data domains by enabling collaboration and the creation of new opportunities for all the members of the community.</p>
<p>Projects</p>
<ul>
<li>Graduated</li>
<li>[Milvus Database]</li>
<li><a href="../o/#open-neural-network-exchange-onnx-format">ONNX Format</a></li>
<li>Egeria, Flyte, Horovod, Pyro</li>
<li>Incubation</li>
<li>Sandbox</li>
</ul>
<p>More at:</p>
<ul>
<li>site - <a href="https://lfaidata.foundation/">https://lfaidata.foundation/</a> </li>
<li>projects - <a href="https://lfaidata.foundation/projects/">https://lfaidata.foundation/projects/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="liquid-ai-company">Liquid AI Company<a class="headerlink" href="#liquid-ai-company" title="Permanent link">#</a></h2>
<p>an MIT spinoff led by robotics expert Daniela Rus, is developing a new type of AI dubbed [liquid neural networks]. These networks, smaller and less resource-intensive than traditional AI models, draw inspiration from the simple neural structures of roundworms. They excel in processing sequential data and adapting to new circumstances, making them suitable for tasks such as autonomous navigation and analyzing variable phenomena. Having raised $37.5 million in seed funding, Liquid AI intends to commercialize these networks by offering a platform for customers to create their own models and providing on-premises AI infrastructure.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.liquid.ai/">https://www.liquid.ai/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="liquid-neural-network-lnn">Liquid Neural Network (LNN)<a class="headerlink" href="#liquid-neural-network-lnn" title="Permanent link">#</a></h2>
<p>We introduce a new class of time-continuous recurrent neural network models. Instead of declaring a learning system's dynamics by implicit nonlinearities, we construct networks of linear first-order dynamical systems modulated via nonlinear interlinked gates. The resulting models represent dynamical systems with varying (i.e., liquid) time-constants coupled to their hidden state, with outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics and compute their expressive power by the trajectory length measure in latent trajectory space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to classical and modern RNNs. </p>
<p>{% youtube "<a href="https://youtu.be/0FNkrjVIcuk?si=I35p6esxM83rYsLf">https://youtu.be/0FNkrjVIcuk?si=I35p6esxM83rYsLf</a>" %}</p>
<iframe src="https://www.youtube.com/embed/ql3ETcRDMEM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2006.04439">https://arxiv.org/abs/2006.04439</a></li>
<li>code - <a href="https://github.com/raminmh/liquid_time_constant_networks">https://github.com/raminmh/liquid_time_constant_networks</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="livebench-benchmark">LiveBench Benchmark<a class="headerlink" href="#livebench-benchmark" title="Permanent link">#</a></h2>
<p>a benchmark for LLMs designed with test set contamination and objective evaluation in mind. It has the following properties:
  * LiveBench is designed to limit potential contamination by releasing new questions monthly, as well as having questions based on recently-released datasets, arXiv papers, news articles, and IMDb movie synopses.
  * Each question has verifiable, objective ground-truth answers, allowing hard questions to be scored accurately and automatically, without the use of an LLM judge.
  * LiveBench currently contains a set of 18 diverse tasks across 6 categories, and we will release new, harder tasks over time.</p>
<p>Questions cover:</p>
<ul>
<li>Math</li>
<li>Reasoning</li>
<li>Language</li>
<li>Coding</li>
<li>Data Analysis</li>
<li>Instruction Following (IF)</li>
</ul>
<object data="https://arxiv.org/pdf/2406.19314" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2406.19314">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://livebench.ai/">https://livebench.ai/</a></li>
<li>leaderboard - <a href="https://livebench.ai/#/">https://livebench.ai/#/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2406.19314">https://arxiv.org/abs/2406.19314</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llama-guard">LLaMa Guard<a class="headerlink" href="#llama-guard" title="Permanent link">#</a></h2>
<object data="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.2365-6/408725049_3688557441468029_8103913771964668529_n.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.2365-6/408725049_3688557441468029_8103913771964668529_n.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/">https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llama-adapter-model">LLaMA-Adapter Model<a class="headerlink" href="#llama-adapter-model" title="Permanent link">#</a></h2>
<p>We present LLaMA-Adapter, a lightweight adaption method to efficiently fine-tune <a href="./#large-language-model-meta-ai-llama-model-family">LLaMA</a> into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the input text tokens at higher transformer layers. Then, a zero-init attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With efficient training, LLaMA-Adapter generates high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Furthermore, our approach can be simply extended to multi-modal input, e.g., images, for image-conditioned <a href="./#large-language-model-meta-ai-llama-model-family">LLaMa</a>, which achieves superior reasoning capacity on <a href="../s/#scienceqa-dataset">ScienceQA</a>.</p>
<object data="https://arxiv.org/pdf/2303.16199" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.16199">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2303.16199">https://arxiv.org/abs/2303.16199</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="llamaindex-python-module">Llamaindex Python Module<a class="headerlink" href="#llamaindex-python-module" title="Permanent link">#</a></h2>
<p>~ an alternative to <a href="./#langchain-python-module">LangChain</a></p>
<iframe src="https://www.youtube.com/embed/CDfpJp8IpV8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="lm-studio-application">LM Studio Application<a class="headerlink" href="#lm-studio-application" title="Permanent link">#</a></h2>
<p>Discover, download, and run local LLMs. An alternative to <a href="../o/#ollama-command-line">Ollama</a></p>
<p>More at:</p>
<ul>
<li>site - <a href="https://lmstudio.ai/">https://lmstudio.ai/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="lmsys-elo-rating-system">LMSys Elo Rating System<a class="headerlink" href="#lmsys-elo-rating-system" title="Permanent link">#</a></h2>
<p>~ <a href="../e/#elo-rating-system">Elo Rating</a> for <a href="./#large-language-model-llm">LLM</a></p>
<p><img alt="" src="../img/l/lmsys_elo_rating_system.png" width="100%" /></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="local-outlier-factor-lof">Local Outlier Factor (LOF)<a class="headerlink" href="#local-outlier-factor-lof" title="Permanent link">#</a></h2>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="local-sensitive-hashing-lsh">Local Sensitive Hashing (LSH)<a class="headerlink" href="#local-sensitive-hashing-lsh" title="Permanent link">#</a></h2>
<p>~ an algorithm used in <a href="../s/#similarity-search">similarity search</a></p>
<p>a set of methods that is used to reduce the search scope by transforming data vectors into hash values while preserving information about their similarity.</p>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/similarity-search-part-5-locality-sensitive-hashing-lsh-76ae4b388203">https://towardsdatascience.com/similarity-search-part-5-locality-sensitive-hashing-lsh-76ae4b388203</a></li>
<li><a href="https://srivatssan.medium.com/locality-sensitive-hashing-e70985c4e95d">https://srivatssan.medium.com/locality-sensitive-hashing-e70985c4e95d</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h3 id="log-loss-function">Log Loss Function<a class="headerlink" href="#log-loss-function" title="Permanent link">#</a></h3>
<p>See [Binary Cross-Entropy Loss Function]</p>
<h2 id="log-transformation">Log Transformation<a class="headerlink" href="#log-transformation" title="Permanent link">#</a></h2>
<p>A <a href="../f/#feature-distribution-transformation">Feature Distribution Transformation</a></p>
<iframe src="https://www.youtube.com/embed/LCDiQxB5S84" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="logical-reasoning">Logical Reasoning<a class="headerlink" href="#logical-reasoning" title="Permanent link">#</a></h2>
<p>If-then-else rules used in <a href="../e/#expert-system">expert systems</a></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a># Knowledge base
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>All men are mortal
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a># Input
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>Aristotle is a men
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a># Inference
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>==&gt;
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a># New fact
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>Aristotle is mortal!
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a># If Aristotle is man AND all men are mortal, then Aritotle is mortal!
</span></code></pre></div>
<p>Ex: personal assistant with memory and can infer from dialog new things (i.e graph network?) !</p>
<p>See also <a href="./">L</a>, <a href="../r/#reasoning">Reasoning</a></p>
<h2 id="logistic-regression-logreg">Logistic Regression (LogReg)<a class="headerlink" href="#logistic-regression-logreg" title="Permanent link">#</a></h2>
<p>Not how long it will take for my car to stop given my speed (<a href="./#linear-regression">linear regression</a>), but whether I am going to hit the tree or not (logistic regression). used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc... Each object being detected in the image would be assigned a probability between 0 and 1 and the sum adding to one.</p>
<p><img alt="" src="../img/l/logistic_regression_data.png" width="100%" /></p>
<p><img alt="" src="../img/l/logistic_regression_fitting.png" width="100%" /></p>
<p>Beware:</p>
<ul>
<li>To turn a probability into a <a href="../c/#classification-task">classification</a>, we need to use a threshold (if P&gt;0.3 or P&lt;0.3 then ...)!</li>
<li>What about using a different P threshold? ==&gt; multiple confusion matrix ==&gt; <a href="../r/#receiver-operating-characteristic-roc-curve">ROC Curve</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../m/#ml-algorithm-evaluation">ML Algorithm Evaluation</a>, <a href="../r/#regression-task">Regression</a></p>
<h2 id="logit">Logit<a class="headerlink" href="#logit" title="Permanent link">#</a></h2>
<p>~ value before the activation function? Logit is unbounded, it can take any value</p>
<p>A "logit" typically refers to the log-odds ratio in statistics and logistic regression. In binary logistic regression, the logistic function is used to model the probability that a given instance belongs to a particular category. The logit function, denoted as "logit," is the natural logarithm of the <a href="../o/#odds">odds</a> that an event will occur, expressed as:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a> logit(p) = log(p/(1-/p))     &lt;-- log of the odds
</span></code></pre></div>
<p>where  p is the probability of the event occurring. The logit function transforms the probability scale (which ranges from 0 to 1) to the log-odds scale (which ranges from negative infinity to positive infinity). This transformation is useful because it allows linear modeling of the relationship between predictor variables and the log-odds of the event.</p>
<p>The logistic regression model can be expressed as:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a> logit(p)= β0 + β1.x1 + β 2.x2 + ... + β n.xn
</span></code></pre></div>
<p>Here β0, β1, ..., βn are coefficients, and x1, x2, ..., xn are the predictor variables. The goal of logistic regression is to estimate the coefficients that maximize the likelihood of the observed data.</p>
<p>In summary, the logit is a mathematical function used in logistic regression to model the relationship between predictor variables and the log-odds of an event occurring.</p>
<iframe src="https://www.youtube.com/embed/ARfXDSkQf1Y" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="long-short-term-memory-lstm-cell">Long Short-Term Memory (LSTM) Cell<a class="headerlink" href="#long-short-term-memory-lstm-cell" title="Permanent link">#</a></h2>
<ul>
<li>overview</li>
<li>input signal = previous state + new info</li>
<li>blue activation function = sigmoid activation function = switch (keep or forget, impact or no-impact)</li>
<li>red activation function = tanh --&gt; add, no effect, or substract</li>
<li>cell state = highway that transfers information down to the sequence chain = memory of the network</li>
<li>gates</li>
<li>forget gate = decide which information should be thrown (=0) out or kept (=1) away (information = previous state + new input info) (sigmoid = 1 --&gt; keep or = 0 forget!)</li>
<li>input gate = update the cell state with (transformed) input signal</li>
<li>output gate used to compute the hidden state = tanh(cell state) gated by input signal</li>
</ul>
<p><img alt="" src="../img/l/long_short_term_memory_cell.png" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/YCzL96nL7j0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/8HyCNIVRbSU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/S27pHKBEp30" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, <a href="../h/#hidden-state">Hidden State</a>, <a href="./#long-short-term-memory-lstm-network">LSTM Network</a></p>
<h2 id="long-short-term-memory-lstm-network">Long Short-Term Memory (LSTM) Network<a class="headerlink" href="#long-short-term-memory-lstm-network" title="Permanent link">#</a></h2>
<p><mark>A multi-layer Recurrent Neural Network, aka RNN, where a neuron is feeding its output to self, remembers its previous output. Good for sequences</mark>. Used in speech recognition, Text to speech, handwriting recognition. Started becoming widespread in 2007. They are a type of Recurrent Neural Network that can efficiently learn via gradient descent. Using a gating mechanism, LSTMs are able to recognise and encode (short and very) long-term patterns (basic RNN can only remember a given length, i.e have short term memory because of vanishing gradient problem). LSTMs are extremely useful to solve problems where the network has to remember information for a long period of time as is the case in music and text generation.</p>
<p>LSTMs also have the RNN chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p>
<p><img alt="" src="../img/l/long_short_term_memory_unrolled.png" width="100%" /></p>
<p>with</p>
<p><img alt="" src="../img/l/long_short_term_memory_repeating_module.png" width="100%" /></p>
<p>In its chain, a LSTM can optionally use a Gated Recurrent Unit (GRU) cell, which is simpler than the one represented above.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span> <span class="o">=</span> <span class="mi">128</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>        <span class="n">n_vocab</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">uniq_words</span><span class="p">)</span>
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>            <span class="n">num_embeddings</span><span class="o">=</span><span class="n">n_vocab</span><span class="p">,</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>            <span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">,</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>        <span class="p">)</span>
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span>
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>            <span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span>
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>            <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>        <span class="p">)</span>
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">n_vocab</span><span class="p">)</span>
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_state</span><span class="p">):</span>
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>        <span class="n">embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">prev_state</span><span class="p">)</span>
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">state</span>
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
</span><span id="__span-12-27"><a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">),</span>
</span><span id="__span-12-28"><a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">))</span>
</span></code></pre></div>
<iframe src="https://www.youtube.com/embed/WCUNPb-5EYI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>{% pdf "../pdf/l/long_short_term_memory_paper.pdf" %}</p>
<object data="https://arxiv.org/pdf/1402.1128" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1402.1128">Download PDF</a>.
    </p>
</object>

<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>LSTM Are now deprecated by attention-based models, such as transformersD</p>
</div>
<p>More at</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory">https://en.wikipedia.org/wiki/Long_short-term_memory</a></li>
<li>papers<ul>
<li>original - </li>
<li>LSTM for speech recognition - <a href="https://arxiv.org/pdf/1402.1128">https://arxiv.org/pdf/1402.1128</a></li>
</ul>
</li>
<li>LSTM code<ul>
<li>pytorch - <a href="https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial">https://closeheat.com/blog/pytorch-lstm-text-generation-tutorial</a></li>
<li>keras - <a href="https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5">https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5</a></li>
</ul>
</li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../a/#attention-based-model">Attention-Based Model</a>, [Gated Recurrent Unit Cell], [Gradient Descent Algorithm], [Recurrent Neural Network], [Transformer Model], <a href="../v/#vanishing-gradient-problem">Vanishing Gradient Problem</a></p>
<h2 id="longformer-architecture">Longformer Architecture<a class="headerlink" href="#longformer-architecture" title="Permanent link">#</a></h2>
<p>Models that have a long context window?</p>
<ul>
<li>Use [Shifted Window Attention (SWA)]</li>
</ul>
<p>Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. We finally introduce the <a href="./#longformer-encoder-decoder-led">Longformer-Encoder-Decoder (LED)</a>, a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.</p>
<object data="https://arxiv.org/pdf/2004.05150v2" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2004.05150v2">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://paperswithcode.com/method/sliding-window-attention">https://paperswithcode.com/method/sliding-window-attention</a></li>
<li>paper - <a href="https://arxiv.org/abs/2004.05150v2">https://arxiv.org/abs/2004.05150v2</a></li>
<li>code - <a href="https://github.com/allenai/longformer/">https://github.com/allenai/longformer/</a></li>
</ul>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="longformer-encoder-decoder-led">Longformer-Encoder-Decoder (LED)<a class="headerlink" href="#longformer-encoder-decoder-led" title="Permanent link">#</a></h2>
<p>A derivative component of the <a href="./#longformer-architecture">Longformer Architecture</a></p>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="look-ahead-planning">Look-Ahead Planning<a class="headerlink" href="#look-ahead-planning" title="Permanent link">#</a></h2>
<p>Understand the impact of a decision on the future</p>
<p>the idea of using a model of the world to reason into the future and produce better actions or outputs. </p>
<p>There are 2 variants:</p>
<ul>
<li><a href="../m/#model-predictive-control-mpc-algorithm">Model Predictive Control (MPC)</a> - used on continuous states</li>
<li>[Monte-Carlo Tree Search (MCTS)] - used with discrete actions and states</li>
</ul>
<div class="language-text highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>Ask a LLLM, how many character will your next response have?
</span></code></pre></div>
<p>See also <a href="./">L</a>, ...</p>
<h2 id="lora-exchange-lorax-serving">LoRA Exchange (LoRAX) Serving<a class="headerlink" href="#lora-exchange-lorax-serving" title="Permanent link">#</a></h2>
<p>~ used to run 100's of fine-tuned models efficiently. Developed by [Predibase]</p>
<p><a href="./#low-rank-adaptation-lora-fine-tuning">LoRA</a> achieves performances comparable to full <a href="../f/#fine-tuning">fine-tuning</a>. At serving time, both the original model parameters and the new adapter parameters can be loaded together as a single deployment. While a dedicated k8s deployment per fine-tuned model is operationally simple to implement, it’s far from optimal. Indeed the part of the deployment that is unique to the fine-tuned model – the adapter weights – accounts for less than 10% of the total parameters, far below the GPU memory capacity in most cases. This all raises the question: what if we could pack multiple fine-tuned models into a single deployment by reusing the common base model parameters?</p>
<p>LoRA Exchange (LoRAX) is a new approach to LLM serving infrastructure specifically designed for serving many fine-tuned models at once using a shared set of GPU resources. Compared with conventional dedicated LLM deployments, LoRAX consists of three novel components:
  1. Dynamic Adapter Loading - LoRA adapters can be loaded dynamically in the same k8s deployment! Incoming requests are queued based on the desired model.
  1. Tiered Weight Caching - Weights are loaded from the object store into the (1) GPU. Once the GPU share fills up, weights are offloaded to the CPU, and then to the local ephemeral disk.
  1. Continuous Multi-Adapter Batching - request are submitted in batches instead of one at a time to avoid continuous swapping of adapter.</p>
<p><img alt="" src="../img/l/lora_exchange_serving.webp" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/Za9HavaK9ks" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>blog - <a href="https://predibase.com/blog/lora-exchange-lorax-serve-100s-of-fine-tuned-llms-for-the-cost-of-one">https://predibase.com/blog/lora-exchange-lorax-serve-100s-of-fine-tuned-llms-for-the-cost-of-one</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="./#ludwig-framework">Ludwig Framework</a></p>
<h2 id="loss-function">Loss Function<a class="headerlink" href="#loss-function" title="Permanent link">#</a></h2>
<p>Loss function is a way to encode a goal. That loss function is going to dictate the optimized path toward that goal? Optimization?</p>
<p>In most cases, the loss function is used for parameter estimation. Those parameters reflect the goal?</p>
<p><mark>The loss function must encode what you want your model to do!</mark> The loss function will take two items as input: the output value of our model and the ground truth expected value. The output of the loss function is called the loss which is a measure of how well our model did at predicting the outcome. A high value for the loss means our model performed very poorly. A low value for the loss means our model performed very well. In most learning networks, error is calculated as the difference between the actual output y and the predicted output ŷ. The function that is used to compute this error is known as Loss Function also known as Cost function. The loss function allows us to find the best line. The model is iterated to minimize the loss function using the gradient descent algorithm. Selection of the proper loss function is critical for training an accurate model. Certain loss functions will have certain properties and help your model learn in a specific way. Some may put more weight on outliers, others on the majority.</p>
<p>The most common loss functions are:</p>
<ul>
<li><a href="../m/#mean-square-error-mse-loss-function">Mean Squared Error (MSE)</a> - Used in a linear regression, the best line is the one that minimize the root-mean square of the error.</li>
<li><a href="../m/#mean-absolute-error-mae-loss-function">Mean Absolute Error (MAE)</a> - Use the absolute error instead of the RMS error. Beware of <a href="../o/#outlier">outliers</a>.</li>
<li><a href="../h/#hinge-loss-function">Hinge Loss Function</a></li>
<li><a href="../h/#huber-loss-function">Huber Loss Function</a> - Use the <a href="../m/#mean-square-error-mse-loss-function">MSE</a> for small values and <a href="../m/#mean-absolute-error-mae-loss-function">MAE</a> for large values ?</li>
<li><a href="../0-9/#0-1-loss-function">0-1 Loss Function</a> : 0=correct 1=not-correct classification</li>
<li>[Binary cross-entropy loss function] (aka Log loss function) : Used with logistic regression because the logistic regression function (sigmoid or ?) is not linear and loss function needs to have a single minimum</li>
<li><a href="../c/#cross-entropy-loss-function">Cross-entropy loss function</a></li>
<li><a href="../c/#contrastive-loss-function">Contrastive loss function</a> and <a href="../t/#triplet-loss-function">triplet loss function</a></li>
<li>another custom function !</li>
</ul>
<p>Choose your loss function based on</p>
<ul>
<li>the original estimator function (?) e.g. linear or sigmoid</li>
<li>must have a global minimum and not local ones</li>
</ul>
<p>More at :</p>
<ul>
<li>choosing a loss function - <a href="https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/">https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/</a></li>
</ul>
<p>See also <a href="./">L</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../b/#backpropagation">Backpropagation</a>, <a href="../d/#discriminator">Discriminator</a>, [Gradient Descent Algorithm], <a href="./#linear-regression">Linear Regression</a>, <a href="../o/#optimizer">Optimizer</a>, <a href="../p/#prediction-error">Prediction Error</a>, <a href="../r/#representation-space">Representation Space</a>, <a href="../r/#residual">Residual</a></p>
<h2 id="loss-graph">Loss Graph<a class="headerlink" href="#loss-graph" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/l/loss_graph.png" width="100%" /></p>
<p>See also <a href="./">L</a>, <a href="../d/#discriminator-loss">Discriminator  Loss</a>, <a href="../g/#generator-loss">Generator Loss</a>, <a href="./#loss-function">Loss Function</a></p>
<h2 id="low-rank-adaptation-lora-fine-tuning">Low-Rank Adaptation (LoRA) Fine-Tuning<a class="headerlink" href="#low-rank-adaptation-lora-fine-tuning" title="Permanent link">#</a></h2>
<p>A method for [parameter-efficient fine-tuning (PEFT)]</p>
<p>LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike <a href="../a/#adapter-layer">adapters</a>, no additional inference latency</p>
<iframe src="https://www.youtube.com/embed/dA-NhCtrrVE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/iYr1xZn26R8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/t509sv5MT0w" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2106.09685" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2106.09685">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a></li>
<li>article(s)<ul>
<li><a href="https://bdtechtalks.com/2023/05/22/what-is-lora/">https://bdtechtalks.com/2023/05/22/what-is-lora/</a></li>
</ul>
</li>
<li>notebook - <a href="https://github.com/togethercomputer/together-cookbook/blob/main/LoRA_Finetuning%26Inference.ipynb">https://github.com/togethercomputer/together-cookbook/blob/main/LoRA_Finetuning%26Inference.ipynb</a></li>
</ul>
<p>See also <a href="./">L</a>, [LoRA Exchange Serving], [QLoRA Fine-Tuning]</p>
<h2 id="low-rank-approximation">Low-Rank Approximation<a class="headerlink" href="#low-rank-approximation" title="Permanent link">#</a></h2>
<p>Replace a high-rank matrix by an approximation returned by the multiplication of 2 low-rank matrices.
 To find the best low-rank approximation use <a href="../s/#singular-value-decomposition-svd">Singular Value Decomposition (SVD)</a>!</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a> Bm,n = Am,k  .  Ck,n
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a># k &lt;&lt; n  and k &lt;&lt; m
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a># Am,k = matrix of m rows and k columns
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a># Ck,n = matrix of k rows and n columns
</span></code></pre></div>
<p>To find the optimum values for k, Am,k , and Ck,n look at [singular value decomposition]</p>
<iframe src="https://www.youtube.com/embed/12K5aydB9cQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">L</a>, ...</p>
<h2 id="ludwig-framework">Ludwig Framework<a class="headerlink" href="#ludwig-framework" title="Permanent link">#</a></h2>
<p>Ludwig is a low-code framework for building custom AI models like <a href="./#large-language-model-llm">LLMs</a> and other [deep neural networks]. Initially developed at Uber.</p>
<iframe src="https://www.youtube.com/embed/K7yLtB2yaPg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/NAyKpcOdHLE" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://ludwig.ai/latest/">https://ludwig.ai/latest/</a></li>
<li>code - <a href="https://github.com/ludwig-ai/ludwig">https://github.com/ludwig-ai/ludwig</a></li>
<li>notebooks for mistral fine-tuning - <a href="https://colab.research.google.com/drive/1i_8A1n__b7ljRWHzIsAdhO7u7r49vUm4">https://colab.research.google.com/drive/1i_8A1n__b7ljRWHzIsAdhO7u7r49vUm4</a></li>
<li>articles<ul>
<li>LF AI &amp; DATA - <a href="https://lfaidata.foundation/projects/ludwig/">https://lfaidata.foundation/projects/ludwig/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">L</a>, [LoRA Exchange Serving]</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../k/" class="md-footer__link md-footer__link--prev" aria-label="Previous: K">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                K
              </div>
            </div>
          </a>
        
        
          
          <a href="../m/" class="md-footer__link md-footer__link--next" aria-label="Next: M">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                M
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>