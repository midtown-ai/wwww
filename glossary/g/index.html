
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Let's explore this transforming technology. Let's shape the future of AI together.">
      
      
        <meta name="author" content="info@midtown.ai (Emmanuel M.)">
      
      
        <link rel="canonical" href="https://midtown-ai.github.io/wwww/glossary/g/">
      
      
        <link rel="prev" href="../f/">
      
      
        <link rel="next" href="../h/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.3">
    
    
      
        <title>G - Midtown AI</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.d7758b05.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M96 0C43 0 0 43 0 96v320c0 53 43 96 96 96h320c17.7 0 32-14.3 32-32s-14.3-32-32-32v-64c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H96m0 384h256v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32m32-240c0-8.8 7.2-16 16-16h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16m16 48h192c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v132.8c0 11.8-3.3 23.5-9.5 33.5L10.3 406.2C3.6 417.2 0 429.7 0 442.6 0 480.9 31.1 512 69.4 512h309.2c38.3 0 69.4-31.1 69.4-69.4 0-12.8-3.6-25.4-10.3-36.4L329.5 230.4c-6.2-10.1-9.5-21.7-9.5-33.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 196.8V64h64v132.8c0 23.7 6.6 46.9 19 67.1l34.5 56.1h-171l34.5-56.1c12.4-20.2 19-43.4 19-67.1"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.1 52.4 442.6 6.5c-1.9-3.9-6.1-6.5-10.5-6.5s-8.5 2.6-10.4 6.5l-16.5 45.9-46 16.8c-4.3 1.6-7.3 5.9-7.2 10.4 0 4.5 3 8.7 7.2 10.2l45.7 16.8 16.8 45.8c1.5 4.4 5.8 7.5 10.4 7.5s8.9-3.1 10.4-7.5l16.5-45.8 45.7-16.8c4.2-1.5 7.2-5.7 7.2-10.2 0-4.6-3-8.9-7.2-10.4zm-132.4 53c-12.5-12.5-32.8-12.5-45.3 0l-2.9 2.9c-22-8-45.8-12.3-70.5-12.3C93.1 96 0 189.1 0 304s93.1 208 208 208 208-93.1 208-208c0-24.7-4.3-48.5-12.2-70.5l2.9-2.9c12.5-12.5 12.5-32.8 0-45.3l-80-80zM200 192c-57.4 0-104 46.6-104 104v8c0 8.8-7.2 16-16 16s-16-7.2-16-16v-8c0-75.1 60.9-136 136-136h8c8.8 0 16 7.2 16 16s-7.2 16-16 16z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-40-176h24v-64h-24c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24h-80c-13.3 0-24-10.7-24-24s10.7-24 24-24m40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 216C0 149.7 53.7 96 120 96h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V216m256 0c0-66.3 53.7-120 120-120h8c17.7 0 32 14.3 32 32s-14.3 32-32 32h-8c-30.9 0-56 25.1-56 56v8h64c35.3 0 64 28.7 64 64v64c0 35.3-28.7 64-64 64h-64c-35.3 0-64-28.7-64-64V216"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7l233.4-233.3c12.5-12.5 32.8-12.5 45.3 0z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/custom_admonitions.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_effects.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_tables.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_text.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom_theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="G - Midtown AI" >
      
        <meta  property="og:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  property="og:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/g.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://midtown-ai.github.io/wwww/glossary/g/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="G - Midtown AI" >
      
        <meta  name="twitter:description"  content="Let's explore this transforming technology. Let's shape the future of AI together." >
      
        <meta  name="twitter:image"  content="https://midtown-ai.github.io/wwww/assets/images/social/glossary/g.png" >
      
    
    
  <link rel="stylesheet" href="../../stylesheets/custom.7c86dd97.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#g" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Midtown AI" class="md-header__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Midtown AI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              G
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Glossary

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../about/" class="md-tabs__link">
        
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Midtown AI" class="md-nav__button md-logo" aria-label="Midtown AI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M22.7 33.4c13.5-4.1 28.1 1.1 35.9 12.9l165.4 248 165.4-248c7.8-11.7 22.4-17 35.9-12.9S448 49.9 448 64v384c0 17.7-14.3 32-32 32s-32-14.3-32-32V169.7L250.6 369.8c-5.9 8.9-15.9 14.2-26.6 14.2s-20.7-5.3-26.6-14.2L64 169.7V448c0 17.7-14.3 32-32 32S0 465.7 0 448V64c0-14.1 9.2-26.5 22.7-30.6"/></svg>

    </a>
    Midtown AI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/entertainment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entertainment
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/category/no-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    No Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Glossary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0-9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    D
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    E
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../f/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    G
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    G
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#galactica-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Galactica LLM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#game-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Game Theory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#game-tree" class="md-nav__link">
    <span class="md-ellipsis">
      Game Tree
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gamengen-model" class="md-nav__link">
    <span class="md-ellipsis">
      GameNGen Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gamma-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Gamma Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gated-recurrent-unit-gru-cell" class="md-nav__link">
    <span class="md-ellipsis">
      Gated Recurrent Unit (GRU) Cell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gato-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gato Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-error-linear-unit-gelu-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Error Linear Unit (GELU) Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-naive-bayes-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Naive Bayes Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-process" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Process
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gemini-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gemini Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gemma-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gemma Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gen-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gen Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gencast-model" class="md-nav__link">
    <span class="md-ellipsis">
      GenCast Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-artificial-intelligence-assistant-gaia-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      General Artificial Intelligence Assistant (GAIA) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-language-understanding-evaluation-glue-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      General Language Understanding Evaluation (GLUE) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-purpose-ai-system-gpais" class="md-nav__link">
    <span class="md-ellipsis">
      General Purpose AI System (GPAIS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalized-additive-2-model-ga2m" class="md-nav__link">
    <span class="md-ellipsis">
      Generalized Additive 2 Model (GA2M)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalized-additive-model-gam" class="md-nav__link">
    <span class="md-ellipsis">
      Generalized Additive Model (GAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-adversarial-network-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Network (GAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-ai-genai" class="md-nav__link">
    <span class="md-ellipsis">
      Generative AI (GenAI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-design" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Design
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-model" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-pre-trained-transformer-gpt-function-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Pre-Trained Transformer (GPT) Function Calling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-pre-trained-transformer-gpt-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Pre-Trained Transformer (GPT) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generator" class="md-nav__link">
    <span class="md-ellipsis">
      Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generator-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Generator Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genetic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Genetic Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genie-model" class="md-nav__link">
    <span class="md-ellipsis">
      Genie Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#geoffrey-hinton-person" class="md-nav__link">
    <span class="md-ellipsis">
      Geoffrey Hinton Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gini-impurity-index" class="md-nav__link">
    <span class="md-ellipsis">
      GINI Impurity Index
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#github-company" class="md-nav__link">
    <span class="md-ellipsis">
      GitHub Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#github-copilot" class="md-nav__link">
    <span class="md-ellipsis">
      GitHub Copilot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#glide-model" class="md-nav__link">
    <span class="md-ellipsis">
      GLIDE Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Global Pooling Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-vector-glove-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Global Vector (GloVe) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gluon" class="md-nav__link">
    <span class="md-ellipsis">
      Gluon
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goal-conditioned-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Goal-Conditioned RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#good-old-fashioned-ai-gofai" class="md-nav__link">
    <span class="md-ellipsis">
      Good Old-Fashioned AI (GOFAI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-company" class="md-nav__link">
    <span class="md-ellipsis">
      Google Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-lens" class="md-nav__link">
    <span class="md-ellipsis">
      Google Lens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-proof-questions-and-answers-gpqa-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      Google-Proof Questions And Answers (GPQA) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-translate-model" class="md-nav__link">
    <span class="md-ellipsis">
      Google Translate Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gopher-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gopher Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-instance" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Instance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-technology-conference-gtc" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Technology Conference (GTC)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grade-school-math-gsm8k-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Grade School Math (GSM8K) Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-ascent-ga-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Ascent (GA) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Bagging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Boosting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Checkpoint
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-gd-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent (GD) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-with-momentum-gdwm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent with Momentum (GDwM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-perturbation" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Perturbation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradio-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Gradio Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph" class="md-nav__link">
    <span class="md-ellipsis">
      Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-convolutional-network-gcn" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Convolutional Network (GCN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-data-science-gds" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Data Science (GDS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-database" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Database
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-machine-learning-gml" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Machine Learning (GML)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-network-for-materials-exploration-gnome-model" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Network For Materials Exploration (GNoME) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-edge-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Edge-Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-graph-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Graph Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-node-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Node-Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU) Kernel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-high-bandwidth-memory-gpu-hbm" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit High Bandwidth Memory (GPU-HBM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU) Memory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-static-random-access-memory-gpu-sram" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit Static Random Access Memory (GPU-SRAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphrag-system" class="md-nav__link">
    <span class="md-ellipsis">
      GraphRAG System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greedy-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Decoding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greedy-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greg-brockman-person" class="md-nav__link">
    <span class="md-ellipsis">
      Greg Brockman Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grid-search" class="md-nav__link">
    <span class="md-ellipsis">
      Grid Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grok-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Grok LLM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grokking" class="md-nav__link">
    <span class="md-ellipsis">
      Grokking
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#groq-company" class="md-nav__link">
    <span class="md-ellipsis">
      Groq Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ground-truth" class="md-nav__link">
    <span class="md-ellipsis">
      Ground Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#group-relative-policy-optimization-grpo-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Group Relative Policy Optimization (GRPO) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grouped-query-attention-gqa" class="md-nav__link">
    <span class="md-ellipsis">
      Grouped-Query Attention (GQA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gshard-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gshard Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guardrail" class="md-nav__link">
    <span class="md-ellipsis">
      Guardrail
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guardrails-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Guardrails Python Module
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../h/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    H
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../k/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    K
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../l/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    L
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    M
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../n/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    N
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../o/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    P
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../q/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    S
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../u/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    U
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../v/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../w/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    W
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    X
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Y
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../z/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Z
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#galactica-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Galactica LLM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#game-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Game Theory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#game-tree" class="md-nav__link">
    <span class="md-ellipsis">
      Game Tree
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gamengen-model" class="md-nav__link">
    <span class="md-ellipsis">
      GameNGen Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gamma-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Gamma Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gated-recurrent-unit-gru-cell" class="md-nav__link">
    <span class="md-ellipsis">
      Gated Recurrent Unit (GRU) Cell
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gato-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gato Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Distribution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-error-linear-unit-gelu-activation-function" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Error Linear Unit (GELU) Activation Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-naive-bayes-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Naive Bayes Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-process" class="md-nav__link">
    <span class="md-ellipsis">
      Gaussian Process
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gemini-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gemini Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gemma-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gemma Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gen-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gen Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gencast-model" class="md-nav__link">
    <span class="md-ellipsis">
      GenCast Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-artificial-intelligence-assistant-gaia-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      General Artificial Intelligence Assistant (GAIA) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-language-understanding-evaluation-glue-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      General Language Understanding Evaluation (GLUE) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-purpose-ai-system-gpais" class="md-nav__link">
    <span class="md-ellipsis">
      General Purpose AI System (GPAIS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalized-additive-2-model-ga2m" class="md-nav__link">
    <span class="md-ellipsis">
      Generalized Additive 2 Model (GA2M)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalized-additive-model-gam" class="md-nav__link">
    <span class="md-ellipsis">
      Generalized Additive Model (GAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-adversarial-network-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Adversarial Network (GAN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-ai-genai" class="md-nav__link">
    <span class="md-ellipsis">
      Generative AI (GenAI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-design" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Design
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-model" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-pre-trained-transformer-gpt-function-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Pre-Trained Transformer (GPT) Function Calling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-pre-trained-transformer-gpt-model-family" class="md-nav__link">
    <span class="md-ellipsis">
      Generative Pre-Trained Transformer (GPT) Model Family
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generator" class="md-nav__link">
    <span class="md-ellipsis">
      Generator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generator-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Generator Loss
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genetic-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Genetic Programming
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genie-model" class="md-nav__link">
    <span class="md-ellipsis">
      Genie Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#geoffrey-hinton-person" class="md-nav__link">
    <span class="md-ellipsis">
      Geoffrey Hinton Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gini-impurity-index" class="md-nav__link">
    <span class="md-ellipsis">
      GINI Impurity Index
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#github-company" class="md-nav__link">
    <span class="md-ellipsis">
      GitHub Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#github-copilot" class="md-nav__link">
    <span class="md-ellipsis">
      GitHub Copilot
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#glide-model" class="md-nav__link">
    <span class="md-ellipsis">
      GLIDE Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-pooling-layer" class="md-nav__link">
    <span class="md-ellipsis">
      Global Pooling Layer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-vector-glove-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Global Vector (GloVe) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gluon" class="md-nav__link">
    <span class="md-ellipsis">
      Gluon
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goal-conditioned-rl" class="md-nav__link">
    <span class="md-ellipsis">
      Goal-Conditioned RL
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#good-old-fashioned-ai-gofai" class="md-nav__link">
    <span class="md-ellipsis">
      Good Old-Fashioned AI (GOFAI)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-company" class="md-nav__link">
    <span class="md-ellipsis">
      Google Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-lens" class="md-nav__link">
    <span class="md-ellipsis">
      Google Lens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-proof-questions-and-answers-gpqa-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      Google-Proof Questions And Answers (GPQA) Benchmark
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-translate-model" class="md-nav__link">
    <span class="md-ellipsis">
      Google Translate Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gopher-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gopher Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-instance" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Instance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-technology-conference-gtc" class="md-nav__link">
    <span class="md-ellipsis">
      GPU Technology Conference (GTC)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grade-school-math-gsm8k-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Grade School Math (GSM8K) Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-ascent-ga-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Ascent (GA) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Bagging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Boosting
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-checkpoint" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Checkpoint
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-gd-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent (GD) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-descent-with-momentum-gdwm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent with Momentum (GDwM) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-perturbation" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Perturbation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradio-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Gradio Python Module
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph" class="md-nav__link">
    <span class="md-ellipsis">
      Graph
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-convolutional-network-gcn" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Convolutional Network (GCN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-data-science-gds" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Data Science (GDS)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-database" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Database
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-machine-learning-gml" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Machine Learning (GML)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-network-for-materials-exploration-gnome-model" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Network For Materials Exploration (GNoME) Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-edge-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Edge-Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-graph-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Graph Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-neural-network-gnn-node-level-task" class="md-nav__link">
    <span class="md-ellipsis">
      Graph Neural Network (GNN) Node-Level Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU) Kernel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-high-bandwidth-memory-gpu-hbm" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit High Bandwidth Memory (GPU-HBM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-gpu-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit (GPU) Memory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphical-processing-unit-static-random-access-memory-gpu-sram" class="md-nav__link">
    <span class="md-ellipsis">
      Graphical Processing Unit Static Random Access Memory (GPU-SRAM)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graphrag-system" class="md-nav__link">
    <span class="md-ellipsis">
      GraphRAG System
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greedy-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Decoding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greedy-sampling" class="md-nav__link">
    <span class="md-ellipsis">
      Greedy Sampling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#greg-brockman-person" class="md-nav__link">
    <span class="md-ellipsis">
      Greg Brockman Person
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grid-search" class="md-nav__link">
    <span class="md-ellipsis">
      Grid Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grok-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Grok LLM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grokking" class="md-nav__link">
    <span class="md-ellipsis">
      Grokking
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#groq-company" class="md-nav__link">
    <span class="md-ellipsis">
      Groq Company
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ground-truth" class="md-nav__link">
    <span class="md-ellipsis">
      Ground Truth
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#group-relative-policy-optimization-grpo-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Group Relative Policy Optimization (GRPO) Algorithm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grouped-query-attention-gqa" class="md-nav__link">
    <span class="md-ellipsis">
      Grouped-Query Attention (GQA)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gshard-model" class="md-nav__link">
    <span class="md-ellipsis">
      Gshard Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guardrail" class="md-nav__link">
    <span class="md-ellipsis">
      Guardrail
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#guardrails-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Guardrails Python Module
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="g">G<a class="headerlink" href="#g" title="Permanent link">#</a></h1>
<h2 id="galactica-llm">Galactica LLM<a class="headerlink" href="#galactica-llm" title="Permanent link">#</a></h2>
<p>Galactica is “a <a href="../l/#large-language-model-llm">large language model</a> that can store, combine and reason about scientific knowledge,” according to a paper published by <a href="../m/#meta-company">Meta</a> AI. It is a transformer model that has been trained on a carefully curated dataset of 48 million papers, textbooks and lecture notes, millions of compounds and proteins, scientific websites, encyclopedias, and more. Galactica was supposed to help scientists navigate the ton of published scientific information. Its developers presented it as being able to find citations, summarize academic literature, solve math problems, and perform other tasks that help scientists in research and writing papers.</p>
<object data="https://arxiv.org/pdf/2211.09085" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2211.09085">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="http://galactica.org">http://galactica.org</a></li>
<li>paper - <a href="https://arxiv.org/abs/2211.09085">https://arxiv.org/abs/2211.09085</a></li>
<li>articles<ul>
<li>what happened to galactica? - <a href="https://www.louisbouchard.ai/galactica/">https://www.louisbouchard.ai/galactica/</a></li>
<li>take-aways - <a href="https://bdtechtalks.com/2022/11/21/meta-ai-galactica">https://bdtechtalks.com/2022/11/21/meta-ai-galactica</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="game-theory">Game Theory<a class="headerlink" href="#game-theory" title="Permanent link">#</a></h2>
<p>Used in model architecture, such as <a href="./#generative-adversarial-network-gan">GAN</a> and used for decision making process, such as in <a href="../p/#pluribus-model">Pluribus Model</a> and [Multi-Agent Model]</p>
<p>More at:</p>
<ul>
<li><a href="https://link.springer.com/article/10.1007/s11042-022-12153-2">https://link.springer.com/article/10.1007/s11042-022-12153-2</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../n/#nash-equilibrium">Nash Equilibrium</a>, [Shapley Value]</p>
<h2 id="game-tree">Game Tree<a class="headerlink" href="#game-tree" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/g/game_tree.png" width="100%" /></p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gamengen-model">GameNGen Model<a class="headerlink" href="#gamengen-model" title="Permanent link">#</a></h2>
<p>9/1/2024 - <a href="./#google-company">Google</a> develops GameNGen: World first AI model that predicts next frame of a live shooter game, playable at 20 fps</p>
<p>Google's GameNGen: AI-Powered Real-Time Game Engine works by predicting each frame in real time with a diffusion model</p>
<p>Key Points</p>
<ul>
<li>GameNGen is a neural network-based game engine that uses diffusion models to simulate complex games in real-time.</li>
<li>It can run the classic first-person shooter game like DOOM at over 20 frames per second on a single TPU.</li>
<li>The system employed a two-phase training process. An RL agent first plays the game, generating training data from its actions and observations.</li>
<li>This data then trains a diffusion model to predict subsequent frames based on past frames and actions.</li>
<li>The model achieves a Peak Signal-to-Noise Ratio (PSNR) of 29.4 for next frame prediction, comparable to lossy JPEG compression.</li>
</ul>
<p>GameNGen's Architecture 
  * It is based on a modified version of Stable Diffusion
  * Key changes include: Removal of text conditioning, Addition of action embedding for input, Concatenation of encoded past frames in latent space and Implementation of noise augmentation for stability.
  * The noise augmentation technique is crucial for maintaining quality over long gameplay sessions. During training, varying amounts of Gaussian noise are added to encoded frames, with the noise level provided as input to the model. This allows the network to correct information from previous frames and prevents quality degradation in auto-regressive generation.
  * The model uses 4 DDIM sampling steps during inference, which surprisingly yields no degradation in simulation quality compared to 20 or more steps.
  * To improve image quality, particularly for small details and the HUD, the researchers fine-tuned the latent decoder of the auto-encoder using an MSE loss against target frame pixels.</p>
<p>Despite operating with only about 3 seconds of game history, GameNGen maintains accurate game state, including health, ammo, and enemy positions. </p>
<p>At scale this could mean AI will be able to create games on the fly, personalized to each player</p>
<object data="https://arxiv.org/pdf/2408.14837" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2408.14837">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2408.14837">https://arxiv.org/abs/2408.14837</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gamma-distribution">Gamma Distribution<a class="headerlink" href="#gamma-distribution" title="Permanent link">#</a></h2>
<p>Continuous distribution based on a Poisson process (independent events)</p>
<iframe src="https://www.youtube.com/embed/cpW40zPdAQ8" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">G</a>, <a href="../d/#distribution">Distribution</a></p>
<h2 id="gated-recurrent-unit-gru-cell">Gated Recurrent Unit (GRU) Cell<a class="headerlink" href="#gated-recurrent-unit-gru-cell" title="Permanent link">#</a></h2>
<p>Cell or module that can be used in the RNN chain of a Long Short Term Memory, or LSTM Network. A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014). It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models and therefore less compute intensive. This cell has been growing increasingly popular.</p>
<p><img alt="" src="../img/g/gated_recurrent_unit_cell2.png" width="100%" /></p>
<p><img alt="" src="../img/g/gated_recurrent_unit_cell.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li>
<li>paper - <a href="https://arxiv.org/abs/1710.04110">https://arxiv.org/abs/1710.04110</a></li>
</ul>
<p>See also <a href="./">G</a>, [Long Short-Term Memory Network], </p>
<h2 id="gato-model">Gato Model<a class="headerlink" href="#gato-model" title="Permanent link">#</a></h2>
<p>A model developed by <a href="../d/#deepmind-company">DeepMind</a> that uses [Multi-Task Learning]</p>
<p><img alt="" src="../img/g/gato_model.png" width="100%" /></p>
<object data="https://arxiv.org/pdf/2205.06175" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2205.06175">Download PDF</a>.
    </p>
</object>

<iframe src="https://www.youtube.com/embed/wSQJZHfAg18" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://www.deepmind.com/publications/a-generalist-agent">https://www.deepmind.com/publications/a-generalist-agent</a></li>
<li>paper - <a href="https://arxiv.org/abs/2205.06175">https://arxiv.org/abs/2205.06175</a></li>
<li>blog - <a href="https://www.deepmind.com/blog/a-generalist-agent">https://www.deepmind.com/blog/a-generalist-agent</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gaussian-distribution">Gaussian Distribution<a class="headerlink" href="#gaussian-distribution" title="Permanent link">#</a></h2>
<p>The Gaussian distribution, normal distribution, or bell curve, is a probability distribution which accurately models a large number of phenomena in the world. Intuitively, it is the mathematical representation of the general truth that many measurable quantities, when taking in aggregate tend to be of the similar values with only a few outliers which is to say that many phenomena follow the central limit theorem.</p>
<p><img alt="" src="../img/g/gaussian_distribution.png" width="100%" /></p>
<p>See also <a href="./">G</a>, <a href="../c/#central-limit-theorem">Central Limit Theorem</a>, <a href="./#gaussian-naive-bayes-classifier">Gaussian Naive Bayes Classifier</a>, <a href="./#gaussian-process">Gaussian Process</a></p>
<h2 id="gaussian-error-linear-unit-gelu-activation-function">Gaussian Error Linear Unit (GELU) Activation Function<a class="headerlink" href="#gaussian-error-linear-unit-gelu-activation-function" title="Permanent link">#</a></h2>
<p>GELU activation functions are used in GPT-3, BERT, and most other <a href="../t/#transformer-architecture">Transformer architecture</a> models.</p>
<p>An empirical evaluation of the GELU nonlinearity against the <a href="../r/#rectified-linear-unit-relu-activation-function">ReLU</a> and <a href="../e/#exponential-linear-unit-elu-activation-function">ELU</a> activations and find performance improvements across all considered <a href="../c/#computer-vision-cv">computer vision</a>, <a href="../n/#natural-language-processing-nlp">natural language processing</a>, and speech tasks.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="" src="../img/g/gaussian_error_linear_unit_activation_function.png" width="100%" /></p>
<object data="https://arxiv.org/pdf/1606.08415v5" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1606.08415v5">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1606.08415v5">https://arxiv.org/abs/1606.08415v5</a></li>
<li>code - <a href="https://github.com/pytorch/pytorch/blob/96aaa311c0251d24decb9dc5da4957b7c590af6f/torch/nn/modules/activation.py#L584">https://github.com/pytorch/pytorch/blob/96aaa311c0251d24decb9dc5da4957b7c590af6f/torch/nn/modules/activation.py#L584</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gaussian-naive-bayes-classifier">Gaussian Naive Bayes Classifier<a class="headerlink" href="#gaussian-naive-bayes-classifier" title="Permanent link">#</a></h2>
<p>A type of <a href="../n/#naive-bayes-classifier">Naive Bayes Classifiers</a> that use the <a href="./#gaussian-distribution">Gaussian Distribution</a> for training data</p>
<iframe src="https://www.youtube.com/embed/H3EjCKtlVog" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">G</a>, ...</p>
<h2 id="gaussian-process">Gaussian Process<a class="headerlink" href="#gaussian-process" title="Permanent link">#</a></h2>
<p>See also <a href="./">G</a>, <a href="../r/#random-forest">Random Forest</a>, [Tree Parzen Estimators]</p>
<h2 id="gemini-model">Gemini Model<a class="headerlink" href="#gemini-model" title="Permanent link">#</a></h2>
<p>Built by <a href="./#google-company">Google</a> using <a href="../p/#pathways-language-model-palm">PaLM</a> to compete with the multimodal [GPT-4V model]</p>
<iframe src="https://www.youtube.com/embed/myEv780rfRU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>announcement <ul>
<li>2024/02 - <a href="https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html">https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html</a></li>
<li>
<ul>
<li><a href="https://deepmind.google/technologies/gemini/#introduction">https://deepmind.google/technologies/gemini/#introduction</a></li>
</ul>
</li>
</ul>
</li>
<li>gemini - <a href="https://gemini.google.com/">https://gemini.google.com/</a></li>
<li>Articles<ul>
<li><a href="https://aibusiness.com/companies/google-doubles-down-on-ai-launches-new-language-model-and-ai-tools">https://aibusiness.com/companies/google-doubles-down-on-ai-launches-new-language-model-and-ai-tools</a></li>
<li><a href="https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/">https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gemma-model">Gemma Model<a class="headerlink" href="#gemma-model" title="Permanent link">#</a></h2>
<p>A <a href="../s/#small-language-model-slm">Small Language Model (SLM)</a> developed by <a href="./#google-company">Google</a> to be used in desktop/phone applications.</p>
<p>Variant:</p>
<ul>
<li>Gemma 1 and Gemma 2 - open-source <a href="../s/#small-language-model-slm">SLM</a></li>
<li>CodeGemma - for code generation?</li>
<li>PaliGemma - [video-language model]</li>
<li>RecurrentGemma - not using transformer architecture </li>
<li>ShieldGemma - instruction tuned models for evaluating the safety of text prompt input and text output responses against a set of defined safety policies.</li>
<li>DataGemma - Model trained on <a href="../d/#data-commons-dataset">Data Commons</a> using <a href="../r/#retrieval-interleaved-generation-rig-system">Retrieval-Interleaved Generation (RIG)</a></li>
</ul>
<iframe src="https://www.youtube.com/embed/IY5XZPrV03A" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>docs - <a href="https://ai.google.dev/gemma/docs">https://ai.google.dev/gemma/docs</a></li>
<li>notbeooks<ul>
<li><a href="https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb">https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a></li>
</ul>
</li>
<li>kaggle <ul>
<li>model page - <a href="https://www.kaggle.com/models/google/gemma">https://www.kaggle.com/models/google/gemma</a></li>
<li>
<ul>
<li><a href="https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora">https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora</a></li>
</ul>
</li>
</ul>
</li>
<li>papers<ul>
<li>RecurrentGemma - <a href="https://arxiv.org/abs/2404.07839v1">https://arxiv.org/abs/2404.07839v1</a> </li>
<li>DataGemma - <a href="https://arxiv.org/abs/2409.13741">https://arxiv.org/abs/2409.13741</a></li>
</ul>
</li>
<li>articles<ul>
<li>RecurrentGemma - <a href="https://developers.googleblog.com/en/gemma-explained-recurrentgemma-architecture/">https://developers.googleblog.com/en/gemma-explained-recurrentgemma-architecture/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gen-model">Gen Model<a class="headerlink" href="#gen-model" title="Permanent link">#</a></h2>
<p>A text-to-video model built by the <a href="../r/#runway-company">Runway</a></p>
<iframe src="https://www.youtube.com/embed/trXPfpV5iRQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/abs/2302.03011" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/abs/2302.03011">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://research.runwayml.com/gen2">https://research.runwayml.com/gen2</a></li>
<li>paper - <a href="https://arxiv.org/abs/2302.03011">https://arxiv.org/abs/2302.03011</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gencast-model">GenCast Model<a class="headerlink" href="#gencast-model" title="Permanent link">#</a></h2>
<p>New AI model created by <a href="../d/#deepmind-company">DeepMind</a> that advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead</p>
<p>GenCast is a diffusion model, the type of generative AI model that underpins the recent, rapid advances in image, video and music generation. However, GenCast differs from these, in that it’s adapted to the spherical geometry of the Earth, and learns to accurately generate the complex probability distribution of future weather scenarios when given the most recent state of the weather as input.</p>
<p>To train GenCast, we provided it with four decades of historical weather data from ECMWF’s ERA5 archive. This data includes variables such as temperature, wind speed, and pressure at various altitudes. The model learned global weather patterns, at 0.25° resolution, directly from this processed weather data.</p>
<p>More at:</p>
<ul>
<li>paper - <a href="https://www.nature.com/articles/s41586-024-08252-9">https://www.nature.com/articles/s41586-024-08252-9</a></li>
<li>announcement - <a href="https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/">https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/</a></li>
<li>GraphCast model (Previous model) - <a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/">https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/</a></li>
<li>articles<ul>
<li>nature - <a href="https://www.nature.com/articles/d41586-024-03957-3">https://www.nature.com/articles/d41586-024-03957-3</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="general-artificial-intelligence-assistant-gaia-benchmark">General Artificial Intelligence Assistant (GAIA) Benchmark<a class="headerlink" href="#general-artificial-intelligence-assistant-gaia-benchmark" title="Permanent link">#</a></h2>
<p>~ a <a href="../b/#benchmark">benchmark</a> for General [AI Assistants].</p>
<p>Created by researchers from <a href="../m/#meta-company">Meta</a>, <a href="../h/#hugging-face-company">Hugging Face</a>, <a href="../a/#autogpt-model">AutoGPT</a> and <a href="./#generative-ai-genai">GenAI</a>, the benchmark “proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency,”</p>
<p>The researchers said GAIA questions are “conceptually simple for humans yet challenging for most advanced AIs.” They tested the benchmark on human respondents and <a href="./#generative-pre-trained-transformer-gpt-model-family">GPT-4</a>, finding that humans scored 92 percent while <a href="./#generative-pre-trained-transformer-gpt-model-family">GPT-4</a> with plugins scored only 15 percent.</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a># Example of questions
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a> Question:
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a> I’m researching species that became invasive after people who kept them as pets released them. There’s a certain species of fish that was popularized as a pet by being the main character of the movie Finding Nemo. According to the USGS, where was this fish found as a nonnative species, before the year 2020? I need the answer formatted as the five-digit zip codes of the places the species was found, separated by commas if there is more than one place.
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a> Answer: 34689
</span></code></pre></div>
<object data="https://arxiv.org/pdf/2311.12983" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2311.12983">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2311.12983">https://arxiv.org/abs/2311.12983</a></li>
<li>site - <a href="https://huggingface.co/gaia-benchmark">https://huggingface.co/gaia-benchmark</a></li>
<li>dataset - <a href="https://huggingface.co/datasets/gaia-benchmark/GAIA">https://huggingface.co/datasets/gaia-benchmark/GAIA</a></li>
<li>leaderboard - <a href="https://huggingface.co/spaces/gaia-benchmark/leaderboard">https://huggingface.co/spaces/gaia-benchmark/leaderboard</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="general-language-understanding-evaluation-glue-benchmark">General Language Understanding Evaluation (GLUE) Benchmark<a class="headerlink" href="#general-language-understanding-evaluation-glue-benchmark" title="Permanent link">#</a></h2>
<p>The General Language Understanding Evaluation (GLUE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems. GLUE consists of:</p>
<ul>
<li>A benchmark of nine sentence- or sentence-pair language understanding tasks built on established existing datasets and selected to cover a diverse range of dataset sizes, text genres, and degrees of difficulty,</li>
<li>A diagnostic dataset designed to evaluate and analyze model performance with respect to a wide range of linguistic phenomena found in natural language, and</li>
<li>A public leaderboard for tracking performance on the benchmark and a dashboard for visualizing the performance of models on the diagnostic set.</li>
</ul>
<p>The format of the GLUE benchmark is model-agnostic, so any system capable of processing sentence and sentence pairs and producing corresponding predictions is eligible to participate. The benchmark tasks are selected so as to favor models that share information across tasks using parameter sharing or other transfer learning techniques. The ultimate goal of GLUE is to drive research in the development of general and robust natural language understanding systems.</p>
<object data="https://arxiv.org/pdf/1804.07461" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1804.07461">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://gluebenchmark.com/">https://gluebenchmark.com/</a></li>
<li>paper - <a href="https://arxiv.org/abs/1804.07461">https://arxiv.org/abs/1804.07461</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../b/#benchmark">Benchmark</a>, <a href="../s/#superglue-benchmark">SuperGLUE Benchmark</a></p>
<h2 id="general-purpose-ai-system-gpais">General Purpose AI System (GPAIS)<a class="headerlink" href="#general-purpose-ai-system-gpais" title="Permanent link">#</a></h2>
<p>A GPAIS (General Purpose AI System) is a category proposed by lawmakers to account for AI tools with more than one application, such as generative AI models like ChatGPT.</p>
<p>Lawmakers are currently debating whether all forms of GPAIS will be designated high risk, and what that would mean for technology companies looking to adopt AI into their products. </p>
<p>More at:</p>
<ul>
<li><a href="https://www.reuters.com/technology/what-is-european-union-ai-act-2023-03-22/">https://www.reuters.com/technology/what-is-european-union-ai-act-2023-03-22/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="generalized-additive-2-model-ga2m">Generalized Additive 2 Model (GA2M)<a class="headerlink" href="#generalized-additive-2-model-ga2m" title="Permanent link">#</a></h2>
<p>Use GA2Ms if they are significantly more accurate than <a href="./#generalized-additive-model-gam">GAMs</a>, especially if you believe from your domain knowledge that there are real feature interactions, but they are not too complex. This also gives the advantages of a <a href="../w/#white-box-model">White Box Model</a>, with more effort to interpret.</p>
<p>More at:</p>
<ul>
<li>constrained GA2M paper - <a href="https://arxiv.org/abs/2106.02836">https://arxiv.org/abs/2106.02836</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="generalized-additive-model-gam">Generalized Additive Model (GAM)<a class="headerlink" href="#generalized-additive-model-gam" title="Permanent link">#</a></h2>
<p>Generalized Additive Models (GAMs) were developed in the 1990s by Hastie and Tibshirani. </p>
<p>More at:</p>
<ul>
<li><a href="https://www.fiddler.ai/blog/a-gentle-introduction-to-ga2ms-a-white-box-model">https://www.fiddler.ai/blog/a-gentle-introduction-to-ga2ms-a-white-box-model</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)<a class="headerlink" href="#generative-adversarial-network-gan" title="Permanent link">#</a></h2>
<p>So why do we want a generative model? Well, it’s in the name! We wish to generate something an image, music, something! But what do we wish to generate? <code>Typically, we wish to generate data</code> (I know, not very specific). More than that though, it is likely that we wish to generate data that is never before seen, yet still fits into some data distribution (i.e. some pre-defined dataset that we have already set aside and that was used to build a discriminator). GANs, a generative AI technique, pit 2 networks against each other to generate new content. The algorithm consists of two competing networks: a generator and a discriminator. A generator is a convolutional neural network (CNN) that learns to create new data resembling the source data it was trained on. The discriminator is another convolutional neural network (CNN) that is trained to differentiate between real and synthetic data. The generator and the discriminator are trained in alternating cycles such that the generator learns to produce more and more realistic data while the discriminator iteratively gets better at learning to differentiate real data from the newly created data.</p>
<p><img alt="" src="../img/g/generative_adversarial_network.png" width="100%" /></p>
<p>There are different types of GAN, including:</p>
<ul>
<li><a href="../v/#vanilla-gan">Vanilla GAN</a></li>
<li>Cycle GAN</li>
<li>Conditional GAN</li>
<li>Deep Convoluted GAN</li>
<li>Style GAN</li>
<li>Super Resolution GAN (SRGAN)</li>
</ul>
<iframe src="https://www.youtube.com/embed/_pIMdDWK5sc" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/3z8VSpBL6Vg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/1406.2661" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/1406.2661">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/1406.2661">https://arxiv.org/abs/1406.2661</a></li>
<li>articles<ul>
<li><a href="http://hunterheidenreich.com/blog/what-is-a-gan/">http://hunterheidenreich.com/blog/what-is-a-gan/</a></li>
</ul>
</li>
<li>code<ul>
<li>GAN with Keras - <a href="https://python.plainenglish.io/exploring-generative-adversarial-networks-gans-in-two-dimensional-space-922ee342b253">https://python.plainenglish.io/exploring-generative-adversarial-networks-gans-in-two-dimensional-space-922ee342b253</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, <a href="../a/#autoregressive-convolutional-neural-network-ar-cnn">AR-CNN</a>, <a href="../c/#convolutional-neural-network-cnn">Convolutional Neural Network</a>, [Conditional GAN], <a href="../c/#cycle-gan">Cycle GAN</a>, [DeepComposer], <a href="../d/#discriminator">Discriminator</a>, <a href="./#generative-model">Generative Model</a>, <a href="./#generator">Generator</a></p>
<h2 id="generative-ai-genai">Generative AI (GenAI)<a class="headerlink" href="#generative-ai-genai" title="Permanent link">#</a></h2>
<p>Generative artificial intelligence (AI) describes algorithms (such as ChatGPT) that can be used to create new content, including audio, code, images, text, simulations, and videos. Recent new breakthroughs in the field have the potential to drastically change the way we approach content creation.</p>
<p>Based on California's [executive order on AI]</p>
<object data="https://www.govops.ca.gov/wp-content/uploads/sites/11/2023/11/GenAI-EO-1-Report_FINAL.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://www.govops.ca.gov/wp-content/uploads/sites/11/2023/11/GenAI-EO-1-Report_FINAL.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li><a href="https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-generative-ai">https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-generative-ai</a></li>
<li><a href="https://www.gov.ca.gov/2023/11/21/newsom-administration-releases-genai-report/">https://www.gov.ca.gov/2023/11/21/newsom-administration-releases-genai-report/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../d/#dall-e-model-family">DALL-E Model</a>, <a href="../c/#chatgpt-model">ChatGPT Model</a></p>
<h2 id="generative-classifier">Generative Classifier<a class="headerlink" href="#generative-classifier" title="Permanent link">#</a></h2>
<p>Generative Classifiers tries to model class, i.e., what are the features of the class. In short, it models how a particular class would generate input data. When a new observation is given to these classifiers, it tries to predict which class would have most likely generated the given observation. Such methods try to learn about the environment. An example of such classifiers is Naive Bayes. Mathematically, generative models try to learn the joint probability distribution, <code>p(x,y)</code>, of the inputs x and label y, and make their prediction using Bayes rule to calculate the conditional probability, <code>p(y|x)</code>, and then picking a most likely label. Thus, it tries to learn the actual distribution of the class.</p>
<p><img alt="" src="../img/g/generative_classifier.png" width="100%" /></p>
<p>See also <a href="./">G</a>, <a href="../b/#bayesian-network">Bayesian Network</a>, [Hidden Markov Model], <a href="../m/#markov-random-field">Markov Random Field</a>, <a href="../n/#naive-bayes-theorem">Naive Bayes Theorem</a></p>
<h2 id="generative-design">Generative Design<a class="headerlink" href="#generative-design" title="Permanent link">#</a></h2>
<p><a href="./#generative-ai-genai">Generative AI</a> applied to architecture, design of parts, etc. everything that normally use CAD tools!</p>
<iframe src="https://www.youtube.com/embed/RrL4HshuzUw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.generativedesign.org/">https://www.generativedesign.org/</a></li>
<li><a href="https://www.ptc.com/en/blogs/cad/beginner-guide-generative-design">https://www.ptc.com/en/blogs/cad/beginner-guide-generative-design</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="generative-model">Generative Model<a class="headerlink" href="#generative-model" title="Permanent link">#</a></h2>
<p>AI models that generate/create content. Examples of Generative AI techniques include:</p>
<ul>
<li><a href="../d/#diffusion-model-dm">Diffusion Models</a></li>
<li>[Generative Adversarial Networks (GANs)]</li>
<li>[Variational autoencoders (VAEs)] = Hidden state is represented by a distribution, which is then sampled and decoded (Q: what is mean and variance?)</li>
<li>[Transformer-Based Models]</li>
<li>Decoders with masked self-attention</li>
</ul>
<p><img alt="" src="../img/g/generative_model_1.png" width="100%" /></p>
<p><img alt="" src="../img/g/generative_model_2.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>Generative Modeling by Estimating Gradients of the Data Distribution - <a href="https://yang-song.net/blog/2021/score/">https://yang-song.net/blog/2021/score/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../d/#decoder">Decoder</a>, <a href="../f/#flow-based-model">Flow-Based Model</a>, <a href="../m/#masked-self-attention">Masked Self-Attention</a></p>
<h2 id="generative-pre-trained-transformer-gpt-function-calling">Generative Pre-Trained Transformer (GPT) Function Calling<a class="headerlink" href="#generative-pre-trained-transformer-gpt-function-calling" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/JVdFB5hgcwQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/AetT0ZqwNqY?start=87" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>articles <ul>
<li><a href="https://www.ai-jason.com/learning-ai/gpt-functioning-calling-tutorial">https://www.ai-jason.com/learning-ai/gpt-functioning-calling-tutorial</a></li>
<li>code - <a href="https://github.com/JayZeeDesign/gpt-function-calling-tutorial/blob/main/app.py">https://github.com/JayZeeDesign/gpt-function-calling-tutorial/blob/main/app.py</a></li>
<li>rapidapi hub - <a href="https://rapidapi.com/hub">https://rapidapi.com/hub</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="generative-pre-trained-transformer-gpt-model-family">Generative Pre-Trained Transformer (GPT) Model Family<a class="headerlink" href="#generative-pre-trained-transformer-gpt-model-family" title="Permanent link">#</a></h2>
<p>Before GPT-3 there was no general language model that could perform well on an array of <a href="../n/#natural-language-processing-nlp">NLP</a> tasks. Language models were designed to perform one specific NLP task, such as text generation, summarization, or classification, using existing algorithms and architectures. GPT-3 has extraordinary capabilities as a general language model. GPT-3 is pre-trained on a corpus of text from five datasets: <a href="../c/#common-crawl-corpus">Common Crawl</a> (Internet), WebText2, Books1, Books2, and Wikipedia. </p>
<ul>
<li>By default, GPT-2 remembers the last 1024 words. That the max? length of the left-side context?</li>
<li>GPT-3 possesses 175 billion weights connecting the equivalent of 8.3 million <a href="../a/#artificial-neuron">artificial neurons</a> arranged 384 layers deep.<ul>
<li>GPT-2 and GPT-3 have fundamentally the same architecture</li>
<li>But each generation of models ~ 10-100x increase in compute/size</li>
<li>The difference in using these models is qualitatively extremely different</li>
</ul>
</li>
</ul>
<p>Here is the paper about GPT-3 in 2020</p>
<object data="https://arxiv.org/pdf/2005.14165v4" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2005.14165v4">Download PDF</a>.
    </p>
</object>

<p>GPT4 released on Tuesday 03/14/2023</p>
<p><img alt="" src="../img/g/gpt4_model_exams.png" width="100%" /></p>
<object data="https://cdn.openai.com/papers/gpt-4.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://cdn.openai.com/papers/gpt-4.pdf">Download PDF</a>.
    </p>
</object>

<p>Early experiment with GPT-4 have shown sparks of <a href="../a/#artificial-general-intelligence-agi">Artificial General Intelligence</a>!</p>
<iframe src="https://www.youtube.com/embed/outcGtbnMuQ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/PEjl7-7lZLA" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/6Hewb1wlOlo" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>A closer look at the multimodal GPT-4V model</p>
<object data="https://cdn.openai.com/papers/GPTV_System_Card.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://cdn.openai.com/papers/GPTV_System_Card.pdf">Download PDF</a>.
    </p>
</object>

<p>On 12/01/2023, during OpenAI dev day, GPT-4Turbo is announced</p>
<p>Impact on the workforce and companies</p>
<object data="https://arxiv.org/pdf/2303.10130" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2303.10130">Download PDF</a>.
    </p>
</object>

<object data="https://wp.technologyreview.com/wp-content/uploads/2023/10/MITTR-GenAI-Report-V15_10-6-23.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://wp.technologyreview.com/wp-content/uploads/2023/10/MITTR-GenAI-Report-V15_10-6-23.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>GPT-1 paper - <a href="https://paperswithcode.com/paper/improving-language-understanding-by">https://paperswithcode.com/paper/improving-language-understanding-by</a></li>
<li>GPT-2 paper - <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a> (also attached)</li>
<li>GPT-3 paper - <a href="https://arxiv.org/abs/2005.14165v4">https://arxiv.org/abs/2005.14165v4</a></li>
<li>GPT-4 paper - <a href="https://cdn.openai.com/papers/gpt-4.pdf">https://cdn.openai.com/papers/gpt-4.pdf</a></li>
<li>GPT-4 site - <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a></li>
<li>GPT fine-tuning - <a href="https://platform.openai.com/docs/guides/fine-tuning">https://platform.openai.com/docs/guides/fine-tuning</a></li>
<li>gpt vs chatgpt vs instructgpt - <a href="https://medium.com/@colin.fraser/chatgpt-automatic-expensive-bs-at-scale-a113692b13d5">https://medium.com/@colin.fraser/chatgpt-automatic-expensive-bs-at-scale-a113692b13d5</a></li>
<li>GPT-4V(ision) site + paper - <a href="https://openai.com/research/gpt-4v-system-card">https://openai.com/research/gpt-4v-system-card</a></li>
<li>GPTs are GPTs papers - <a href="https://arxiv.org/abs/2303.10130">https://arxiv.org/abs/2303.10130</a></li>
<li>articles<ul>
<li>MIT TR deployment strategy - <a href="https://www.technologyreview.com/2023/10/10/1081117/generative-ai-deployment-strategies-for-smooth-scaling/">https://www.technologyreview.com/2023/10/10/1081117/generative-ai-deployment-strategies-for-smooth-scaling/</a></li>
<li>OpenAI Function Calling - <a href="https://cobusgreyling.medium.com/emergence-of-large-action-models-lams-and-their-impact-on-ai-agents-424d3df5df28">https://cobusgreyling.medium.com/emergence-of-large-action-models-lams-and-their-impact-on-ai-agents-424d3df5df28</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, <a href="../c/#chatgpt-model">ChatGPT Model</a>, <a href="../d/#digital-watermark">Digital Watermark</a>, <a href="../f/#fine-tuning">Fine-Tuning</a>, <a href="./#generative-pre-trained-transformer-gpt-function-calling">GPT Function Calling</a>, <a href="../i/#instructgpt-model">InstructGPT Model</a>, <a href="../n/#natural-language-processing-nlp">Natural Language Processing</a>, [Pre-Trained Model], <a href="../r/#radiogpt">RadioGPT</a>, <a href="../w/#webgpt-model">WebGPT Model</a></p>
<h2 id="generator">Generator<a class="headerlink" href="#generator" title="Permanent link">#</a></h2>
<p>A neural network that generates music, image, something and is getting feedback from a Discriminator neural network. How does the generator generate images? Solution : The generator takes noise from latent space and further based on test and trial feedback , the generator keeps improvising on images. After a certain times of trial and error , the generator starts producing accurate images of a certain class which are quite difficult to differentiate from real images.</p>
<p>See also <a href="./">G</a>, [DeepComposer], <a href="../d/#discriminator">Discriminator</a>, [Generative Adversarial Network], <a href="./#generator-loss">Generator Loss</a>, <a href="../l/#latent-space">Latent Space</a></p>
<h2 id="generator-loss">Generator Loss<a class="headerlink" href="#generator-loss" title="Permanent link">#</a></h2>
<p>Typically when training any sort of model, it is a standard practice to monitor the value of the loss function throughout the duration of the training. The discriminator loss has been found to correlate well with sample quality. You should expect the discriminator loss to converge to zero and the generator loss to converge to some number which need not be zero. When the loss function plateaus, it is an indicator that the model is no longer learning. At this point, you can stop training the model. You can view these loss function graphs in the AWS DeepComposer console:</p>
<p><img alt="" src="../img/g/generator_loss.png" width="100%" /></p>
<p>After 400 epochs of training, discriminator loss approaches near zero and the generator converges to a steady-state value. Loss is useful as an evaluation metric since the model will not improve as much or stop improving entirely when the loss plateaus.</p>
<p>See also <a href="./">G</a>, <a href="../d/#discriminator-loss">Discriminator Loss</a>, <a href="../l/#loss-function">Loss Function</a>, <a href="../l/#loss-graph">Loss Graph</a></p>
<h2 id="genetic-programming">Genetic Programming<a class="headerlink" href="#genetic-programming" title="Permanent link">#</a></h2>
<p>Genetic programming is a technique to create algorithms that can program themselves by simulating biological breeding and Darwinian evolution. Instead of programming a model that can solve a particular problem, genetic programming only provides a general objective and lets the model figure out the details itself. The basic approach is to let the machine automatically test various simple evolutionary algorithms and then “breed” the most successful programs in new generations.</p>
<h2 id="genie-model">Genie Model<a class="headerlink" href="#genie-model" title="Permanent link">#</a></h2>
<p>~ the <a href="../w/#world-model">world model</a> developed by <a href="./#google-company">google</a></p>
<p>More at:</p>
<ul>
<li>co-lead ? - <a href="https://x.com/jparkerholder">https://x.com/jparkerholder</a></li>
<li>papers<ul>
<li>genie 1 - <a href="https://deepmind.google/research/publications/60474/">https://deepmind.google/research/publications/60474/</a></li>
<li>genie 2 - <a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/">https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="geoffrey-hinton-person">Geoffrey Hinton Person<a class="headerlink" href="#geoffrey-hinton-person" title="Permanent link">#</a></h2>
<p>Since 2013, he has divided his time working for Google (Google Brain) and the University of Toronto. In 2017, he co-founded and became the Chief Scientific Advisor of the Vector Institute in Toronto.</p>
<p>With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the <a href="../b/#backpropagation">backpropagation</a> algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The dramatic image-recognition milestone of the <a href="../a/#alexnet-model">AlexNet Model</a> designed in collaboration with his students <a href="../a/#alex-krizhevsky-person">Alex Krizhevsky</a> and <a href="../i/#ilya-sutskever-person">Ilya Sutskever</a> for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.</p>
<iframe src="https://www.youtube.com/embed/qpoRO378qRY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">https://en.wikipedia.org/wiki/Geoffrey_Hinton</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gini-impurity-index">GINI Impurity Index<a class="headerlink" href="#gini-impurity-index" title="Permanent link">#</a></h2>
<p>A metrics to measure how diverse the data is in a dataset.</p>
<ul>
<li>The more diverse the dataset is, the closer the GINI index is to 1 (but never equal to one)</li>
<li>The GINI index = 1 in the impossible case where all the elements in the dataset are different and the dataset is na infinite number of sample</li>
<li>The GINI index is 0 if all the samples in the dataset are the same (same label)</li>
</ul>
<iframe src="https://www.youtube.com/embed/u4IxOk2ijSs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<details>
<summary>Why is this important?</summary>
</details>
<p>See also <a href="./">G</a>, <a href="../d/#dataset">Dataset</a>, <a href="../f/#forest-of-stumps">Forest Of Stumps</a>, <a href="../w/#weighted-gini-impurity-index">Weighted Gini Impurity Index</a></p>
<h2 id="github-company">GitHub Company<a class="headerlink" href="#github-company" title="Permanent link">#</a></h2>
<p>Offers code repositories. An acquisition of <a href="../m/#microsoft-company">Microsoft</a></p>
<p>See also <a href="./">G</a>, <a href="./#github-copilot">GitHub Copilot</a></p>
<h2 id="github-copilot">GitHub Copilot<a class="headerlink" href="#github-copilot" title="Permanent link">#</a></h2>
<p>The <a href="../c/#codex-model">OpenAI Codex</a> integrated to <a href="./#github-company">GitHub</a> to suggest code and entire functions in real-time, right from your editor.</p>
<p>More at:</p>
<ul>
<li><a href="https://github.com/features/copilot">https://github.com/features/copilot</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="glide-model">GLIDE Model<a class="headerlink" href="#glide-model" title="Permanent link">#</a></h2>
<p>What adds the text conditioning to the diffusion model!?</p>
<iframe src="https://www.youtube.com/embed/lvv4N2nf-HU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2112.10741" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2112.10741">Download PDF</a>.
    </p>
</object>

<p>More at :</p>
<ul>
<li>blog - <a href="https://syncedreview.com/2021/12/24/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-173/">https://syncedreview.com/2021/12/24/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-173/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2112.10741">https://arxiv.org/abs/2112.10741</a></li>
<li>code <ul>
<li>github - <a href="https://github.com/openai/glide-text2im">https://github.com/openai/glide-text2im</a></li>
<li>notebooks - <a href="https://github.com/openai/glide-text2im/tree/main/notebooks">https://github.com/openai/glide-text2im/tree/main/notebooks</a></li>
</ul>
</li>
<li>articles<ul>
<li>how does DALL-E work? - <a href="https://www.assemblyai.com/blog/how-dall-e-2-actually-works/">https://www.assemblyai.com/blog/how-dall-e-2-actually-works/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, <a href="../d/#dall-e-model-family">DALL-E Model</a></p>
<h2 id="global-pooling-layer">Global Pooling Layer<a class="headerlink" href="#global-pooling-layer" title="Permanent link">#</a></h2>
<p>Global pooling reduces each channel in the feature map to a single value. Thus, an nh x nw x nc feature map is reduced to 1 x 1 x nc feature map. This is equivalent to using a filter of dimensions nh x nw i.e. the dimensions of the feature map. 
 Further, it can be either global max pooling or global average pooling.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GlobalMaxPooling2D</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GlobalAveragePooling2D</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="c1"># define input image</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>                  <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>                  <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="c1"># define gm_model containing just a single global-max pooling layer</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="n">gm_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>    <span class="p">[</span><span class="n">GlobalMaxPooling2D</span><span class="p">()])</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="c1"># define ga_model containing just a single global-average pooling layer</span>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="n">ga_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>    <span class="p">[</span><span class="n">GlobalAveragePooling2D</span><span class="p">()])</span>
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a><span class="c1"># generate pooled output</span>
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a><span class="n">gm_output</span> <span class="o">=</span> <span class="n">gm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="n">ga_output</span> <span class="o">=</span> <span class="n">ga_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a><span class="c1"># print output image</span>
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a><span class="n">gm_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">gm_output</span><span class="p">)</span>
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a><span class="n">ga_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">ga_output</span><span class="p">)</span>
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;gm_output: &quot;</span><span class="p">,</span> <span class="n">gm_output</span><span class="p">)</span>
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ga_output: &quot;</span><span class="p">,</span> <span class="n">ga_output</span><span class="p">)</span>
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="c1"># gm_output:  9.0</span>
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="c1"># ga_output:  4.0625</span>
</span></code></pre></div>
<p>More at:</p>
<ul>
<li><a href="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/">https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="global-vector-glove-algorithm">Global Vector (GloVe) Algorithm<a class="headerlink" href="#global-vector-glove-algorithm" title="Permanent link">#</a></h2>
<p>Global Vectors for Word Representation developed by the Stanford NLP Team, deprecated by <a href="../w/#word2vec-model">Word2Vec</a> ?</p>
<p>GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.</p>
<p>Released in 08/2014, updated in 2015</p>
<object data="https://nlp.stanford.edu/pubs/glove.pdf" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://nlp.stanford.edu/pubs/glove.pdf">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>site - <a href="https://nlp.stanford.edu/projects/glove/">https://nlp.stanford.edu/projects/glove/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../w/#word-embedding-space">Word Embedding Space</a></p>
<h2 id="gluon">Gluon<a class="headerlink" href="#gluon" title="Permanent link">#</a></h2>
<p>This is ...</p>
<h2 id="goal-conditioned-rl">Goal-Conditioned RL<a class="headerlink" href="#goal-conditioned-rl" title="Permanent link">#</a></h2>
<p>In [Reinforcement Learning (RL)], Train universal policies conditioned on goals. Generalizes to new goals.</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="good-old-fashioned-ai-gofai">Good Old-Fashioned AI (GOFAI)<a class="headerlink" href="#good-old-fashioned-ai-gofai" title="Permanent link">#</a></h2>
<p>See <a href="../s/#symbolic-ai">Symbolic AI</a></p>
<h2 id="google-company">Google Company<a class="headerlink" href="#google-company" title="Permanent link">#</a></h2>
<p>Model architecture developed by company</p>
<ul>
<li><a href="../p/#pathways-model-architecture">Pathways Model Architecture</a> -</li>
<li><a href="../t/#transformer-architecture">Transformer Architecture</a> -</li>
</ul>
<p>Hardware developed by company</p>
<ul>
<li><a href="../t/#tensor-processing-unit-tpu">Tensor Processing Unit (TPU)</a> - custom hardware for tensor arithmetic</li>
</ul>
<p>Models developed by the company</p>
<ul>
<li><a href="../a/#astra-model">Astra</a> - A model that has ears, eyes, and a voice and that comes with you everywhere you go</li>
<li><a href="../b/#bard-model">Bard</a> - A lightweight version of Lambda meant to compete against Bing + <a href="../c/#chatgpt-model">ChatGPT Model</a></li>
<li><a href="../d/#dreamix-model">DreamIX</a> - text-to-video and image-to-video diffusion model</li>
<li><a href="https://blog.google/technology/ai/google-project-gameface/">Gameface</a> - use your face in place of a mouse!</li>
<li><a href="./#gamengen-model">GameNGen</a> - 9/1/2024 - World first AI model that predicts next frame of a live shooter game, playable at 20 fps</li>
<li><a href="./#gemini-model">Gemini</a> - multimodal to enable future innovations like memory and planning</li>
<li><a href="./#gemma-model">Gemma</a> - Small Language Modeli deployable on desktops</li>
<li><a href="./#genie-model">Genie</a> - 12/1/2024 - world model for embodied agents </li>
<li><a href="./#graph-network-for-materials-exploration-gnome-model">Gnome</a> - Graph Network for materials exploration</li>
<li><a href="./#google-lens">Google Lens</a> - search what you see, uses cellphone cameras and <a href="../c/#computer-vision-cv">computer vision</a></li>
<li><a href="./#google-translate-model">Google Translate</a> - Translate one language into another, <a href="../m/#machine-translation">machine translation</a></li>
<li><a href="./#gshard-model">Gshard Model</a> -</li>
<li><a href="../i/#imagen-model-family">Imagen</a> - A text-to-image diffusion model</li>
<li><a href="../i/#imagen-video-model">Imagen Video</a> - A text-to-video model</li>
<li><a href="../m/#magi-model">Magi Model</a> - <a href="../b/#bard-model">Bard</a> with Ads!</li>
<li><a href="../m/#minerva-model">Minerva Model</a> -</li>
<li><a href="../m/#mum-model">MUM Model</a> - Use <a href="../t/#text-to-text-transfer-transformer-t5-model-family">T5 Model</a>, NLU and multimodal, 1000 more powerful than the <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT Model</a>. </li>
<li><a href="../m/#muse-model">Muse Model</a> -</li>
<li><a href="../m/#musiclm-model">MusicLM</a> - Generative model for music</li>
<li><a href="../p/#pathways-language-model-palm">PaLM Model</a> - The GPT3 equivalent, deprecated [LaMBDA]</li>
<li><a href="../p/#phenaki-model">Phenaki Model</a> - realistic video synthesis, given a sequence of textual prompts</li>
<li><a href="../s/#switch-transformer-model">Switch Transformer</a> -</li>
<li><a href="../t/#text-to-text-transfer-transformer-t5-model-family">T5 Model</a> -</li>
<li>[Veo] - Video generation model</li>
</ul>
<p>Utilities</p>
<ul>
<li><a href="../n/#notebooklm-utility">NotebookLM</a> - a notebook for research integrated with a LLM</li>
</ul>
<p>Superseded models</p>
<ul>
<li>2010: <a href="https://googleblog.blogspot.com/2010/01/helping-computers-understand-language.html">Helping computers understand language</a></li>
<li>2015: RankBrain</li>
<li>2018: Neural Matching</li>
<li>2019: <a href="../b/#bidirectional-encoder-representation-from-transformer-bert-model-family">BERT</a> - A <a href="../n/#natural-language-processing-nlp">natural language processing</a> model based on the <a href="../t/#transformer-architecture">transformer architecture</a> </li>
<li>2023: <a href="../l/#language-model-for-discussion-applications-lamda-model">LaMDA</a> - A large language model built for discussion applications, deprecated by PaLM</li>
</ul>
<p>Companies</p>
<ul>
<li><a href="../d/#deepmind-company">DeepMind</a> which built models such as <a href="../c/#chinchilla-model">Chinchilla</a>, <a href="../s/#sparrow-model">Sparrow</a>, [AlphaiFold], <a href="./#gencast-model">GenCast</a> and more ... </li>
<li><a href="../k/#kaggle-company">Kaggle</a> which also runs [KaggleX]</li>
</ul>
<p>Projects</p>
<ul>
<li><a href="https://experiments.withgoogle.com/">Experiments</a><ul>
<li><a href="https://experiments.withgoogle.com/collection/ai">AI Experiments</a></li>
<li><a href="https://quickdraw.withgoogle.com/">Quick Draw</a></li>
</ul>
</li>
<li><a href="https://teachablemachine.withgoogle.com/">Teachable Machine</a><ul>
<li>Pose project - <a href="https://medium.com/@warronbebster/teachable-machine-tutorial-head-tilt-f4f6116f491">https://medium.com/@warronbebster/teachable-machine-tutorial-head-tilt-f4f6116f491</a></li>
<li>Image project - <a href="https://medium.com/p/4bfffa765866">https://medium.com/p/4bfffa765866</a></li>
<li>Audio project - [<a href="https://medium.com/p/4212fd7f3555(https://medium.com/p/4212fd7f3555">https://medium.com/p/4212fd7f3555(https://medium.com/p/4212fd7f3555</a>)</li>
</ul>
</li>
</ul>
<iframe src="https://www.youtube.com/embed/X5iLF-cszu0?start=611" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>research blog - <a href="https://blog.research.google/">https://blog.research.google/</a></li>
<li>Google IO 2023 - <a href="https://blog.google/technology/developers/google-io-2023-100-announcements/">https://blog.google/technology/developers/google-io-2023-100-announcements/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../c/#company">Company</a></p>
<h2 id="google-lens">Google Lens<a class="headerlink" href="#google-lens" title="Permanent link">#</a></h2>
<p>Developed by <a href="./#google-company">Google</a>, ...</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="google-proof-questions-and-answers-gpqa-benchmark">Google-Proof Questions And Answers (GPQA) Benchmark<a class="headerlink" href="#google-proof-questions-and-answers-gpqa-benchmark" title="Permanent link">#</a></h2>
<p>We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are "Google-proof"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.</p>
<object data="https://arxiv.org/pdf/2311.12022" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2311.12022">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2311.12022">https://arxiv.org/abs/2311.12022</a></li>
<li>github - <a href="https://github.com/idavidrein/gpqa">https://github.com/idavidrein/gpqa</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../b/#benchmark">Benchmark</a></p>
<h2 id="google-translate-model">Google Translate Model<a class="headerlink" href="#google-translate-model" title="Permanent link">#</a></h2>
<p><mark>Google Translate started using a <a href="../s/#sequence-to-sequence-seq2seq-model">Seq2Seq</a>-based model in production in late 2016</mark></p>
<p>Google Translate is a multilingual neural machine translation service developed by <a href="./#google-company">Google</a> to translate text, documents and websites from one language into another. It offers a website interface, a mobile app for Android and iOS, and an API that helps developers build browser extensions and software applications. As of April 2023, Google Translate supports 133 languages at various levels, and as of April 2016, claimed over 500 million total users, with more than 100 billion words translated daily, after the company stated in May 2013 that it served over 200 million people daily.</p>
<p>Launched in April 2006 as a statistical machine translation service, it used United Nations and European Parliament documents and transcripts to gather linguistic data. Rather than translating languages directly, it first translates text to English and then pivots to the target language in most of the language combinations it posits in its grid, with a few exceptions including Catalan-Spanish. During a translation, it looks for patterns in millions of documents to help decide which words to choose and how to arrange them in the target language. Its accuracy, which has been criticized on several occasions, has been measured to vary greatly across languages. In November 2016, Google announced that Google Translate would switch to a neural machine translation engine – Google Neural Machine Translation (GNMT) – which translates "whole sentences at a time, rather than just piece by piece. It uses this broader context to help it figure out the most relevant translation, which it then rearranges and adjusts to be more like a human speaking with proper grammar".</p>
<iframe src="https://www.youtube.com/embed/_GdSC1Z1Kzs" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/TIG2ckcCh1Y" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li>site - <a href="https://translate.google.com/">https://translate.google.com/</a></li>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/Google_Translate">https://en.wikipedia.org/wiki/Google_Translate</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gopher-model">Gopher Model<a class="headerlink" href="#gopher-model" title="Permanent link">#</a></h2>
<p>NLP model developed by <a href="../d/#deepmind-company">DeepMind</a></p>
<p>~ 280 parameters with a transformer architecture. Was later optimized and resulted in the <a href="../c/#chinchilla-model">Chinchilla Model</a></p>
<iframe src="https://www.youtube.com/embed/nO653U-Pb5c" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2112.11446" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2112.11446">Download PDF</a>.
    </p>
</object>

<p>More at :</p>
<ul>
<li>blog - <a href="https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval">https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval</a></li>
<li>paper - <a href="https://arxiv.org/abs/2112.11446">https://arxiv.org/abs/2112.11446</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gpu-instance">GPU Instance<a class="headerlink" href="#gpu-instance" title="Permanent link">#</a></h2>
<p>P2 and P3 instances on AWS.</p>
<p>See also <a href="./">G</a>, [Graphical Processing Unit]</p>
<h2 id="gpu-technology-conference-gtc">GPU Technology Conference (GTC)<a class="headerlink" href="#gpu-technology-conference-gtc" title="Permanent link">#</a></h2>
<p>Annual conference organized by <a href="../n/#nvidia-company">Nvidia</a></p>
<p>The last conference was help on 2023/03/20 to 23.</p>
<p>Here are the highlights and the keynote.</p>
<iframe src="https://www.youtube.com/embed/tg332P3IfOU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/DiGB5uAYKAg" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.nvidia.com/gtc/">https://www.nvidia.com/gtc/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="grade-school-math-gsm8k-dataset">Grade School Math (GSM8K) Dataset<a class="headerlink" href="#grade-school-math-gsm8k-dataset" title="Permanent link">#</a></h2>
<p>GSM8K is a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers and financed by <a href="../o/#openai-company">OpenAI</a>. The dataset is segmented into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the final answer. A bright middle school student should be able to solve every problem. It can be used for multi-step mathematical reasoning.</p>
<object data="https://arxiv.org/pdf/2110.14168" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2110.14168">Download PDF</a>.
    </p>
</object>

<p>More at</p>
<ul>
<li>research and samples - <a href="https://openai.com/research/solving-math-word-problems">https://openai.com/research/solving-math-word-problems</a></li>
<li>paper - <a href="https://paperswithcode.com/paper/training-verifiers-to-solve-math-word">https://paperswithcode.com/paper/training-verifiers-to-solve-math-word</a></li>
<li>site - <a href="https://github.com/openai/grade-school-math">https://github.com/openai/grade-school-math</a></li>
<li>dataset - <a href="https://paperswithcode.com/dataset/gsm8k">https://paperswithcode.com/dataset/gsm8k</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../d/#dataset">Dataset</a>, <a href="../p/#pathways-language-model-palm">PaLM Model</a></p>
<h2 id="gradient">Gradient<a class="headerlink" href="#gradient" title="Permanent link">#</a></h2>
<p>A gradient is the direction and magnitude calculated during the training of a neural network it is used to teach the network weights in the right direction by the right amount.</p>
<p>See also <a href="./">G</a>, [Gradient Descent Algorithm]</p>
<h2 id="gradient-ascent-ga-algorithm">Gradient Ascent (GA) Algorithm<a class="headerlink" href="#gradient-ascent-ga-algorithm" title="Permanent link">#</a></h2>
<p>Maximize a function, unlike [gradient descent] which minimize a cost function.</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gradient-bagging">Gradient Bagging<a class="headerlink" href="#gradient-bagging" title="Permanent link">#</a></h2>
<p>~ <a href="../b/#bagging">bagging</a> but where each weak learner is built to correct errors of the previous ones/ensemble</p>
<p><a href="./#gradient-boosting">Gradient boosting</a> is an ensemble machine learning technique that combines multiple <a href="../w/#weak-learner">weak learners</a> (typically <a href="../d/#decision-tree">decision trees</a>) together to produce a strong predictive model. Bagging is another ensemble technique involving training <a href="../w/#weak-learner">weak learners</a> on different randomized subsets of the data. Gradient bagging combines these two methods:</p>
<ul>
<li>Like gradient boosting, it trains predictors sequentially, with each new tree correcting errors from the previous tree.</li>
<li>Like bagging, each tree is trained on a random subset of the data for diversity.</li>
<li>At each iteration, a subsample of the data is taken (without replacement), similar to bagging.</li>
<li>A new model is fit to the subsample, aiming to reduce the errors from previous models.</li>
<li>This continues for a specified number of iterations, adding models that complement each other.</li>
<li>The final prediction is obtained by aggregating the predictions from all the trained weak learners.</li>
</ul>
<p>Some key advantages of gradient bagging include:</p>
<ul>
<li>Reduces <a href="../o/#overfitting">overfitting</a> compared to gradient boosting alone.</li>
<li>Computationally efficient for training weak learners.</li>
<li>Captures complex interactions like gradient boosting.</li>
<li>Maintains model interpretability.</li>
</ul>
<p>Overall, gradient bagging combines the strengths of bagging and gradient boosting to produce robust, accurate and interpretable ensembles for prediction tasks.</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gradient-boosting">Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permanent link">#</a></h2>
<p>~ <a href="../b/#boosting">boosting</a> but where each new weak learner is built to correct errors of the previous ones/ensemble.</p>
<p>Gradient boosting is one of the variants of <a href="../e/#ensemble-method">ensemble methods</a> where you create multiple weak models and combine them to get better performance as a whole.</p>
<p>Popular algorithms:</p>
<ul>
<li><a href="../e/#extreme-gradient-boosting-xgboost">XGBoost</a></li>
<li><a href="../l/#light-gradient-boosting-machine-lightgbm">LightGBM</a></li>
<li><a href="../c/#catboost-python-module">CatBoost</a></li>
</ul>
<p>More at:</p>
<ul>
<li>wikipedia - <a href="https://en.wikipedia.org/wiki/Gradient_boosting">https://en.wikipedia.org/wiki/Gradient_boosting</a></li>
<li>articles<ul>
<li>regressions - <a href="https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502">https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502</a></li>
<li>classifications - <a href="https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-2-classification-d3ed8f56541e">https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-2-classification-d3ed8f56541e</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, <a href="../b/#boosting">Boosting</a>, <a href="../e/#ensemble-method">Ensemble Method</a>, <a href="./#gradient-bagging">Gradient Bagging</a>, <a href="../w/#weak-learner">Weak Learner</a></p>
<h2 id="gradient-checkpoint">Gradient Checkpoint<a class="headerlink" href="#gradient-checkpoint" title="Permanent link">#</a></h2>
<p>See [Activation Checkpoint]</p>
<h2 id="gradient-clipping">Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="Permanent link">#</a></h2>
<p>A technique to prevent exploding gradients in very deep networks, usually in recurrent neural networks. Gradient Clipping is a method where the error derivative is changed or clipped to a threshold during backward propagation through the network, and using the clipped gradients to update the weights.</p>
<p>Gradient Clipping is implemented in two variants:</p>
<ul>
<li>Clipping-by-value</li>
<li>Clipping-by-norm</li>
</ul>
<p>Benefits ?</p>
<p>More at: </p>
<ul>
<li><a href="https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48">https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48</a></li>
<li>gradient clipping accelerate learning? - <a href="https://openreview.net/pdf?id=BJgnXpVYwS">https://openreview.net/pdf?id=BJgnXpVYwS</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../e/#exploding-gradient-problem">Exploding Gradient Problem</a>, [Gradient Descent Algorithm], [Recurring Neural Network]</p>
<h2 id="gradient-descent-gd-algorithm">Gradient Descent (GD) Algorithm<a class="headerlink" href="#gradient-descent-gd-algorithm" title="Permanent link">#</a></h2>
<p>One of the shining successes in machine learning is the gradient descent algorithm (and its modified counterpart, stochastic gradient descent). Gradient descent is an iterative method for finding the minimum of a function. In machine learning, that function is typically the loss (or cost) function. "Loss" is simply some metric that quantifies the cost of wrong predictions. Gradient descent calculates the loss achieved by a model with a given set of parameters, and then alters those parameters to reduce the loss. It repeats this process until that loss can't substantially be reduced further. The final set of parameters that minimize the loss now define your fitted model. </p>
<iframe src="https://www.youtube.com/embed/OkmNXy7er84" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>Gradient descent algorithms and derivatives</p>
<ul>
<li><a href="../s/#stochastic-gradient-descent-sgd-algorithm">Stochastic Gradient Descent (SGD)</a></li>
<li><a href="./#gradient-descent-with-momentum-gdwm-algorithm">Gradient descent with momentum (GDwM)</a></li>
<li>nesterov accelerated gradient</li>
<li>[Adaptive Gradient (AdaGrad)]</li>
<li>[AdaDelta Gradient (AdaDelta)]</li>
<li>[Adaptive Momentum Estimation (Adam)]</li>
<li>[Root Mean Square Propagation (RMSprop)]</li>
<li>nag ?</li>
</ul>
<iframe src="https://www.youtube.com/embed/nhqo0u1a6fw" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/4F0_V_0OO2Q" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p><img alt="" src="../img/g/gradient_descent.png" width="100%" /></p>
<p><mark>Using gradient descent, you can find the regression line that best fit the sample using a loss function</mark> (distance of sample from line). To do that, you can start with any line and calculate the loss function, as you move the parameter, the loss function become smaller and smaller indicating in which direction the parameter should go.</p>
<div class="admonition warning">
<p class="admonition-title">On huge datasets, There are downsides of the gradient descent algorithm. Indeed for huge datasets, we need to take a huge amount of computation we make for each iteration of the algorithm. To alleviate the problem, possible solutions are:</p>
<ul>
<li>batch data for lighter partial processing (= standard gradient descent) <img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> compute intensive for large datasets</li>
<li>mini-batch ... = uses all the data in batches (= best of all proposed alternatives?)</li>
<li>data sampling or stochastic gradient descent. (= lower compute required since we use only a few sample, but faster iteration with slower convergence st each step, but faster overall?)</li>
</ul>
</div>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21">https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../a/#activation-function">Activation Function</a>, <a href="../b/#batch-gradient-descent-algorithm">Batch Gradient Descent Algorithm</a>, <a href="./#gradient-perturbation">Gradient Perturbation</a>, <a href="../l/#learning-rate">Learning Rate</a>, <a href="../l/#loss-function">Loss Function</a>, <a href="../m/#mini-batch-gradient-descent-algorithm">Mini-Batch Gradient Descent Algorithm</a>, <a href="../p/#parameter">Parameter</a>, <a href="../p/#prediction-error">Prediction Error</a>, [Stochastic Gradient Descent Algorithm]</p>
<h2 id="gradient-descent-with-momentum-gdwm-algorithm">Gradient Descent with Momentum (GDwM) Algorithm<a class="headerlink" href="#gradient-descent-with-momentum-gdwm-algorithm" title="Permanent link">#</a></h2>
<p>In the context of <a href="./#gradient-descent-gd-algorithm">Gradient Descent (GD)</a>, momentum is a technique that helps the algorithm to converge faster and more consistently by reducing the oscillation of the updates to the model parameters.</p>
<p>The momentum technique introduces a new parameter called momentum coefficient, which determines the contribution of the previous updates to the current update. Instead of computing the update at each iteration solely based on the gradient, the momentum technique calculates an exponentially weighted average of the past gradients and uses it to update the model parameters.</p>
<p>This helps to smooth out the updates and prevent the model from getting stuck in local optima. It also helps to accelerate the convergence in directions where the gradient changes sign frequently, by preserving the momentum of the gradient in the previous iterations.</p>
<p>The momentum technique is particularly useful in deep learning where the optimization problem is complex and high-dimensional, and the gradient can be noisy or sparse. It is often used in combination with other optimization techniques such as <a href="../a/#adaptive-moment-adam-estimation-algorithm">Adam</a>, <a href="../a/#adaptive-gradient-adagrad-algorithm">Adagrad</a>, and <a href="../r/#root-mean-square-propagation-rmsprop-algorithm">Root Mean Square Propagation (RMSProp)</a> to further improve the performance of the gradient descent algorithm.</p>
<iframe src="https://www.youtube.com/embed/k8fTYJPd3_I" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/gradient-descent-with-momentum-59420f626c8f">https://towardsdatascience.com/gradient-descent-with-momentum-59420f626c8f</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gradient-perturbation">Gradient Perturbation<a class="headerlink" href="#gradient-perturbation" title="Permanent link">#</a></h2>
<p>Works for neural network only or where gradient descent is used. Better than output perturbation in that the noise is built in the model, so you can share the model at will ;-) Gradient perturbation, widely used for differentially private optimization, injects noise at every iterative update to guarantee differential privacy. Noise is included in the gradient descent!</p>
<p>More at:</p>
<ul>
<li>[<a href="https://www.ijcai.org/Proceedings/2020/431}(https://www.ijcai.org/Proceedings/2020/431">https://www.ijcai.org/Proceedings/2020/431}(https://www.ijcai.org/Proceedings/2020/431</a>)</li>
<li>deep learning with differential privacy paper - <a href="https://arxiv.org/abs/1607.00133">https://arxiv.org/abs/1607.00133</a></li>
<li>paper - <a href="https://www.microsoft.com/en-us/research/publication/gradient-perturbation-is-underrated-for-differentially-private-convex-optimization/">https://www.microsoft.com/en-us/research/publication/gradient-perturbation-is-underrated-for-differentially-private-convex-optimization/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../d/#differential-privacy">Differential Privacy</a>, <a href="./#gradient-clipping">Gradient Clipping</a>, <a href="../o/#output-perturbation">Output Perturbation</a></p>
<h2 id="gradio-python-module">Gradio Python Module<a class="headerlink" href="#gradio-python-module" title="Permanent link">#</a></h2>
<p>A <a href="../p/#python-module">python module</a> to build a UI for machine learning models.</p>
<p>Compatible with <a href="../h/#hugging-face-company">Hugging Face</a> Spaces.</p>
<iframe src="https://www.youtube.com/embed/RiCQzBluTxU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://www.gradio.app/">https://www.gradio.app/</a></li>
<li>quickstart - <a href="https://www.gradio.app/quickstart/">https://www.gradio.app/quickstart/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph">Graph<a class="headerlink" href="#graph" title="Permanent link">#</a></h2>
<p>A representation of items or nodes, linked by relations or edges</p>
<p>Good representation for</p>
<ul>
<li>molecule</li>
<li>social network</li>
<li>knowledge graph</li>
<li>3D meshes</li>
<li>the internet</li>
<li>the brain</li>
<li>...</li>
</ul>
<p><img alt="" src="../img/g/graph.png" width="100%" /></p>
<p><img alt="" src="../img/g/graph_family_tree.png" width="100%" /></p>
<p><img alt="" src="../img/g/graph_image.png" width="100%" /></p>
<p>Algorithms</p>
<ul>
<li><a href="../l/#link-prediction">Link prediction</a> for recommendation engine</li>
<li><a href="../n/#node-classification">Node classification</a> is for assigning labels to nodes</li>
<li><a href="./#graph-classification">Graph classification</a> is for assigning labels to graph like coworkers, school friends, etc.</li>
</ul>
<p><img alt="" src="../img/g/graph_algorithms.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a">https://towardsdatascience.com/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph-classification">Graph Classification<a class="headerlink" href="#graph-classification" title="Permanent link">#</a></h2>
<p>Graph classification refers to the task of assigning categories or labels to entire graphs. Some key points:</p>
<ul>
<li>In graph classification, the samples are entire graphs or networks. The goal is to categorize each graph into a class. This contrasts node-level and edge-level prediction tasks.</li>
<li>For example, graph classification can categorize social networks into types (college friends, work colleagues etc), molecular graph structures into activity classes, or assign genres to graph representations of texts.</li>
<li>A major application of graph classification is in predicting properties and characteristics of molecules based on their chemical compound graph structure.</li>
<li>Typical pipeline involves extracting informative numeric graph-level representations from each graph (graph embeddings), then training a machine learning classifier model on the graph embeddings and graph labels.</li>
<li>Common techniques for representing whole graphs as feature vectors/embeddings include graph kernels, graph neural networks, etc. These capture structural properties of the entire graph beyond individual nodes and edges.</li>
<li>Classical machine learning models like random forests and neural networks can be used for the actual graph categorization once suitable embeddings are extracted.</li>
</ul>
<p>In summary, graph classification focuses on categorizing entire graphs into certain classes, by extracting graph-level signatures and training classifiers over labeled graph datasets. This contrasts with node and edge level prediction tasks common in graphical machine learning.</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph-convolutional-network-gcn">Graph Convolutional Network (GCN)<a class="headerlink" href="#graph-convolutional-network-gcn" title="Permanent link">#</a></h2>
<p>More at 
  * <a href="https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780">https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780</a></p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph-data-science-gds">Graph Data Science (GDS)<a class="headerlink" href="#graph-data-science-gds" title="Permanent link">#</a></h2>
<p>Language used by the open-source neo4j graph database.</p>
<p>More at:</p>
<ul>
<li><a href="https://neo4j.com/docs/graph-data-science/current/">https://neo4j.com/docs/graph-data-science/current/</a></li>
<li>articles<ul>
<li><a href="https://towardsdatascience.com/getting-started-with-graph-embeddings-2f06030e97ae">https://towardsdatascience.com/getting-started-with-graph-embeddings-2f06030e97ae</a></li>
</ul>
</li>
</ul>
<h2 id="graph-database">Graph Database<a class="headerlink" href="#graph-database" title="Permanent link">#</a></h2>
<ul>
<li><a href="../n/#neo4j-graph-database">Neo4j</a> --&gt; use [GDS] and [openCypher] language</li>
<li>AWS Neptune --&gt; [DGL] and [Gremlin]</li>
<li>TigerGraph  --&gt; [GSQL]</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph-embedding">Graph Embedding<a class="headerlink" href="#graph-embedding" title="Permanent link">#</a></h2>
<p>~ turn the nodes of a network graph into a vectors</p>
<ul>
<li><a href="../n/#node2vec-model">Node2Vec</a></li>
<li><a href="../d/#deepwalk">DeepWalk</a></li>
<li><a href="../f/#fast-random-projection-fastrp">FastRP</a></li>
</ul>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/getting-started-with-graph-embeddings-2f06030e97ae">https://towardsdatascience.com/getting-started-with-graph-embeddings-2f06030e97ae</a></li>
<li>visualization with t-SNE - <a href="https://towardsdatascience.com/visualizing-graph-embeddings-with-t-sne-in-python-10227e7876aa">https://towardsdatascience.com/visualizing-graph-embeddings-with-t-sne-in-python-10227e7876aa</a></li>
</ul>
<h2 id="graph-machine-learning-gml">Graph Machine Learning (GML)<a class="headerlink" href="#graph-machine-learning-gml" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li><a href="https://www.uber.com/blog/uber-eats-graph-learning/">https://www.uber.com/blog/uber-eats-graph-learning/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graph-network-for-materials-exploration-gnome-model">Graph Network For Materials Exploration (GNoME) Model<a class="headerlink" href="#graph-network-for-materials-exploration-gnome-model" title="Permanent link">#</a></h2>
<p><img alt="" src="../img/g/graph_network_for_materials_exploration_model.webp" width="100%" /></p>
<p>More at;</p>
<ul>
<li>papers<ul>
<li>Nature - <a href="https://www.nature.com/articles/s41586-023-06735-9">https://www.nature.com/articles/s41586-023-06735-9</a></li>
<li>Berkeley - <a href="https://www.nature.com/articles/s41586-023-06734-w">https://www.nature.com/articles/s41586-023-06734-w</a></li>
</ul>
</li>
<li>dataset - <a href="https://github.com/google-deepmind/materials_discovery">https://github.com/google-deepmind/materials_discovery</a></li>
<li>data <ul>
<li>the materials project - <a href="https://next-gen.materialsproject.org/">https://next-gen.materialsproject.org/</a></li>
</ul>
</li>
<li>articles<ul>
<li>announcement - <a href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/">https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, <a href="../m/#matbench-discovery-benchmark">Matbench Discovery Benchmark</a></p>
<h2 id="graph-neural-network-gnn">Graph Neural Network (GNN)<a class="headerlink" href="#graph-neural-network-gnn" title="Permanent link">#</a></h2>
<p>Use graph relationship to ... GNNs are used to train predictive models on datasets such as:</p>
<ul>
<li>Social networks, where graphs show connections between related people,</li>
<li>Recommender systems, where graphs show interactions between customers and items,</li>
<li>Chemical analysis, where compounds are modeled as graphs of atoms and bonds,</li>
<li>Cybersecurity, where graphs describe connections between source and destination IP addresses,</li>
<li>And more!</li>
</ul>
<p>Ex: Most of the time, these datasets are extremely large and only partially labeled. Consider a fraud detection scenario where we would try to predict the likelihood that an individual is a fraudulent actor by analyzing his connections to known fraudsters. This problem could be defined as a semi-supervised learning task, where only a fraction of graph nodes would be labeled (‘fraudster’ or ‘legitimate’). This should be a better solution than trying to build a large hand-labeled dataset, and “linearizing” it to apply traditional machine learning algorithms.</p>
<iframe src="https://www.youtube.com/embed/9QH6jnwqrAk" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>More at:</p>
<ul>
<li><a href="https://distill.pub/2021/gnn-intro/">https://distill.pub/2021/gnn-intro/</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../e/#entity-extraction">Entity Extraction</a>, <a href="./#graph-neural-network-gnn-edge-level-task">GNN Edge-Level Task</a>, [GNN Graph-Level Task], <a href="./#graph-neural-network-gnn-node-level-task">GNN Node-Level Task</a>, <a href="../i/#insufficient-data-algorithm">Insufficient Data Algorithm</a>, [Knowledge Graph], <a href="../r/#relation-extraction">Relation Extraction</a>, <a href="../s/#scene-graph">Scene Graph</a></p>
<h2 id="graph-neural-network-gnn-edge-level-task">Graph Neural Network (GNN) Edge-Level Task<a class="headerlink" href="#graph-neural-network-gnn-edge-level-task" title="Permanent link">#</a></h2>
<p>One example of edge-level inference is in image scene understanding. Beyond identifying objects in an image, deep learning models can be used to predict the relationship between them. We can phrase this as an edge-level classification: given nodes that represent the objects in the image, we wish to predict which of these nodes share an edge or what the value of that edge is. If we wish to discover connections between entities, we could consider the graph fully connected and based on their predicted value prune edges to arrive at a sparse graph.</p>
<p><img alt="" src="../img/g/graph_neural_network_edge_level_task.png" width="100%" /></p>
<p>In (b), above, the original image (a) has been segmented into five entities: each of the fighters, the referee, the audience and the mat. (C) shows the relationships between these entities.</p>
<p><img alt="" src="../img/g/graph_neural_network_edge_level_task2.png" width="100%" /></p>
<p>See also <a href="./">G</a>, [Graph Neural Network]</p>
<h2 id="graph-neural-network-gnn-graph-level-task">Graph Neural Network (GNN) Graph Level Task<a class="headerlink" href="#graph-neural-network-gnn-graph-level-task" title="Permanent link">#</a></h2>
<p>In a graph-level task, our goal is to predict the property of an entire graph. For example, for a molecule represented as a graph, we might want to predict what the molecule smells like, or whether it will bind to a receptor implicated in a disease.</p>
<p><img alt="" src="../img/g/graph_neural_network_graph_level_task.png" width="100%" /></p>
<p>This is analogous to image classification problems with MNIST and CIFAR, where we want to associate a label to an entire image. With text, a similar problem is sentiment analysis where we want to identify the mood or emotion of an entire sentence at once.</p>
<p>See also <a href="./">G</a>, [Graph Neural Network]</p>
<h2 id="graph-neural-network-gnn-node-level-task">Graph Neural Network (GNN) Node-Level Task<a class="headerlink" href="#graph-neural-network-gnn-node-level-task" title="Permanent link">#</a></h2>
<p>Node-level tasks are concerned with predicting the identity or role of each node within a graph. A classic example of a node-level prediction problem is Zach’s karate club. The dataset is a single social network graph made up of individuals that have sworn allegiance to one of two karate clubs after a political rift. As the story goes, a feud between Mr. Hi (Instructor) and John H (Administrator) creates a schism in the karate club. The nodes represent individual karate practitioners, and the edges represent interactions between these members outside of karate. The prediction problem is to classify whether a given member becomes loyal to either Mr. Hi or John H, after the feud. In this case, distance between a node to either the Instructor or Administrator is highly correlated to this label.</p>
<p><img alt="" src="../img/g/graph_neural_network_node_level_task.png" width="100%" /></p>
<p>On the left we have the initial conditions of the problem, on the right we have a possible solution, where each node has been classified based on the alliance. The dataset can be used in other graph problems like unsupervised learning.</p>
<p>Following the image analogy, node-level prediction problems are analogous to image segmentation, where we are trying to label the role of each pixel in an image. With text, a similar task would be predicting the parts-of-speech of each word in a sentence (e.g. noun, verb, adverb, etc).</p>
<p>See also <a href="./">G</a>, [Graph Neural Network]</p>
<h2 id="graphical-processing-unit-gpu">Graphical Processing Unit (GPU)<a class="headerlink" href="#graphical-processing-unit-gpu" title="Permanent link">#</a></h2>
<p>To accelerate processing of data.</p>
<p>The move of AI/ML from CPU to GPU was done when <a href="../a/#alexnet-model">AlexNet Model</a> solved the [ImageNet Large Scale Visual Recognition Challenge] in 09/30/2012</p>
<p><img alt="" src="../img/g/graphical_processing_unit_scaling.webp" width="100%" /></p>
<p>{% youtube "<a href="https://youtu.be/Axd50ew4pco?si=xCAag1Lx43z0SsIz">https://youtu.be/Axd50ew4pco?si=xCAag1Lx43z0SsIz</a>" %}</p>
<p>More at:</p>
<ul>
<li><a href="https://www.nature.com/articles/s41586-021-04362-w">https://www.nature.com/articles/s41586-021-04362-w</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../c/#central-processing-unit-cpu">CPU</a>, [Cuda Core], [Hyperparameter Optimization], <a href="../t/#tensor-processing-unit-tpu">TPU</a></p>
<h2 id="graphical-processing-unit-gpu-kernel">Graphical Processing Unit (GPU) Kernel<a class="headerlink" href="#graphical-processing-unit-gpu-kernel" title="Permanent link">#</a></h2>
<p>A process running on a GPU is called a kernel!</p>
<p>A GPU kernel is a piece of code that is executed in parallel by multiple threads on an accelerator such as a GPU. These kernels are designed to handle highly parallelizable tasks that take advantage of the many cores present in modern GPUs.</p>
<p>Another way of looking at a GPU kernel is as a function that can be called from a host program to perform calculations or other operations on the GPU. These functions are optimized for execution efficiency on the GPU, usually by breaking large tasks down into smaller sub-tasks that can be executed in parallel by multiple threads.</p>
<p>GPU kernels are widely employed in graphics processing, scientific computing, machine learning, and other high-performance computing applications. By offloading computational tasks to the GPU, these programs can achieve significant performance gains compared to running identical code on a CPU.</p>
<p>They’re particularly beneficial when dealing with large data sets requiring lots of computation since they take advantage of the parallel processing power of GPUs to accelerate operations and reduce overall execution time.</p>
<p>More at:</p>
<ul>
<li><a href="https://www.wepc.com/gpu/faq/what-is-a-gpu-kernel/">https://www.wepc.com/gpu/faq/what-is-a-gpu-kernel/</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graphical-processing-unit-high-bandwidth-memory-gpu-hbm">Graphical Processing Unit High Bandwidth Memory (GPU-HBM)<a class="headerlink" href="#graphical-processing-unit-high-bandwidth-memory-gpu-hbm" title="Permanent link">#</a></h2>
<p>~ the slower type of in-GPU memory (1.5 TB/s with 40GB size)</p>
<p>The other memory is [GPU Static Random Access Memory (GPU-SRAM)]</p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graphical-processing-unit-gpu-memory">Graphical Processing Unit (GPU) Memory<a class="headerlink" href="#graphical-processing-unit-gpu-memory" title="Permanent link">#</a></h2>
<p>2 types:</p>
<ul>
<li>[GPU Static Random Access (GPU-SRAM)]</li>
<li><a href="./#graphical-processing-unit-high-bandwidth-memory-gpu-hbm">GPU High Bandwidth Memory (GPU-HBM)</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graphical-processing-unit-static-random-access-memory-gpu-sram">Graphical Processing Unit Static Random Access Memory (GPU-SRAM)<a class="headerlink" href="#graphical-processing-unit-static-random-access-memory-gpu-sram" title="Permanent link">#</a></h2>
<p>~ the fastest type of in-GPU memory (19TB/s but 20 MB size)</p>
<p>The other GPU memory type is <a href="./#graphical-processing-unit-high-bandwidth-memory-gpu-hbm">GPU High Bandwidth Memory (GPU-HBM)</a></p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="graphrag-system">GraphRAG System<a class="headerlink" href="#graphrag-system" title="Permanent link">#</a></h2>
<p>~ a type of [Retrieval-Augmented Generation] that retrieves the most relevant information from the knowledge graph and uses it to condition the LLM’s response, improving accuracy and reducing hallucinations.</p>
<p>GraphRAG uses knowledge graphs to provide substantial improvements in question-and-answer performance when reasoning about complex information. RAG techniques have shown promise in helping <a href="../l/#large-language-model-llm">LLMs</a> to reason about private <a href="../d/#dataset">datasets</a> - data that the LLM is not trained on and has never seen before, such as an enterprise’s proprietary research, business documents, or communications.</p>
<iframe src="https://www.youtube.com/embed/f6pUqDeMiG0" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<object data="https://arxiv.org/pdf/2404.16130" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2404.16130">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>code - <a href="https://github.com/microsoft/graphrag">https://github.com/microsoft/graphrag</a></li>
<li>docs - <a href="https://microsoft.github.io/graphrag/">https://microsoft.github.io/graphrag/</a></li>
<li>paper - <a href="https://arxiv.org/abs/2404.16130">https://arxiv.org/abs/2404.16130</a></li>
<li>articles<ul>
<li>annoucement - <a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/">https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/</a></li>
<li>GraphRAG vs baseline RAG - <a href="https://microsoft.github.io/graphrag/#graphrag-vs-baseline-rag">https://microsoft.github.io/graphrag/#graphrag-vs-baseline-rag</a></li>
<li>Narrative private data - <a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/</a></li>
<li>How GraphRAG works - <a href="https://medium.com/data-science-in-your-pocket/what-is-graphrag-1ee1cc9027a4">https://medium.com/data-science-in-your-pocket/what-is-graphrag-1ee1cc9027a4</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, [Knowledge Graph]</p>
<h2 id="greedy-decoding">Greedy Decoding<a class="headerlink" href="#greedy-decoding" title="Permanent link">#</a></h2>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="greedy-sampling">Greedy Sampling<a class="headerlink" href="#greedy-sampling" title="Permanent link">#</a></h2>
<p>~ an approach to select a sample among a sample distribution: always take the sample with the highest probability. An alternative to <a href="../r/#random-sampling">random sampling</a>.</p>
<p>During model inference, the model produces a probability distribution across all tokens in the model’s known vocabulary. The model chooses—or samples—a single token from this distribution as the next token to include in the response.</p>
<p>Most generative model-inference implementations default to greedy sampling, also called greedy decoding. This is the simplest form of next-token prediction, as the model always chooses the word with the highest probability. This method works well for very short generations but may result in repeated tokens or sequences of tokens.</p>
<p><img alt="" src="../img/g/greedy_sampling.png" width="100%" /></p>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="greg-brockman-person">Greg Brockman Person<a class="headerlink" href="#greg-brockman-person" title="Permanent link">#</a></h2>
<iframe src="https://www.youtube.com/embed/YtJEfTTD_Y4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">G</a>, ...</p>
<h2 id="grid-search">Grid Search<a class="headerlink" href="#grid-search" title="Permanent link">#</a></h2>
<p>It’s tricky to find the optimal value for hyperparameters. The simplest solution is to try a bunch of combinations and see what works best. This idea of creating a “grid” of parameters and just trying out all the possible combinations is called a Grid Search.</p>
<p><img alt="⚠" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" title=":warning:" /> Beware of combinatorial growth or the <a href="../c/#curse-of-dimensionality">curse of dimensionality</a></p>
<p><img alt="" src="../img/g/grid_search.webp" width="100%" /></p>
<p>More at:</p>
<ul>
<li><a href="https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d">https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d</a></li>
</ul>
<p>See also <a href="./">G</a>, [Hyperparameter Optimization], <a href="../r/#random-search">Random Search</a></p>
<h2 id="grok-llm">Grok LLM<a class="headerlink" href="#grok-llm" title="Permanent link">#</a></h2>
<p>An LLM build by <a href="../x/#xai-company">xAI</a></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>Grok is an AI modeled after the Hitchhiker’s Guide to the Galaxy, so intended to answer almost anything and, far harder, even suggest what questions to ask!
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>Grok is designed to answer questions with a bit of wit and has a rebellious streak, so please don’t use it if you hate humor!
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>A unique and fundamental advantage of Grok is that it has real-time knowledge of the world via the 𝕏 platform. It will also answer spicy questions that are rejected by most other AI systems.
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>Grok is still a very early beta product – the best we could do with 2 months of training – so expect it to improve rapidly with each passing week with your help.
</span></code></pre></div>
<p>More at:</p>
<ul>
<li>GROK 1 announcement - <a href="https://x.ai/">https://x.ai/</a></li>
<li>Elon Musk on Tweeter - <a href="https://twitter.com/elonmusk/status/1720660977786433810">https://twitter.com/elonmusk/status/1720660977786433810</a></li>
<li>code - <a href="https://github.com/xai-org/grok-1">https://github.com/xai-org/grok-1</a></li>
<li>articles<ul>
<li>open release - <a href="https://www.theverge.com/2024/3/17/24097810/xai-open-source-grok-musk-generative-ai-llm">https://www.theverge.com/2024/3/17/24097810/xai-open-source-grok-musk-generative-ai-llm</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="grokking">Grokking<a class="headerlink" href="#grokking" title="Permanent link">#</a></h2>
<p>~ changing regime from memorization to generalization</p>
<p><img alt="" src="../img/g/grokking.png" width="100%" /></p>
<object data="https://arxiv.org/pdf/2201.02177" type="application/pdf" width="100%" height="600px">
    <p>Your browser does not support PDFs. Please download the PDF: 
       <a href="https://arxiv.org/pdf/2201.02177">Download PDF</a>.
    </p>
</object>

<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2201.02177">https://arxiv.org/abs/2201.02177</a></li>
<li><a href="https://pair.withgoogle.com/explorables/grokking/">https://pair.withgoogle.com/explorables/grokking/</a></li>
<li>book - <a href="https://www.manning.com/books/grokking-machine-learning">https://www.manning.com/books/grokking-machine-learning</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="groq-company">Groq Company<a class="headerlink" href="#groq-company" title="Permanent link">#</a></h2>
<p>First company to develop <a href="../l/#language-processing-unit-lpu">Language Processing Unit (LPU)</a></p>
<p>More at:</p>
<ul>
<li>LLM UI -  <a href="https://wow.groq.com/">https://wow.groq.com/</a></li>
<li>articles<ul>
<li><a href="https://www.forbes.com/sites/amyfeldman/2021/04/14/ai-chip-startup-groq-founded-by-ex-googlers-raises-300-million-to-power-autonomous-vehicles-and-data-centers/">https://www.forbes.com/sites/amyfeldman/2021/04/14/ai-chip-startup-groq-founded-by-ex-googlers-raises-300-million-to-power-autonomous-vehicles-and-data-centers/</a></li>
<li><a href="https://futurumgroup.com/insights/groq-ushers-in-a-new-ai-compute-paradigm-the-language-processing-unit/">https://futurumgroup.com/insights/groq-ushers-in-a-new-ai-compute-paradigm-the-language-processing-unit/</a></li>
</ul>
</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="ground-truth">Ground Truth<a class="headerlink" href="#ground-truth" title="Permanent link">#</a></h2>
<p>In machine learning, ground truth refers to the accurate and reliable information about the target values or outcomes of a dataset, which is used to train, validate, and assess the performance of machine learning models. Ground truth data provides a basis for comparison, allowing machine learning algorithms to learn patterns and make predictions.</p>
<p>Here's how ground truth is used in machine learning:</p>
<ul>
<li>Training: During the training phase, a machine learning model learns from a dataset that includes input features and corresponding ground truth labels. The model adjusts its internal parameters to minimize the discrepancy between its predictions and the ground truth labels.</li>
<li>Validation: After training, the model's performance is assessed using a validation dataset that also contains ground truth labels. This helps determine how well the model generalizes to new, unseen data.</li>
<li>Testing and Evaluation: Once the model is trained and validated, it's tested on a separate testing dataset with ground truth labels. This final evaluation helps measure the model's real-world performance and its ability to make accurate predictions.</li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="group-relative-policy-optimization-grpo-algorithm">Group Relative Policy Optimization (GRPO) Algorithm<a class="headerlink" href="#group-relative-policy-optimization-grpo-algorithm" title="Permanent link">#</a></h2>
<p>A <a href="../p/#policy-gradient-algorithm">policy gradient algorithm</a> that ...</p>
<p><img alt="" src="../img/g/group_relative_policy_optimization.webp" width="100%" /></p>
<p><img alt="" src="../img/g/group_relative_policy_optimization_vs_ppo.webp" width="100%" /></p>
<iframe src="https://www.youtube.com/embed/VUzA1UHWsF4" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/bEcE2bVXbJI" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/lt5qBi1LtkM" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/L6sA6qMDMuY" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<iframe src="https://www.youtube.com/embed/0d9t82kn1rU" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>

<p>See also <a href="./">G</a>, ...</p>
<h2 id="grouped-query-attention-gqa">Grouped-Query Attention (GQA)<a class="headerlink" href="#grouped-query-attention-gqa" title="Permanent link">#</a></h2>
<p>~ a technique that helps getting faster inferences</p>
<p>Grouped query attention is a technique used in some neural network architectures, particularly in natural language processing models like transformers.</p>
<p>Used by:</p>
<ul>
<li><a href="../m/#mistral-model">Mistral Models</a></li>
</ul>
<p>The key ideas behind grouped query attention are:</p>
<ul>
<li>Attention mechanisms allow a model to learn what parts of an input to focus on by having later layers give different weights to earlier parts of the input. This helps the model learn complex relationships.</li>
<li>In the standard transformer model, the attention is applied one word at a time across the whole input sequence. This can be inefficient for very long sequences.</li>
<li>Grouped query attention divides the sequence into groups (chunks) and applies attention within each group separately. So each word attends only to other words in its group rather than across the whole sequence.</li>
<li>This reduces the overall computation required for attention while still allowing important context to be incorporated within each group.</li>
<li>The groups/chunks can either be pre-defined blocks or can be learned partitions where the model learns how to best divide the sequence.</li>
</ul>
<p>So in summary, grouped query attention applies the power of attention models in a more focused, partitioned way, enabling attention mechanisms to be efficiently scaled to very long sequences. It's an optimization that retains modeling flexibility and enables transformers to handle tasks with longer inputs.</p>
<p><img alt="" src="../img/g/grouped_query_attention.png" width="100%" /></p>
<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2305.13245v2">https://arxiv.org/abs/2305.13245v2</a></li>
<li>code - <a href="https://paperswithcode.com/method/grouped-query-attention">https://paperswithcode.com/method/grouped-query-attention</a></li>
<li>more code - <a href="https://paperswithcode.com/paper/gqa-training-generalized-multi-query">https://paperswithcode.com/paper/gqa-training-generalized-multi-query</a></li>
</ul>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="gshard-model">Gshard Model<a class="headerlink" href="#gshard-model" title="Permanent link">#</a></h2>
<p>A Model built by <a href="./#google-company">Google</a> to ...</p>
<p>More at:</p>
<ul>
<li>paper - <a href="https://arxiv.org/abs/2006.16668">https://arxiv.org/abs/2006.16668</a></li>
</ul>
<p>See also <a href="./">G</a>, <a href="../s/#sparse-activation">Sparse Activation</a></p>
<h2 id="guardrail">Guardrail<a class="headerlink" href="#guardrail" title="Permanent link">#</a></h2>
<p>See also <a href="./">G</a>, ...</p>
<h2 id="guardrails-python-module">Guardrails Python Module<a class="headerlink" href="#guardrails-python-module" title="Permanent link">#</a></h2>
<p>More at:</p>
<ul>
<li>site - <a href="https://www.guardrailsai.com/">https://www.guardrailsai.com/</a></li>
<li>code - <a href="https://github.com/guardrails-ai/guardrails">https://github.com/guardrails-ai/guardrails</a></li>
</ul>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">February 7, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/emayssat" class="md-author" title="@emayssat">
          
          <img src="https://avatars.githubusercontent.com/u/1972699?v=4&size=72" alt="emayssat">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../f/" class="md-footer__link md-footer__link--prev" aria-label="Previous: F">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                F
              </div>
            </div>
          </a>
        
        
          
          <a href="../h/" class="md-footer__link md-footer__link--next" aria-label="Next: H">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                H
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 - 2025 <a href="https://www.midtown.ai/" rel="noopener" target="_blank">Midtown AI, Inc.</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://x.com/midtown_ai" target="_blank" rel="noopener" title="Follow us on X" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:ai4all@midtown.ai" target="_blank" rel="noopener" title="Send us an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../javascript/tablesort.js"></script>
      
    
  </body>
</html>